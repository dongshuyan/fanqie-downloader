# -*- coding: utf-8 -*-
"""
‰øÆÂ§çÁâàmain.py - Ëß£ÂÜ≥cookieÁîüÊàêÊó∂ÁöÑÂ∑®Â§ßÂæ™ÁéØÂç°Ê≠ªÈóÆÈ¢ò
ÂéüÁâàÊú¨Âú®_get_new_cookieÂáΩÊï∞‰∏≠‰ΩøÁî®6√ó10^18Âà∞9√ó10^18ÁöÑÂ∑®Â§ßÂæ™ÁéØËåÉÂõ¥ÔºåÂØºËá¥Á®ãÂ∫èÂç°‰Ωè
‰øÆÂ§çÁâàÊú¨‰ΩøÁî®Âü∫‰∫éÊó∂Èó¥Êà≥ÁöÑÂêàÁêÜËåÉÂõ¥ÔºåÈÅøÂÖçÈïøÊó∂Èó¥Á≠âÂæÖ
"""
import requests as req
from lxml import etree
from ebooklib import epub
from tqdm import tqdm
from bs4 import BeautifulSoup
import json
import yaml  # Ê∑ªÂä†YAMLÊîØÊåÅ
import time
import random
import re  # Ê∑ªÂä†Ê≠£ÂàôË°®ËææÂºèÊ®°Âùó
import os
import platform
import shutil
import concurrent.futures
import argparse  # Ê∑ªÂä†ÂëΩ‰ª§Ë°åÂèÇÊï∞Ëß£Êûê
from typing import Callable, Optional, Dict, List, Union
from dataclasses import dataclass, field
from enum import Enum


class SaveMode(Enum):
    SINGLE_TXT = 1
    SPLIT_TXT = 2
    EPUB = 3
    HTML = 4
    LATEX = 5


@dataclass
class Config:
    # Êñá‰ª∂Ê†ºÂºèÊéßÂà∂
    enable_txt: bool = True
    enable_epub: bool = False
    enable_html: bool = False
    enable_latex: bool = False
    enable_pdf: bool = False
    
    # ÁõÆÂΩïÈÖçÁΩÆ (ÁÆÄÂåñÁâà)
    bookstore_dir: str = "bookstore"    # JSONÊñá‰ª∂Â≠òÊîæÁõÆÂΩï
    download_dir: str = "downloads"     # ÂÖ∂‰ªñÊ†ºÂºèÊñá‰ª∂Â≠òÊîæÁõÆÂΩï
    
    # ÊÄßËÉΩÈÖçÁΩÆ
    thread_count: int = 8
    delay_mode: str = "normal"
    custom_delay: List[int] = field(default_factory=lambda: [150, 300])
    
    # Êñá‰ª∂ÁÆ°ÁêÜ
    delete_chapters_after_merge: bool = False
    conflict_resolution: str = "rename"
    encoding: str = "UTF-8"
    preserve_original_order: bool = False
    
    # CookieÈÖçÁΩÆ
    cookie_mode: str = "auto"
    manual_cookie: str = ""
    cookie_file: str = "data/cookie.json"
    validate_cookie: bool = False
    
    # ÂÜÖÂÆπÂ§ÑÁêÜ
    paragraph_spacing: int = 0
    indent_character: str = "„ÄÄ"
    decode_mode: str = "auto"
    filter_special_chars: bool = False
    
    # ÁΩëÁªúÈÖçÁΩÆ
    timeout: int = 30
    retry_count: int = 3
    retry_delays: List[int] = field(default_factory=lambda: [1, 2, 4])  # ÈáçËØïÈó¥Èöî(Áßí)
    rotate_user_agent: bool = True
    
    # Êó•ÂøóÈÖçÁΩÆ
    log_level: str = "normal"
    save_log_to_file: bool = False
    log_file: str = "logs/download.log"
    
    # È´òÁ∫ßÈÄâÈ°π
    enable_experimental: bool = False
    memory_mode: str = "normal"
    show_progress_bar: bool = True
    
    # ÂÖºÂÆπÊÄßÂ≠óÊÆµÔºà‰øùÊåÅÂêëÂêéÂÖºÂÆπÔºâ
    kg: int = 0
    kgf: str = '„ÄÄ'
    delay: List[int] = field(default_factory=lambda: [100, 200])
    save_path: str = ''
    save_mode: SaveMode = SaveMode.SINGLE_TXT
    space_mode: str = 'halfwidth'
    xc: int = 8
    
    def __post_init__(self):
        # Â§ÑÁêÜÂª∂Êó∂ÈÖçÁΩÆ
        if self.delay_mode == "fast":
            self.delay = [50, 100]
        elif self.delay_mode == "normal":
            self.delay = [100, 200]
        elif self.delay_mode == "safe":
            self.delay = [200, 500]
        elif self.delay_mode == "custom":
            self.delay = self.custom_delay.copy()
        
        # ÂêåÊ≠•Á∫øÁ®ãÊï∞ÈÖçÁΩÆ
        self.xc = self.thread_count
        
        # ÂêåÊ≠•ÊÆµËêΩÈÖçÁΩÆ
        self.kg = self.paragraph_spacing
        self.kgf = self.indent_character
    
    @classmethod
    def from_yaml(cls, yaml_path: str) -> 'Config':
        """‰ªéYAMLÊñá‰ª∂Âä†ËΩΩÈÖçÁΩÆ"""
        try:
            with open(yaml_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
            
            config = cls()
            
            # Êñá‰ª∂Ê†ºÂºèÈÖçÁΩÆ
            if 'formats' in data:
                formats = data['formats']
                config.enable_txt = formats.get('enable_txt', True)
                config.enable_epub = formats.get('enable_epub', False)
                config.enable_html = formats.get('enable_html', False)
                config.enable_latex = formats.get('enable_latex', False)
                config.enable_pdf = formats.get('enable_pdf', False)
            
            # ÁõÆÂΩïÈÖçÁΩÆ (ÁÆÄÂåñÁâà)
            if 'directories' in data:
                dirs = data['directories']
                config.bookstore_dir = dirs.get('bookstore_dir', "bookstore")
                config.download_dir = dirs.get('download_dir', "downloads")
            
            # ÊÄßËÉΩÈÖçÁΩÆ
            if 'performance' in data:
                perf = data['performance']
                config.thread_count = perf.get('thread_count', 8)
                config.delay_mode = perf.get('delay_mode', "normal")
                config.custom_delay = perf.get('custom_delay', [150, 300])
            
            # Êñá‰ª∂ÁÆ°ÁêÜÈÖçÁΩÆ
            if 'file_management' in data:
                fm = data['file_management']
                config.delete_chapters_after_merge = fm.get('delete_chapters_after_merge', False)
                config.conflict_resolution = fm.get('conflict_resolution', "rename")
                config.encoding = fm.get('encoding', "UTF-8")
                config.preserve_original_order = fm.get('preserve_original_order', False)
            
            # CookieÈÖçÁΩÆ
            if 'authentication' in data:
                auth = data['authentication']
                config.cookie_mode = auth.get('cookie_mode', "auto")
                config.manual_cookie = auth.get('manual_cookie', "")
                config.cookie_file = auth.get('cookie_file', "data/cookie.json")
                config.validate_cookie = auth.get('validate_cookie', False)
            
            # ÂÜÖÂÆπÂ§ÑÁêÜÈÖçÁΩÆ
            if 'content' in data:
                content = data['content']
                config.paragraph_spacing = content.get('paragraph_spacing', 0)
                config.indent_character = content.get('indent_character', "„ÄÄ")
                config.decode_mode = content.get('decode_mode', "auto")
                config.filter_special_chars = content.get('filter_special_chars', False)
            
            # ÁΩëÁªúÈÖçÁΩÆ
            if 'network' in data:
                net = data['network']
                config.timeout = net.get('timeout', 30)
                config.retry_count = net.get('retry_count', 3)
                config.retry_delays = net.get('retry_delays', [1, 2, 4])
                config.rotate_user_agent = net.get('rotate_user_agent', True)
            
            # Êó•ÂøóÈÖçÁΩÆ
            if 'logging' in data:
                log = data['logging']
                config.log_level = log.get('level', "normal")
                config.save_log_to_file = log.get('save_to_file', False)
                config.log_file = log.get('log_file', "logs/download.log")
            
            # È´òÁ∫ßÈÖçÁΩÆ
            if 'advanced' in data:
                adv = data['advanced']
                config.enable_experimental = adv.get('enable_experimental', False)
                config.memory_mode = adv.get('memory_mode', "normal")
                config.show_progress_bar = adv.get('show_progress_bar', True)
            
            return config
            
        except Exception as e:
            print(f"‚ö†Ô∏è ÈÖçÁΩÆÊñá‰ª∂ËØªÂèñÂ§±Ë¥•: {e}")
            print("‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ")
            return cls()
    
    def get_delay_range(self) -> List[int]:
        """Ëé∑ÂèñÂΩìÂâçÁöÑÂª∂Êó∂ËåÉÂõ¥"""
        return self.delay


class NovelDownloader:
    def __init__(self,
                 config: Config,
                 progress_callback: Optional[Callable] = None,
                 log_callback: Optional[Callable] = None):
        self.config = config
        self.progress_callback = progress_callback or self._default_progress
        self.log_callback = log_callback or print

        # Initialize headers first
        self.headers_lib = [
            {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36'},
            {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0'},
            {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36 Edg/93.0.961.47'}
        ]
        self.headers = random.choice(self.headers_lib)

        # Use absolute paths based on script location
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        self.data_dir = os.path.join(self.script_dir, 'data')
        
        # ‰ΩøÁî®ÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑÁõÆÂΩïËÆæÁΩÆ (ÁÆÄÂåñÁâà)
        self.bookstore_dir = os.path.join(self.script_dir, self.config.bookstore_dir)  # JSONÊñá‰ª∂ÁõÆÂΩï
        self.download_dir = os.path.join(self.script_dir, self.config.download_dir)    # ÂÖ∂‰ªñÊ†ºÂºèÊñá‰ª∂ÁõÆÂΩï
        
        self.record_path = os.path.join(self.data_dir, 'record.json')
        self.config_path = os.path.join(self.data_dir, 'config.json')
        
        # CookieË∑ØÂæÑÊ†πÊçÆÈÖçÁΩÆÂÜ≥ÂÆö
        if self.config.cookie_mode == "file":
            self.cookie_path = os.path.join(self.script_dir, self.config.cookie_file)
        else:
            self.cookie_path = os.path.join(self.data_dir, 'cookie.json')

        self.CODE = [[58344, 58715], [58345, 58716]]

        # Load charset for text decoding
        charset_path = os.path.join(self.script_dir, 'charset.json')
        with open(charset_path, 'r', encoding='UTF-8') as f:
            self.charset = json.load(f)

        self._setup_directories()
        self._init_cookie()

        # Add these variables
        self.zj = {}  # For storing chapter data
        self.cs = 0  # Chapter counter
        self.tcs = 0  # Test counter
        self.tzj = None  # Test chapter ID
        self.book_json_path = None  # Current book's JSON path
        
        # ÂèçÁà¨Ê£ÄÊµãÂíåËá™ÈÄÇÂ∫îÂª∂Êó∂
        self.empty_content_count = 0  # ËøûÁª≠Á©∫ÂÜÖÂÆπËÆ°Êï∞
        self.total_empty_count = 0    # ÊÄªËÆ°Á©∫ÂÜÖÂÆπËÆ°Êï∞
        self.adaptive_delay_multiplier = 1.0  # Ëá™ÈÄÇÂ∫îÂª∂Êó∂ÂÄçÊï∞
        self.last_successful_time = time.time()  # ‰∏äÊ¨°ÊàêÂäüÊó∂Èó¥
        
        # üîÑ Á≠ñÁï•2ÔºöÊàêÂäü‰∏ãËΩΩËÆ°Êï∞Âô®ÔºàÁî®‰∫é‰∏ªÂä®CookieÂà∑Êñ∞Ôºâ
        self.successful_downloads = 0
        
        # üìù Â§±Ë¥•Á´†ËäÇËÆ∞ÂΩïÔºàÁî®‰∫éÁîüÊàêerror.logÔºâ
        self.failed_chapters = []  # Ê†ºÂºè: [{'title': str, 'chapter_id': str, 'reason': str}]

    def _setup_directories(self):
        """Create necessary directories if they don't exist"""
        os.makedirs(self.data_dir, exist_ok=True)
        
        # ÂàõÂª∫Âü∫Á°ÄÁõÆÂΩï
        os.makedirs(self.bookstore_dir, exist_ok=True)  # JSONÊñá‰ª∂ÁõÆÂΩïÔºàÊÄªÊòØÈúÄË¶ÅÔºâ
        os.makedirs(self.download_dir, exist_ok=True)   # ÂÖ∂‰ªñÊ†ºÂºèÊñá‰ª∂ÁõÆÂΩï
            
        # Â¶ÇÊûúÈúÄË¶Å‰øùÂ≠òÊó•ÂøóÔºåÂàõÂª∫Êó•ÂøóÁõÆÂΩï
        if self.config.save_log_to_file:
            log_dir = os.path.dirname(os.path.join(self.script_dir, self.config.log_file))
            if log_dir:
                os.makedirs(log_dir, exist_ok=True)

    def _init_cookie(self):
        """Initialize cookie for downloads - ÁÆÄÂåñÁâàÊú¨ÔºåÁõ¥Êé•‰ΩøÁî®ÈªòËÆ§cookie"""
        self.log_callback('Ê≠£Âú®ÂàùÂßãÂåñcookie')
        
        # Áõ¥Êé•‰ΩøÁî®Êó∂Èó¥Êà≥ÁîüÊàêÈªòËÆ§cookieÔºåÊó†ÈúÄÈ™åËØÅ
        base_timestamp = int(time.time() * 1000)
        self.cookie = f'novel_web_id={base_timestamp}'
        
        # ‰øùÂ≠òcookieÂà∞Êñá‰ª∂
        try:
            with open(self.cookie_path, 'w', encoding='UTF-8') as f:
                json.dump(self.cookie, f)
        except Exception:
            pass  # ÂøΩÁï•‰øùÂ≠òÂ§±Ë¥•ÔºåÁªßÁª≠‰ΩøÁî®ÂÜÖÂ≠ò‰∏≠ÁöÑcookie
            
        self.log_callback('CookieÂàùÂßãÂåñÂÆåÊàê')

    def _default_progress(self, current: int, total: int, desc: str = '',
                          chapter_title: str = None):
        """Progress tracking for both CLI and web"""
        # For CLI: Don't create additional progress bar, tqdm is already handled in download_novel
        # For web: Return progress info as dict
        return {
            'current': current,
            'total': total,
            'percentage': (current / total * 100) if total > 0 else 0,
            'description': desc,
            'chapter_title': chapter_title
        }
    
    def _write_debug_log(self, message: str):
        """ÂÜôÂÖ•Ë∞ÉËØïÊó•ÂøóÂà∞Êñá‰ª∂ÂíåÊéßÂà∂Âè∞"""
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_message = f"[{timestamp}] {message}"
        
        # ËæìÂá∫Âà∞ÊéßÂà∂Âè∞ÔºàÂ¶ÇÊûúÂêØÁî®‰∫ÜËØ¶ÁªÜÊó•ÂøóÔºâ
        if hasattr(self.config, 'log_level') and self.config.log_level == 'debug':
            self.log_callback(log_message)
        
        # ÂÜôÂÖ•Êó•ÂøóÊñá‰ª∂
        log_dir = "logs"
        os.makedirs(log_dir, exist_ok=True)
        log_file = os.path.join(log_dir, "download_debug.log")
        
        try:
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(log_message + '\n')
        except Exception as e:
            # ÈÅøÂÖçÊó•ÂøóÂÜôÂÖ•Â§±Ë¥•ÂΩ±Âìç‰∏ªÁ®ãÂ∫è
            pass

    def _get_randomized_headers(self) -> Dict[str, str]:
        """üé≠ Á≠ñÁï•3ÔºöÁîüÊàêÈ´òÂ∫¶ÁúüÂÆûÂåñÁöÑÈöèÊú∫ËØ∑Ê±ÇÂ§¥ÔºåÊ®°ÊãüÁúüÂÆûÁî®Êà∑Ë°å‰∏∫Ôºà20+ÁßçÂèòÂåñÔºâ"""
        
        # üåü Â§ßÂπÖÊâ©Â±ïUser-AgentÊ±†Ôºà20+ÁßçÁúüÂÆûÊµèËßàÂô®Ôºâ
        user_agents = [
            # ChromeÊúÄÊñ∞ÁâàÊú¨ - Windows
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0',
            
            # Chrome - macOS
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            
            # Safari - macOS
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Safari/605.1.15',
            
            # Firefox - Windows & macOS
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:122.0) Gecko/20100101 Firefox/122.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0',
            
            # Edge - Windows
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0',
            
            # ÁßªÂä®Á´ØUser-AgentÔºàÂÅ∂Â∞î‰ΩøÁî®Â¢ûÂä†ÁúüÂÆûÊÄßÔºâ
            'Mozilla/5.0 (iPhone; CPU iPhone OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (Linux; Android 13; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Mobile Safari/537.36',
            
            # ‰∏Ä‰∫õÁ®çÊóß‰ΩÜ‰ªçÁÑ∂ÁúüÂÆûÁöÑÁâàÊú¨
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0',
        ]
        
        # üåê Êâ©Â±ïAccept-LanguageÊ±†ÔºàÁúüÂÆûÂú∞Âå∫ÂèòÂåñÔºâ
        accept_languages = [
            'zh-CN,zh;q=0.9,en;q=0.8',
            'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
            'zh-CN,zh;q=0.9,en;q=0.8,ja;q=0.7',
            'zh-CN,zh;q=0.9',
            'zh,en-US;q=0.8,en;q=0.6',
            'zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7',
            'zh-CN,zh-TW;q=0.9,zh;q=0.8,en;q=0.7',
            'zh-CN,zh;q=0.8,en;q=0.6,ja;q=0.4',
            'zh-CN,zh;q=0.9,en-GB;q=0.8,en;q=0.7,zh-TW;q=0.6'
        ]
        
        # üìã Êâ©Â±ïAcceptÊ±†ÔºàÊõ¥ÁúüÂÆûÁöÑÊµèËßàÂô®Ë°å‰∏∫Ôºâ
        accepts = [
            'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'
        ]
        
        # üóúÔ∏è Êâ©Â±ïAccept-EncodingÊ±†
        accept_encodings = [
            'gzip, deflate, br',
            'gzip, deflate',
            'gzip, deflate, br, zstd',
            'gzip, deflate, br',
            'gzip, deflate, compress, br',
            'gzip, br, deflate'
        ]
        
        # üîó ÁúüÂÆûÁöÑConnectionÈÄâÈ°π
        connections = ['keep-alive', 'close']
        
        # üíæ ÁúüÂÆûÁöÑCache-ControlÈÄâÈ°π
        cache_controls = [
            'no-cache',
            'max-age=0',
            'no-store',
            'max-age=0, no-cache',
            'no-cache, no-store, must-revalidate',
            'max-age=3600'
        ]
        
        # üåç ÁúüÂÆûÁöÑRefererÈÄâÈ°πÔºàÊ®°Êãü‰ªé‰∏çÂêåÈ°µÈù¢ËÆøÈóÆÔºâ
        referers = [
            'https://fanqienovel.com/',
            'https://fanqienovel.com/page',
            'https://www.google.com/',
            'https://www.baidu.com/',
            'https://fanqienovel.com/search',
            None  # ÊúâÊó∂ÂÄôÊ≤°Êúâreferer
        ]
        
        # üîí ÁúüÂÆûÁöÑSec-FetchÁ≥ªÂàó
        sec_fetch_dests = ['document', 'empty', 'iframe']
        sec_fetch_modes = ['navigate', 'cors', 'no-cors', 'same-origin']  
        sec_fetch_sites = ['none', 'same-origin', 'same-site', 'cross-site']
        sec_fetch_users = ['?1', None]  # ÊúâÊó∂ÂÄôÊ≤°ÊúâËøô‰∏™Â§¥
        
        # üéØ ÈÄâÊã©User-AgentÂπ∂Âü∫‰∫éÂÆÉÁ°ÆÂÆöÊµèËßàÂô®Á±ªÂûã
        selected_ua = random.choice(user_agents)
        is_chrome = 'Chrome' in selected_ua and 'Edg' not in selected_ua
        is_firefox = 'Firefox' in selected_ua
        is_safari = 'Safari' in selected_ua and 'Chrome' not in selected_ua
        is_edge = 'Edg' in selected_ua
        is_mobile = 'Mobile' in selected_ua
        
        base_headers = self.headers.copy()
        
        # üé≠ ÊûÑÂª∫ÁúüÂÆûÁöÑÈöèÊú∫ÂåñËØ∑Ê±ÇÂ§¥
        randomized_headers = {
            **base_headers,
            'User-Agent': selected_ua,
            'Accept': random.choice(accepts),
            'Accept-Language': random.choice(accept_languages),
            'Accept-Encoding': random.choice(accept_encodings),
            'Connection': random.choice(connections),
            'Cache-Control': random.choice(cache_controls),
        }
        
        # üåç ÈöèÊú∫Ê∑ªÂä†RefererÔºà80%Ê¶ÇÁéáÔºâ
        if random.random() > 0.2:
            referer = random.choice(referers)
            if referer:
                randomized_headers['Referer'] = referer
        
        # üîí Chrome/EdgeÁâπÊúâÁöÑSec-FetchÂ§¥ÈÉ®
        if is_chrome or is_edge:
            randomized_headers['Sec-Fetch-Dest'] = random.choice(sec_fetch_dests)
            randomized_headers['Sec-Fetch-Mode'] = random.choice(sec_fetch_modes)
            randomized_headers['Sec-Fetch-Site'] = random.choice(sec_fetch_sites)
            
            # Sec-Fetch-UserÔºàÂØºËà™Êó∂ÊâçÊúâÔºâ
            if random.choice(sec_fetch_users):
                randomized_headers['Sec-Fetch-User'] = '?1'
                
            # Sec-CHÁ≥ªÂàóÔºàChromeÁâπÊúâÔºâ
            if is_chrome and random.random() > 0.5:
                randomized_headers['Sec-CH-UA'] = '"Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"'
                randomized_headers['Sec-CH-UA-Mobile'] = '?1' if is_mobile else '?0'
                randomized_headers['Sec-CH-UA-Platform'] = f'"{random.choice(["Windows", "macOS", "Linux"])}"'
        
        # üö´ DNTÂ§¥ÈÉ®Ôºà60%Ê¶ÇÁéáÔºâ
        if random.random() > 0.4:
            randomized_headers['DNT'] = '1'
        
        # üîí Upgrade-Insecure-RequestsÔºà70%Ê¶ÇÁéáÔºâ
        if random.random() > 0.3:
            randomized_headers['Upgrade-Insecure-Requests'] = '1'
            
        # üì± ÁßªÂä®Á´ØÁâπÊúâÂ§¥ÈÉ®
        if is_mobile:
            randomized_headers['Viewport-Width'] = str(random.choice([375, 414, 390, 393]))
            if random.random() > 0.5:
                randomized_headers['Device-Memory'] = str(random.choice([4, 6, 8]))
        
        # üï∞Ô∏è PragmaÂ§¥ÈÉ®ÔºàÂÅ∂Â∞îÊ∑ªÂä†Ôºå10%Ê¶ÇÁéáÔºâ
        if random.random() > 0.9:
            randomized_headers['Pragma'] = 'no-cache'
            
        # üåç HostÂ§¥ÈÉ®ÔºàÊÄªÊòØËÆæÁΩÆ‰∏∫ÁõÆÊ†áÁ´ôÁÇπÔºâ
        randomized_headers['Host'] = 'fanqienovel.com'
        
        # üîß ÊµèËßàÂô®ÁâπÊúâÁöÑÂÖ∂‰ªñÂ§¥ÈÉ®
        
        # FirefoxÁâπÊúâ
        if is_firefox and random.random() > 0.7:
            randomized_headers['Accept-Language'] = randomized_headers['Accept-Language'].replace('q=0.', 'q=0.')
            
        # SafariÁâπÊúâ  
        if is_safari and random.random() > 0.6:
            randomized_headers['Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
            
        # ÈöèÊú∫ÁßªÈô§Êüê‰∫õÂèØÈÄâÂ§¥ÈÉ®ÔºàÊ®°Êãü‰∏çÂêåÊµèËßàÂô®ÈÖçÁΩÆÔºâ
        optional_headers = ['DNT', 'Pragma', 'Sec-CH-UA', 'Device-Memory', 'Viewport-Width']
        for header in optional_headers:
            if header in randomized_headers and random.random() > 0.8:
                del randomized_headers[header]
        
        # üìä ËÆ∞ÂΩï‰ΩøÁî®ÁöÑËØ∑Ê±ÇÂ§¥Á±ªÂûãÔºàÁî®‰∫éË∞ÉËØïÔºâ
        browser_type = 'Chrome' if is_chrome else 'Firefox' if is_firefox else 'Safari' if is_safari else 'Edge' if is_edge else 'Unknown'
        self._write_debug_log(f"üé≠ ‰ΩøÁî®{browser_type}ËØ∑Ê±ÇÂ§¥Ê®°ÊãüÔºåÂÖ±{len(randomized_headers)}‰∏™Â§¥ÈÉ®")
        
        return randomized_headers

    def _smart_reading_pause(self, chapter_title: str = ""):
        """üé≠ Á≠ñÁï•3ÔºöÊ®°ÊãüÁúüÂÆûÈòÖËØªË°å‰∏∫ÁöÑÈöèÊú∫ÊöÇÂÅú (0-5Áßí)"""
        pause_duration = random.uniform(0, 5.0)  # 0Âà∞5ÁßíÁöÑÈöèÊú∫ÊöÇÂÅú
        
        if pause_duration > 0.1:  # Âè™ËÆ∞ÂΩïË∂ÖËøá0.1ÁßíÁöÑÊöÇÂÅú
            self._write_debug_log(f"üé≠ Ê®°ÊãüÈòÖËØªÊöÇÂÅú {pause_duration:.2f}Áßí {'- ' + chapter_title if chapter_title else ''}")
        
        time.sleep(pause_duration)

    def _should_refresh_cookie_proactively(self) -> bool:
        """üîÑ Á≠ñÁï•2ÔºöÊ£ÄÊü•ÊòØÂê¶Â∫îËØ•‰∏ªÂä®Âà∑Êñ∞Cookie"""
        # üö® Êõ¥ÊøÄËøõÔºöÊØè20‰∏™Á´†ËäÇ‰∏ªÂä®Âà∑Êñ∞‰∏ÄÊ¨°
        return hasattr(self, 'successful_downloads') and self.successful_downloads > 0 and self.successful_downloads % 20 == 0

    def _generate_error_log(self, output_dir: str):
        """üìù ÁîüÊàêerror.logÊñá‰ª∂ËÆ∞ÂΩïÊúÄÁªàÂ§±Ë¥•ÁöÑÁ´†ËäÇ"""
        if not self.failed_chapters:
            return  # Ê≤°ÊúâÂ§±Ë¥•Á´†ËäÇÂ∞±‰∏çÁîüÊàê
        
        error_log_path = os.path.join(output_dir, "error.log")
        
        try:
            with open(error_log_path, 'w', encoding='utf-8') as f:
                f.write("# Á´†ËäÇ‰∏ãËΩΩÂ§±Ë¥•ËÆ∞ÂΩï\n")
                f.write(f"# ÁîüÊàêÊó∂Èó¥: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# Â§±Ë¥•Á´†ËäÇÊÄªÊï∞: {len(self.failed_chapters)}\n")
                f.write("# Ê†ºÂºè: Á´†ËäÇÊ†áÈ¢ò | Á´†ËäÇID | Â§±Ë¥•ÂéüÂõ†\n")
                f.write("=" * 80 + "\n\n")
                
                for failed in self.failed_chapters:
                    title = failed.get('title', 'Êú™Áü•Ê†áÈ¢ò')
                    chapter_id = failed.get('chapter_id', 'Êú™Áü•ID')
                    reason = failed.get('reason', 'Êú™Áü•ÂéüÂõ†')
                    f.write(f"{title} | {chapter_id} | {reason}\n")
            
            self.log_callback(f"üìù Â∑≤ÁîüÊàêÂ§±Ë¥•Á´†ËäÇËÆ∞ÂΩï: {error_log_path} ({len(self.failed_chapters)}‰∏™Â§±Ë¥•Á´†ËäÇ)")
            self._write_debug_log(f"üìù error.logÂ∑≤ÁîüÊàê: {error_log_path}")
            
        except Exception as e:
            self.log_callback(f"‚ö†Ô∏è ÁîüÊàêerror.logÂ§±Ë¥•: {str(e)}")
            self._write_debug_log(f"‚ö†Ô∏è ÁîüÊàêerror.logÂ§±Ë¥•: {str(e)}")

    def download_novel(self, novel_id: int) -> str:
        """Download a novel"""
        try:
            # üìù ÈáçÁΩÆÂ§±Ë¥•Á´†ËäÇËÆ∞ÂΩïÔºàÊØè‰∏™Â∞èËØ¥ÂçïÁã¨ËÆ∞ÂΩïÔºâ
            self.failed_chapters = []
            
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nÂºÄÂßã‰∏ãËΩΩ„Ää{name}„ÄãÔºåÁä∂ÊÄÅÔºö{status[0]}')

            # ÂàõÂª∫"‰π¶Âêç-id"Êñá‰ª∂Â§πÁªìÊûÑ
            book_folder_name = f"{safe_name}-{novel_id}"
            book_download_dir = os.path.join(self.download_dir, book_folder_name)    # ÂÖ∂‰ªñÊ†ºÂºèÊñá‰ª∂ÁõÆÂΩï
            book_json_dir = os.path.join(self.bookstore_dir, book_folder_name)       # JSONÊñá‰ª∂ÁõÆÂΩï
            chapters_dir = os.path.join(book_download_dir, "Chapters")
            
            # ÂàõÂª∫ÂøÖÈúÄÁöÑÁõÆÂΩï
            os.makedirs(book_download_dir, exist_ok=True)
            os.makedirs(book_json_dir, exist_ok=True) 
            os.makedirs(chapters_dir, exist_ok=True)
            
            self.log_callback(f'ÂàõÂª∫Êñá‰ª∂Â§π: {book_folder_name}')

            # ‰ΩøÁî®ÂéüÂßãÁ´†ËäÇÂàóË°®ÁöÑÈ°∫Â∫è
            chapter_list = list(chapters.items())  # ËΩ¨Êç¢‰∏∫ÂàóË°®‰øùÊåÅÈ°∫Â∫è
            total_chapters = len(chapter_list)
            completed_chapters = 0

            # ÂàõÂª∫‰∏Ä‰∏™ÊúâÂ∫èÂ≠óÂÖ∏Êù•‰øùÂ≠òÁ´†ËäÇÂÜÖÂÆπ
            novel_content = {}

            # ‰∏ãËΩΩÁ´†ËäÇ
            with tqdm(total=total_chapters, desc='‰∏ãËΩΩËøõÂ∫¶') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter,
                            title,
                            chapter_id,
                            {}
                        ): (title, chapter_id) for title, chapter_id in chapter_list
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        title, chapter_id = future_to_chapter[future]
                        try:
                            content = future.result()
                            if content:
                                # ËÆ∞ÂΩïËØ¶ÁªÜÁöÑÁ´†ËäÇ‰∏ãËΩΩ‰ø°ÊÅØ
                                self._write_debug_log(f"‚úÖ ÊàêÂäü‰∏ãËΩΩÁ´†ËäÇ: „Äå{title}„Äç(ID: {chapter_id}) - ÂÜÖÂÆπÈïøÂ∫¶: {len(content)} Â≠óÁ¨¶")
                                
                                # üö® ÂÖ≥ÈîÆË∞ÉËØïÁÇπÔºöÊ£ÄÊü•Ê†áÈ¢òÂ§ÑÁêÜËøáÁ®ã
                                self._write_debug_log(f"üîç „ÄêÊñá‰ª∂‰øùÂ≠òË∞ÉËØï„ÄëÂºÄÂßãÂ§ÑÁêÜÁ´†ËäÇÊñá‰ª∂‰øùÂ≠ò")
                                self._write_debug_log(f"üîç ÂéüÂßãtitle: {repr(title)} (Á±ªÂûã: {type(title).__name__})")
                                
                                clean_title = title.strip()
                                self._write_debug_log(f"üîç clean_title: {repr(clean_title)} (Á±ªÂûã: {type(clean_title).__name__})")
                                
                                novel_content[clean_title] = content
                                
                                # üö® ÂÖ≥ÈîÆË∞ÉËØïÁÇπÔºöÊñá‰ª∂ÂêçÁîüÊàêËøáÁ®ã
                                self._write_debug_log(f"üîç Ë∞ÉÁî®_sanitize_filenameÂâç: {repr(clean_title)}")
                                sanitized_title = self._sanitize_filename(clean_title)
                                self._write_debug_log(f"üîç _sanitize_filenameËøîÂõû: {repr(sanitized_title)} (Á±ªÂûã: {type(sanitized_title).__name__})")
                                
                                chapter_filename = f"{sanitized_title}.txt"
                                self._write_debug_log(f"üîç chapter_filename: {repr(chapter_filename)} (Á±ªÂûã: {type(chapter_filename).__name__})")
                                
                                # üö® ÂÖ≥ÈîÆË∞ÉËØïÁÇπÔºöË∑ØÂæÑÊãºÊé•ËøáÁ®ã
                                self._write_debug_log(f"üîç chapters_dir: {repr(chapters_dir)} (Á±ªÂûã: {type(chapters_dir).__name__})")
                                self._write_debug_log(f"üîç ÂáÜÂ§áË∞ÉÁî®os.path.join({repr(chapters_dir)}, {repr(chapter_filename)})")
                                
                                chapter_path = os.path.join(chapters_dir, chapter_filename)
                                self._write_debug_log(f"üîç chapter_path: {repr(chapter_path)} (Á±ªÂûã: {type(chapter_path).__name__})")
                                
                                # üö® ÂÖ≥ÈîÆË∞ÉËØïÁÇπÔºöÊñá‰ª∂ÂÜôÂÖ•ËøáÁ®ã
                                self._write_debug_log(f"üîç ÂáÜÂ§áÊâìÂºÄÊñá‰ª∂: {repr(chapter_path)}")
                                with open(chapter_path, 'w', encoding='UTF-8') as f:
                                    f.write(f"{clean_title}\n\n{content}")
                                self._write_debug_log(f"‚úÖ Á´†ËäÇÊñá‰ª∂‰øùÂ≠òÊàêÂäü: {chapter_path}")
                            else:
                                # ÂÜÖÂÆπ‰∏∫Á©∫ÁöÑÊÉÖÂÜµ
                                self._write_debug_log(f"‚ö†Ô∏è Á´†ËäÇÂÜÖÂÆπ‰∏∫Á©∫: „Äå{title}„Äç(ID: {chapter_id})")
                                self.log_callback(f"‚ö†Ô∏è Á´†ËäÇ„Äå{title}„Äç‰∏ãËΩΩÂ§±Ë¥•: ÂÜÖÂÆπ‰∏∫Á©∫")
                                    
                        except Exception as e:
                            # üö®üö®üö® ÂÆåÊï¥ÁöÑÈîôËØØ‰ø°ÊÅØËæìÂá∫ - Áî®Êà∑Âº∫Ë∞ÉÁöÑÂÖ≥ÈîÆÈúÄÊ±ÇÔºÅüö®üö®üö®
                            self._write_debug_log(f"‚ùå‚ùå‚ùå „ÄêÂÆåÊï¥ÈîôËØØÊä•Âëä„ÄëÁ´†ËäÇ‰∏ãËΩΩÂºÇÂ∏∏: „Äå{title}„Äç(ID: {chapter_id}) ‚ùå‚ùå‚ùå")
                            self._write_debug_log(f"=" * 100)
                            
                            # Âü∫Êú¨‰ø°ÊÅØ
                            self._write_debug_log(f"üîç Ê†áÈ¢ò‰ø°ÊÅØ:")
                            self._write_debug_log(f"   - Ê†áÈ¢òÁ±ªÂûã: {type(title).__name__}")
                            self._write_debug_log(f"   - Ê†áÈ¢òÂÜÖÂÆπ: {repr(title)}")
                            self._write_debug_log(f"   - Ê†áÈ¢òÈïøÂ∫¶: {len(title) if title else 'None'}")
                            self._write_debug_log(f"üîç Á´†ËäÇID‰ø°ÊÅØ:")
                            self._write_debug_log(f"   - Á´†ËäÇIDÁ±ªÂûã: {type(chapter_id).__name__}")
                            self._write_debug_log(f"   - Á´†ËäÇIDÂÜÖÂÆπ: {repr(chapter_id)}")
                            
                            # ÈîôËØØËØ¶ÊÉÖ
                            self._write_debug_log(f"‚ùå ÈîôËØØËØ¶ÊÉÖ:")
                            self._write_debug_log(f"   - ÈîôËØØÁ±ªÂûã: {type(e).__name__}")
                            self._write_debug_log(f"   - ÈîôËØØËØ¶ÊÉÖ: {str(e)}")
                            self._write_debug_log(f"   - ÈîôËØØÂèÇÊï∞: {getattr(e, 'args', 'No args')}")
                            self._write_debug_log(f"   - ÂÆåÊï¥ÂºÇÂ∏∏‰ø°ÊÅØ: {repr(e)}")
                            
                            # üö® ÂÖ≥ÈîÆÔºöÂ∞ùËØïËé∑ÂèñËØ•Á´†ËäÇÁöÑÂÆåÊï¥ÂìçÂ∫îÂÜÖÂÆπ
                            self._write_debug_log(f"üåê Â∞ùËØïËé∑ÂèñËØ•Á´†ËäÇÁöÑÂÆåÊï¥ÁΩëÁªúÂìçÂ∫î:")
                            try:
                                # Âº∫Âà∂Ëé∑ÂèñËØ•Á´†ËäÇÁöÑÂéüÂßãÂìçÂ∫î
                                test_content = self._download_chapter_content(int(chapter_id), test_mode=True)
                                self._write_debug_log(f"üì• ÂéüÂßãÂìçÂ∫îÂÜÖÂÆπÁ±ªÂûã: {type(test_content).__name__}")
                                self._write_debug_log(f"üì• ÂéüÂßãÂìçÂ∫îÈïøÂ∫¶: {len(test_content) if test_content else 'None'}")
                                self._write_debug_log(f"üì• ÂéüÂßãÂìçÂ∫îÂâç500Â≠óÁ¨¶: {repr(test_content[:500]) if test_content else 'None'}")
                                if test_content and len(test_content) > 500:
                                    self._write_debug_log(f"üì• ÂéüÂßãÂìçÂ∫îÂêé200Â≠óÁ¨¶: {repr(test_content[-200:])}")
                                self._write_debug_log(f"üì• ÂÆåÊï¥ÂéüÂßãÂìçÂ∫î: {repr(test_content)}")
                            except Exception as response_error:
                                self._write_debug_log(f"üí• Ëé∑ÂèñÂéüÂßãÂìçÂ∫îÂ§±Ë¥•: {str(response_error)}")
                                self._write_debug_log(f"üí• ÂìçÂ∫îÈîôËØØÁ±ªÂûã: {type(response_error).__name__}")
                                self._write_debug_log(f"üí• ÂìçÂ∫îÈîôËØØËØ¶ÊÉÖ: {repr(response_error)}")
                            
                            # ÁéØÂ¢ÉÁä∂ÊÄÅ‰ø°ÊÅØ
                            self._write_debug_log(f"üåç ÁéØÂ¢ÉÁä∂ÊÄÅ:")
                            self._write_debug_log(f"   - chapters_dir: {repr(chapters_dir)}")
                            self._write_debug_log(f"   - chapters_dirÁ±ªÂûã: {type(chapters_dir).__name__}")
                            self._write_debug_log(f"   - chapters_dirÂ≠òÂú®: {os.path.exists(chapters_dir) if chapters_dir else 'chapters_dir is None'}")
                            self._write_debug_log(f"   - ÂΩìÂâçÂ∑•‰ΩúÁõÆÂΩï: {repr(os.getcwd())}")
                            
                            # Â±ÄÈÉ®ÂèòÈáèÁä∂ÊÄÅ
                            self._write_debug_log(f"üìä Â±ÄÈÉ®ÂèòÈáèÁä∂ÊÄÅ:")
                            local_vars = ['content', 'clean_title', 'sanitized_title', 'chapter_filename', 'chapter_path']
                            for var_name in local_vars:
                                if var_name in locals():
                                    var_value = locals()[var_name]
                                    self._write_debug_log(f"   - {var_name}: {repr(var_value)} (Á±ªÂûã: {type(var_value).__name__})")
                                else:
                                    self._write_debug_log(f"   - {var_name}: Êú™ÂÆö‰πâ")
                            
                            # ÁâπÊÆäÂ§ÑÁêÜË∑ØÂæÑÁõ∏ÂÖ≥ÈîôËØØ
                            if "PathLike" in str(e) or "NoneType" in str(e):
                                self._write_debug_log(f"üö® Ê£ÄÊµãÂà∞Ë∑ØÂæÑÊàñNoneTypeÈîôËØØ - Ê∑±Â∫¶ÂàÜÊûê:")
                                
                                # ÊµãËØï_sanitize_filenameÂáΩÊï∞
                                try:
                                    test_title = title.strip() if title else "ERROR_None_Title"
                                    sanitized = self._sanitize_filename(test_title)
                                    self._write_debug_log(f"   üîß _sanitize_filenameÊµãËØï: {repr(test_title)} -> {repr(sanitized)}")
                                except Exception as sanitize_error:
                                    self._write_debug_log(f"   üí• _sanitize_filenameÊµãËØïÂ§±Ë¥•: {str(sanitize_error)}")
                                    self._write_debug_log(f"   üí• _sanitize_filenameÈîôËØØËØ¶ÊÉÖ: {repr(sanitize_error)}")
                            
                            self._write_debug_log(f"=" * 100)
                            self._write_debug_log(f"‚ùå‚ùå‚ùå „ÄêÂÆåÊï¥ÈîôËØØÊä•ÂëäÁªìÊùü„Äë ‚ùå‚ùå‚ùå")
                            
                            # üìù ËÆ∞ÂΩïÊúÄÁªàÂ§±Ë¥•ÁöÑÁ´†ËäÇÔºàÁî®‰∫éÁîüÊàêerror.logÔºâ
                            failure_reason = self._get_failure_reason(e)
                            self.failed_chapters.append({
                                'title': title,
                                'chapter_id': chapter_id,
                                'reason': failure_reason
                            })
                            
                            # üìù 1. ÂàõÂª∫Âç†‰ΩçTXTÊñá‰ª∂
                            try:
                                clean_title = title.strip() if title else f"Á¨¨{chapter_id}Á´†"
                                sanitized_title = self._sanitize_filename(clean_title)
                                chapter_filename = f"{sanitized_title}.txt"
                                chapter_path = os.path.join(chapters_dir, chapter_filename)
                                
                                with open(chapter_path, 'w', encoding='UTF-8') as f:
                                    f.write(f"{clean_title}\n\nÊäìÂèñÂÜÖÂÆπ‰∏∫Á©∫")
                                
                                self._write_debug_log(f"üìù Â∑≤ÂàõÂª∫Â§±Ë¥•Á´†ËäÇÂç†‰ΩçÊñá‰ª∂: {chapter_path}")
                                
                                # üìù 2. Ê∑ªÂä†Âç†‰ΩçÂÜÖÂÆπÂà∞novel_contentÔºàÁî®‰∫éJSONÂíåÂêàÂπ∂TXTÔºâ
                                novel_content[clean_title] = "ÊäìÂèñÂÜÖÂÆπ‰∏∫Á©∫"
                                
                            except Exception as placeholder_error:
                                self._write_debug_log(f"‚ö†Ô∏è ÂàõÂª∫Âç†‰ΩçÊñá‰ª∂Â§±Ë¥•: {str(placeholder_error)}")
                            
                            # ËæìÂá∫Âà∞ÊéßÂà∂Âè∞ËÆ©Áî®Êà∑ÁúãÂà∞ÁúüÊ≠£ÁöÑÈóÆÈ¢ò
                            self.log_callback(f'‚ùå ‰∏ãËΩΩÁ´†ËäÇÂ§±Ë¥•„Äå{title}„Äç: {failure_reason}ÔºàÂ∑≤ÂàõÂª∫Âç†‰ΩçÊñá‰ª∂Ôºâ')
                            
                            # ÁªßÁª≠Â§ÑÁêÜÂÖ∂‰ªñÁ´†ËäÇÔºå‰ΩÜ‰øùÁïôÂÆåÊï¥ÁöÑÈîôËØØËÆ∞ÂΩï

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            '‰∏ãËΩΩËøõÂ∫¶',
                            title
                        )

            # Ê†πÊçÆÈÖçÁΩÆÂÜ≥ÂÆö‰øùÂ≠òÂì™‰∫õÊ†ºÂºè
            results = []
            
            # ‰øùÂ≠òJSONÊñá‰ª∂ÔºàÂøÖÈ°ªË¶ÅÁöÑÔºâ
            json_path = os.path.join(book_json_dir, f'{safe_name}.json')
            with open(json_path, 'w', encoding='UTF-8') as f:
                json.dump(novel_content, f, ensure_ascii=False, indent=4)
            self.log_callback(f'‚úÖ JSONÊñá‰ª∂Â∑≤‰øùÂ≠ò: {json_path}')
            results.append('json')
            
            # ‰øùÂ≠òTXTÊñá‰ª∂ÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            if self.config.enable_txt:
                result = self._save_single_txt_to_folder(safe_name, novel_content, book_download_dir)
                if result == 's':
                    self.log_callback(f'‚úÖ TXTÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                    results.append('txt')
                    
                    # Â¶ÇÊûúÈÖçÁΩÆË¶ÅÊ±ÇÂà†Èô§Á´†ËäÇÊñá‰ª∂Â§π
                    if self.config.delete_chapters_after_merge:
                        try:
                            import shutil
                            shutil.rmtree(chapters_dir)
                            self.log_callback(f'üóëÔ∏è Â∑≤Âà†Èô§Á´†ËäÇÊñá‰ª∂Â§π: {chapters_dir}')
                        except Exception as e:
                            self.log_callback(f'‚ö†Ô∏è Âà†Èô§Á´†ËäÇÊñá‰ª∂Â§πÂ§±Ë¥•: {e}')
            
            # ‰øùÂ≠òEPUBÊñá‰ª∂ÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            if self.config.enable_epub:
                try:
                    epub_result = self._save_epub_from_content(safe_name, novel_content, book_download_dir, novel_id)
                    if epub_result == 's':
                        self.log_callback(f'‚úÖ EPUBÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                        results.append('epub')
                except Exception as e:
                    self.log_callback(f'‚ö†Ô∏è EPUB‰øùÂ≠òÂ§±Ë¥•: {e}')
            
            # ‰øùÂ≠òHTMLÊñá‰ª∂ÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            if self.config.enable_html:
                try:
                    html_result = self._save_html_from_content(safe_name, novel_content, book_download_dir)
                    if html_result == 's':
                        self.log_callback(f'‚úÖ HTMLÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                        results.append('html')
                except Exception as e:
                    self.log_callback(f'‚ö†Ô∏è HTML‰øùÂ≠òÂ§±Ë¥•: {e}')
            
            # ‰øùÂ≠òLaTeXÊñá‰ª∂ÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            if self.config.enable_latex:
                try:
                    latex_result = self._save_latex_from_content(safe_name, novel_content, book_download_dir)
                    if latex_result == 's':
                        self.log_callback(f'‚úÖ LaTeXÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                        results.append('latex')
                        
                        # Â¶ÇÊûú‰πüÂêØÁî®‰∫ÜPDFÔºå‰ªéLaTeXÁîüÊàêPDF
                        if self.config.enable_pdf:
                            try:
                                pdf_result = self._generate_pdf_from_latex(safe_name, book_download_dir)
                                if pdf_result == 's':
                                    self.log_callback(f'‚úÖ PDFÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                                    results.append('pdf')
                            except Exception as e:
                                self.log_callback(f'‚ö†Ô∏è PDFÁîüÊàêÂ§±Ë¥•: {e}')
                except Exception as e:
                    self.log_callback(f'‚ö†Ô∏è LaTeX‰øùÂ≠òÂ§±Ë¥•: {e}')
            elif self.config.enable_pdf:
                # Â¶ÇÊûúÂè™ÂêØÁî®‰∫ÜPDFËÄåÊ≤°ÊúâÂêØÁî®LaTeXÔºåÂÖàÁîüÊàêLaTeXÂÜçËΩ¨PDF
                try:
                    latex_result = self._save_latex_from_content(safe_name, novel_content, book_download_dir)
                    if latex_result == 's':
                        pdf_result = self._generate_pdf_from_latex(safe_name, book_download_dir)
                        if pdf_result == 's':
                            self.log_callback(f'‚úÖ PDFÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                            results.append('pdf')
                            # Âà†Èô§‰∏¥Êó∂LaTeXÊñá‰ª∂
                            try:
                                latex_path = os.path.join(book_download_dir, f'{safe_name}.tex')
                                if os.path.exists(latex_path):
                                    os.remove(latex_path)
                            except:
                                pass
                except Exception as e:
                    self.log_callback(f'‚ö†Ô∏è PDFÁîüÊàêÂ§±Ë¥•: {e}')
            
            # üìù ÁîüÊàêerror.logÊñá‰ª∂ÔºàÂ¶ÇÊûúÊúâÂ§±Ë¥•Á´†ËäÇÔºâ
            self._generate_error_log(book_download_dir)
            
            # ËøîÂõûÁªìÊûú
            if results:
                self.log_callback(f'üéâ ‰∏ãËΩΩÂÆåÊàêÔºÅÂ∑≤‰øùÂ≠òÊ†ºÂºè: {", ".join(results)}')
                if self.failed_chapters:
                    self.log_callback(f'‚ö†Ô∏è Ê≥®ÊÑèÔºöÊúâ {len(self.failed_chapters)} ‰∏™Á´†ËäÇ‰∏ãËΩΩÂ§±Ë¥•ÔºåÂ∑≤ÂàõÂª∫Âç†‰ΩçÊñá‰ª∂ÔºåËØ¶ÊÉÖËØ∑Êü•Áúã error.log')
                return 's'
            else:
                self.log_callback(f'‚ö†Ô∏è Êú™ÂêØÁî®‰ªª‰ΩïËæìÂá∫Ê†ºÂºè')
                return 'err'

        except Exception as e:
            self.log_callback(f'‰∏ãËΩΩÂ§±Ë¥•: {str(e)}')
            return 'err'

    def search_novel(self, keyword: str) -> List[Dict]:
        """
        Search for novels by keyword
        Returns list of novel info dictionaries
        """
        if not keyword:
            return []

        # Use the correct API endpoint from ref_main.py
        url = f"https://api5-normal-lf.fqnovel.com/reading/bookapi/search/page/v/"
        params = {
            "query": keyword,
            "aid": "1967",
            "channel": "0",
            "os_version": "0",
            "device_type": "0",
            "device_platform": "0",
            "iid": "466614321180296",
            "passback": "{(page-1)*10}",
            "version_code": "999"
        }

        try:
            response = req.get(url, params=params, headers=self.headers)
            response.raise_for_status()
            data = response.json()

            if data['code'] == 0 and data['data']:
                return data['data']
            else:
                self.log_callback("Ê≤°ÊúâÊâæÂà∞Áõ∏ÂÖ≥‰π¶Á±ç„ÄÇ")
                return []

        except req.RequestException as e:
            self.log_callback(f"ÁΩëÁªúËØ∑Ê±ÇÂ§±Ë¥•: {str(e)}")
            return []
        except json.JSONDecodeError as e:
            self.log_callback(f"Ëß£ÊûêÊêúÁ¥¢ÁªìÊûúÂ§±Ë¥•: {str(e)}")
            return []
        except Exception as e:
            self.log_callback(f'ÊêúÁ¥¢Â§±Ë¥•: {str(e)}')
            return []

    # ... Additional helper methods would go here ...

    def _get_initial_chapter_id(self) -> int:
        """Get an initial chapter ID for cookie testing"""
        test_novel_id = 7143038691944959011  # Example novel ID
        chapters = self._get_chapter_list(test_novel_id)
        if chapters and len(chapters[1]) > 21:
            return int(random.choice(list(chapters[1].values())[21:]))
        raise Exception("Failed to get initial chapter ID")

    def _get_new_cookie(self, chapter_id: int):
        """Generate new cookie - ‰ºòÂåñÁâàÊú¨ÔºåÂáèÂ∞ëÈ™åËØÅÊ¨°Êï∞"""
        base_timestamp = int(time.time() * 1000)
        
        # Âè™Â∞ùËØï5Ê¨°ÔºåÂáèÂ∞ëÁ≠âÂæÖÊó∂Èó¥
        for i in range(5):
            cookie_id = base_timestamp + random.randint(1000, 999999)
            time.sleep(0.1)  # ÂáèÂ∞ëÂª∂ËøüÂà∞100ms
            self.cookie = f'novel_web_id={cookie_id}'
            
            try:
                if len(self._download_chapter_content(chapter_id, test_mode=True)) > 200:
                    with open(self.cookie_path, 'w', encoding='UTF-8') as f:
                        json.dump(self.cookie, f)
                    return
            except:
                continue
        
        # Âø´ÈÄüÂ§±Ë¥•Ôºå‰ΩøÁî®ÈªòËÆ§cookie
        self.cookie = f'novel_web_id={base_timestamp}'
        print("‚ö†Ô∏è CookieÁîüÊàêÂ§±Ë¥•Ôºå‰ΩøÁî®ÈªòËÆ§ÂÄº")

    def _download_txt(self, novel_id: int) -> str:
        """Download novel in TXT format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nÂºÄÂßã‰∏ãËΩΩ„Ää{name}„ÄãÔºåÁä∂ÊÄÅÔºö{status[0]}')

            # Set book_json_path for the current download
            self.book_json_path = os.path.join(self.bookstore_dir, f'{safe_name}.json')

            # Initialize global variables for this download
            self.zj = {}
            self.cs = 0
            self.tcs = 0

            # Store metadata at the start
            metadata = {
                '_metadata': {
                    'novel_id': str(novel_id),  # Á°Æ‰øùÂ≠òÂÇ®‰∏∫Â≠óÁ¨¶‰∏≤
                    'name': name,
                    'status': status[0] if status else None,
                    'last_updated': time.strftime('%Y-%m-%d %H:%M:%S')
                }
            }

            # Load existing content and merge with metadata
            existing_content = {}
            if os.path.exists(self.book_json_path):
                with open(self.book_json_path, 'r', encoding='UTF-8') as f:
                    existing_content = json.load(f)
                    # Keep existing chapters but update metadata
                    if isinstance(existing_content, dict):
                        existing_content.update(metadata)
            else:
                existing_content = metadata
                # Save initial metadata
                with open(self.book_json_path, 'w', encoding='UTF-8') as f:
                    json.dump(existing_content, f, ensure_ascii=False)

            total_chapters = len(chapters)
            completed_chapters = 0

            # Create CLI progress bar
            with tqdm(total=total_chapters, desc='‰∏ãËΩΩËøõÂ∫¶') as pbar:
                # Download chapters
                content = existing_content.copy()  # Start with existing content including metadata
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter,
                            title,
                            chapter_id,
                            existing_content
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            chapter_content = future.result()
                            if chapter_content:
                                content[chapter_title] = chapter_content
                                # Save progress periodically
                                if completed_chapters % 5 == 0:
                                    with open(self.book_json_path, 'w', encoding='UTF-8') as f:
                                        json.dump(content, f, ensure_ascii=False)
                        except Exception as e:
                            self.log_callback(f'‰∏ãËΩΩÁ´†ËäÇÂ§±Ë¥• {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            '‰∏ãËΩΩËøõÂ∫¶',
                            chapter_title
                        )

                # Save final content
                with open(self.book_json_path, 'w', encoding='UTF-8') as f:
                    json.dump(content, f, ensure_ascii=False)

                # Generate output file
                if self.config.save_mode == SaveMode.SINGLE_TXT:
                    return self._save_single_txt(safe_name, content)
                else:
                    return self._save_split_txt(safe_name, content)

        finally:
            # Send 100% completion if not already sent
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, '‰∏ãËΩΩÂÆåÊàê')

    def _download_epub(self, novel_id: int) -> str:
        """Download novel in EPUB format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nÂºÄÂßã‰∏ãËΩΩ„Ää{name}„ÄãÔºåÁä∂ÊÄÅÔºö{status[0]}')

            # Create EPUB book
            book = epub.EpubBook()
            book.set_title(name)
            book.set_language('zh')

            # Get author info and cover
            author = self._get_author_info(novel_id)
            if author:
                book.add_author(author)
            cover_url = self._get_cover_url(novel_id)
            if cover_url:
                self._add_cover_to_epub(book, cover_url)

            total_chapters = len(chapters)
            completed_chapters = 0

            # Download chapters with progress tracking
            epub_chapters = []
            with tqdm(total=total_chapters, desc='‰∏ãËΩΩËøõÂ∫¶') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter_for_epub,
                            title,
                            chapter_id
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            epub_chapter = future.result()
                            if epub_chapter:
                                epub_chapters.append((chapter_title, epub_chapter))
                        except Exception as e:
                            self.log_callback(f'‰∏ãËΩΩÁ´†ËäÇÂ§±Ë¥• {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            '‰∏ãËΩΩËøõÂ∫¶',
                            chapter_title
                        )

            # Sort chapters by their original order
            epub_chapters.sort(key=lambda x: list(chapters.keys()).index(x[0]))
            for _, chapter in epub_chapters:
                book.add_item(chapter)

            # Add navigation
            book.toc = [chapter for _, chapter in epub_chapters]
            book.spine = ['nav'] + [chapter for _, chapter in epub_chapters]
            book.add_item(epub.EpubNcx())
            book.add_item(epub.EpubNav())

            # Save EPUB file
            epub_path = os.path.join(self.config.save_path, f'{safe_name}.epub')
            epub.write_epub(epub_path, book)
            return 's'

        finally:
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, '‰∏ãËΩΩÂÆåÊàê')

    def _download_chapter(self, title: str, chapter_id: str, existing_content: Dict) -> Optional[str]:
        """Download a single chapter with retries and intelligent error handling"""
        if title in existing_content:
            self.zj[title] = existing_content[title]
            return existing_content[title]

        self.log_callback(f'‰∏ãËΩΩÁ´†ËäÇ: {title}')
        retries = self.config.retry_count
        last_error = None
        
        # ËØ¶ÁªÜËÆ∞ÂΩïÈáçËØïËøáÁ®ã
        self._write_debug_log(f"üîÑ ÂºÄÂßã‰∏ãËΩΩÁ´†ËäÇ„Äå{title}„Äç(ID: {chapter_id}) - ÊúÄÂ§ßÈáçËØïÊ¨°Êï∞: {retries}")
        self._write_debug_log(f"üìã ÈáçËØïÈó¥ÈöîÈÖçÁΩÆ: {self.config.retry_delays}")

        while retries > 0:
            try:
                self._write_debug_log(f"üì° Â∞ùËØï‰∏ãËΩΩÁ´†ËäÇ„Äå{title}„Äç- Ââ©‰ΩôÈáçËØïÊ¨°Êï∞: {retries}")
                
                content = self._download_chapter_content(chapter_id)
                
                # Áªü‰∏ÄÂ§ÑÁêÜÂêÑÁßçÂ§±Ë¥•ÊÉÖÂÜµ
                if content == 'err' or not content or not content.strip():
                    self.tcs += 1
                    
                    if content == 'err':
                        error_msg = "APIËøîÂõûÈîôËØØ"
                    elif not content:
                        error_msg = "ËøîÂõûÂÜÖÂÆπ‰∏∫None"
                    else:
                        error_msg = "ËøîÂõûÂÜÖÂÆπ‰∏∫Á©∫Â≠óÁ¨¶‰∏≤"
                    
                    # Êõ¥Êñ∞ÂèçÁà¨Ê£ÄÊµãÁªüËÆ°
                    self.empty_content_count += 1
                    self.total_empty_count += 1
                    
                    # Ê£ÄÊµãÂèçÁà¨ÊÉÖÂÜµÂπ∂Ë∞ÉÊï¥Á≠ñÁï•
                    if self.empty_content_count >= 3:
                        self.adaptive_delay_multiplier = min(5.0, self.adaptive_delay_multiplier + 0.5)
                        self._write_debug_log(f"üö® ËøûÁª≠Â§±Ë¥• {self.empty_content_count} Ê¨°ÔºåÁñë‰ººÂèçÁà¨Ê£ÄÊµãÔºÅ")
                        self._write_debug_log(f"üìä Ë∞ÉÊï¥Âª∂Êó∂ÂÄçÊï∞Ëá≥: {self.adaptive_delay_multiplier:.1f}")
                        self.log_callback(f"üö® Ê£ÄÊµãÂà∞ËøûÁª≠Â§±Ë¥•ÔºåÂ∑≤Ë∞ÉÊï¥‰∏ãËΩΩÁ≠ñÁï•")
                    
                    # ËÆ∞ÂΩïËØ¶ÁªÜÁöÑÂ§±Ë¥•‰ø°ÊÅØ
                    time_since_success = time.time() - self.last_successful_time
                    self._write_debug_log(f"‚ö†Ô∏è Á´†ËäÇ„Äå{title}„Äç‰∏ãËΩΩÂºÇÂ∏∏: {error_msg}")
                    self._write_debug_log(f"üìä Â§±Ë¥•ÁªüËÆ° - ËøûÁª≠: {self.empty_content_count}, ÊÄªËÆ°: {self.total_empty_count}")
                    self._write_debug_log(f"‚è∞ Ë∑ùÁ¶ª‰∏äÊ¨°ÊàêÂäü: {time_since_success:.1f}Áßí")
                    
                    # Cookie Âà∑Êñ∞Êú∫Âà∂
                    if self.tcs > 7:
                        self.tcs = 0
                        self._write_debug_log(f"üîÑ Ëß¶ÂèëCookieÂà∑Êñ∞ (chapter_id: {chapter_id})")
                        self._get_new_cookie(self.tzj)
                        self.log_callback(f"üîÑ Ê£ÄÊµãÂà∞Â§öÊ¨°Â§±Ë¥•ÔºåÂ∑≤Âà∑Êñ∞Cookie")
                    
                    raise Exception(f"Chapter download failed: {error_msg}")

                # ÊàêÂäüÊó∂Êõ¥Êñ∞ÁªüËÆ°‰ø°ÊÅØ
                self.empty_content_count = 0  # ÈáçÁΩÆËøûÁª≠Á©∫ÂÜÖÂÆπËÆ°Êï∞
                self.last_successful_time = time.time()
                
                # üîÑ Á≠ñÁï•2ÔºöÂ¢ûÂä†ÊàêÂäü‰∏ãËΩΩËÆ°Êï∞Âô®
                self.successful_downloads += 1
                
                # üîÑ Á≠ñÁï•2ÔºöÊ£ÄÊü•ÊòØÂê¶ÈúÄË¶Å‰∏ªÂä®Âà∑Êñ∞CookieÔºàÊØè20‰∏™Á´†ËäÇÔºâ
                if self._should_refresh_cookie_proactively():
                    effective_chapter_id = int(chapter_id) if chapter_id else (self.tzj if self.tzj else 1)
                    self._write_debug_log(f"üîÑ Á≠ñÁï•2ÔºöÁ¨¨{self.successful_downloads}‰∏™Á´†ËäÇÔºå‰∏ªÂä®Âà∑Êñ∞Cookie (chapter_id: {effective_chapter_id})")
                    self._get_new_cookie(effective_chapter_id)
                    self.log_callback(f"üîÑ Á≠ñÁï•2ÔºöÂ∑≤‰∏ãËΩΩ{self.successful_downloads}‰∏™Á´†ËäÇÔºå‰∏ªÂä®Âà∑Êñ∞CookieÔºàÊØè20Á´†ËäÇÁ≠ñÁï•Ôºâ")
                
                # Ê†πÊçÆÊàêÂäüÊÉÖÂÜµË∞ÉÊï¥Âª∂Êó∂ÂÄçÊï∞
                if self.adaptive_delay_multiplier > 1.0:
                    self.adaptive_delay_multiplier = max(1.0, self.adaptive_delay_multiplier - 0.1)
                    self._write_debug_log(f"üìà ‰∏ãËΩΩÊàêÂäüÔºåÈôç‰ΩéÂª∂Êó∂ÂÄçÊï∞Ëá≥: {self.adaptive_delay_multiplier:.1f}")
                
                # üé≠ Á≠ñÁï•3ÔºöÊ®°ÊãüÁúüÂÆûÈòÖËØªË°å‰∏∫
                self._smart_reading_pause(title)
                
                # Ëá™ÈÄÇÂ∫îÂª∂Êó∂
                base_delay_ms = random.randint(self.config.delay[0], self.config.delay[1])
                actual_delay_ms = int(base_delay_ms * self.adaptive_delay_multiplier)
                self._write_debug_log(f"‚è±Ô∏è Á´†ËäÇ„Äå{title}„Äç‰∏ãËΩΩÊàêÂäüÔºåÂª∂Êó∂ {actual_delay_ms}ms (Âü∫Á°Ä:{base_delay_ms}ms √ó ÂÄçÊï∞:{self.adaptive_delay_multiplier:.1f})")
                time.sleep(actual_delay_ms / 1000)

                # Save progress periodically
                self.cs += 1
                if self.cs >= 5:
                    self.cs = 0
                    self._save_progress(title, content)

                self.zj[title] = content
                self._write_debug_log(f"‚úÖ Á´†ËäÇ„Äå{title}„Äç‰∏ãËΩΩÂÆåÊàêÔºåÂÜÖÂÆπÈïøÂ∫¶: {len(content)} Â≠óÁ¨¶")
                return content

            except Exception as e:
                last_error = e
                retries -= 1
                
                self._write_debug_log(f"‚ùå Á´†ËäÇ„Äå{title}„ÄçÈáçËØïÂ§±Ë¥•: {str(e)} (Ââ©‰ΩôÈáçËØï: {retries})")
                
                if retries > 0:
                    # ‰ΩøÁî®ÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑÈáçËØïÈó¥Èöî
                    attempt_index = self.config.retry_count - retries
                    if attempt_index < len(self.config.retry_delays):
                        retry_delay = self.config.retry_delays[attempt_index]
                    else:
                        # Â¶ÇÊûúÈáçËØïÊ¨°Êï∞Ë∂ÖËøáÈÖçÁΩÆÁöÑÈó¥ÈöîÊï∞ÁªÑÔºå‰ΩøÁî®ÊúÄÂêé‰∏Ä‰∏™ÂÄº
                        retry_delay = self.config.retry_delays[-1]
                    
                    # üö® Áî®Êà∑Ë¶ÅÊ±ÇÔºöÊòéÁ°ÆÂ§±Ë¥•ÂéüÂõ†
                    failure_reason = self._get_failure_reason(e)
                    
                    # üö® Á≠ñÁï•2ÔºöÊõ¥ÊøÄËøõÁöÑCookieÂà∑Êñ∞Ê£ÄÊü•ÔºàÂ§±Ë¥•1Ê¨°Â∞±Âà∑Êñ∞Ôºâ
                    cookie_action = ""
                    if self.tcs > 0:  # Á≠ñÁï•2ÔºöÂ§±Ë¥•1Ê¨°Â∞±Â∞ùËØïÂà∑Êñ∞Cookie
                        self.tcs = 0
                        # ‰øÆÂ§çCookieÂà∑Êñ∞Ôºö‰ΩøÁî®ÊúâÊïàÁöÑchapter_id
                        effective_chapter_id = int(chapter_id) if chapter_id else (self.tzj if self.tzj else 1)
                        self._write_debug_log(f"üîÑ Á≠ñÁï•2ÔºöÂ§±Ë¥•1Ê¨°Âç≥Âà∑Êñ∞Cookie (effective_chapter_id: {effective_chapter_id})")
                        self._get_new_cookie(effective_chapter_id)
                        cookie_action = " (Á≠ñÁï•2: Â∑≤Âà∑Êñ∞Cookie)"
                    
                    self._write_debug_log(f"‚è≥ Á≠âÂæÖ {retry_delay}s ÂêéÈáçËØï... (ÈáçËØïÈó¥ÈöîÈÖçÁΩÆÁ¥¢Âºï: {attempt_index})")
                    
                    # üö® Áî®Êà∑Ë¶ÅÊ±ÇÔºöÂåÖÂê´ÂÖ∑‰ΩìÂ§±Ë¥•ÂéüÂõ†ÁöÑÈáçËØïÊó•Âøó
                    self.log_callback(f"‚ö†Ô∏è Á´†ËäÇ„Äå{title}„Äç‰∏ãËΩΩÂ§±Ë¥• ({failure_reason})Ôºå{retry_delay}sÂêéÈáçËØï (Ââ©‰Ωô{retries}Ê¨°){cookie_action}")
                    
                    # ÂøÖË¶ÅÊó∂ËæìÂá∫ÂÆåÊï¥ÂìçÂ∫î
                    if "ÂÜÖÂÆπ‰∏∫Á©∫" not in failure_reason and "ÁΩëÁªú" not in failure_reason:
                        self._write_debug_log(f"üì• ÈáçËØïÂâçËé∑ÂèñÂÆåÊï¥ÂìçÂ∫îÂÜÖÂÆπ:")
                        try:
                            debug_content = self._download_chapter_content(int(chapter_id), test_mode=True)
                            self._write_debug_log(f"üì• ÂÆåÊï¥ÂìçÂ∫î: {repr(debug_content[:1000])}{'...' if len(debug_content) > 1000 else ''}")
                        except:
                            self._write_debug_log(f"üì• Êó†Ê≥ïËé∑ÂèñÂìçÂ∫îÂÜÖÂÆπ")
                    
                    time.sleep(retry_delay)
                else:
                    self._write_debug_log(f"üí• Á´†ËäÇ„Äå{title}„ÄçÊúÄÁªà‰∏ãËΩΩÂ§±Ë¥•: {str(e)}")
                    self.log_callback(f'‰∏ãËΩΩÂ§±Ë¥• {title}: {str(e)}')

        if last_error:
            raise last_error
        return None

    def _download_chapter_for_epub(self, title: str, chapter_id: str) -> Optional[epub.EpubHtml]:
        """Download and format chapter for EPUB"""
        content = self._download_chapter(title, chapter_id, {})
        if not content:
            return None

        chapter = epub.EpubHtml(
            title=title,
            file_name=f'chapter_{chapter_id}.xhtml',
            lang='zh'
        )

        # ‰ΩøÁî®<p>Ê†áÁ≠æÂåÖË£πÊØè‰∏™ÊÆµËêΩÔºåÁ°Æ‰øùÊ≤°ÊúâÂ§ö‰ΩôÁöÑÊç¢Ë°åÁ¨¶
        formatted_content = ''.join(f'<p>{para.strip()}</p>' for para in content.split('\n') if para.strip())
        chapter.content = f'<h1>{title}</h1>{formatted_content}'
        return chapter

    def _save_single_txt(self, name: str, content: dict) -> str:
        """Save all chapters to a single TXT file"""
        output_path = os.path.join(self.download_dir, f'{name}.txt')  # ‰øùÂ≠òÂà∞‰∏ãËΩΩÁõÆÂΩï
        fg = '\n' + self.config.kgf * self.config.kg

        with open(output_path, 'w', encoding='UTF-8') as f:
            for title, chapter_content in content.items():
                # Ë∑≥ËøáÂÖÉÊï∞ÊçÆÈ°π
                if title.startswith('_'):
                    continue
                    
                f.write(f'\n{title}{fg}')
                if self.config.kg == 0:
                    f.write(f'{chapter_content}\n')
                else:
                    # Â∞ÜÊõøÊç¢ÁªìÊûúÂ≠òÂÇ®Âú®‰∏Ä‰∏™ÂèòÈáè‰∏≠
                    modified_content = chapter_content.replace("\n", fg)
                    # Âú® f-string ‰∏≠‰ΩøÁî®Ëøô‰∏™ÂèòÈáè
                    f.write(f'{modified_content}\n')
        
        return 's'  # ËøîÂõûÊàêÂäüÊ†áËØÜ

    def _save_single_txt_to_folder(self, name: str, content: dict, output_dir: str) -> str:
        """Save all chapters to a single TXT file in specified folder with smart chapter ordering"""
        output_path = os.path.join(output_dir, f'{name}.txt')
        fg = '\n' + self.config.kgf * self.config.kg

        # ÊèêÂèñÊâÄÊúâÁ´†ËäÇÂèäÂÖ∂ÁºñÂè∑ÔºåË∑≥ËøáÂÖÉÊï∞ÊçÆ
        chapters_with_numbers = []
        for title, chapter_content in content.items():
            if title.startswith('_'):
                continue
            chapter_num = self._extract_chapter_number(title)
            chapters_with_numbers.append((chapter_num, title, chapter_content))
        
        # ÊåâÁ´†ËäÇÁºñÂè∑ÊéíÂ∫è
        chapters_with_numbers.sort(key=lambda x: x[0])
        
        self.log_callback(f'ÊåâÈ°∫Â∫èÂêàÂπ∂Á´†ËäÇ: ÂÖ± {len(chapters_with_numbers)} Á´†')
        
        with open(output_path, 'w', encoding='UTF-8') as f:
            if not chapters_with_numbers:
                f.write('ÊöÇÊó†Á´†ËäÇÂÜÖÂÆπ\n')
                return 's'
            
            # Ëé∑ÂèñÁ´†ËäÇÁºñÂè∑ËåÉÂõ¥
            min_chapter = chapters_with_numbers[0][0]
            max_chapter = chapters_with_numbers[-1][0]
            
            # ÂàõÂª∫Á´†ËäÇÂ≠óÂÖ∏‰ª•‰æøÂø´ÈÄüÊü•Êâæ
            chapter_dict = {num: (title, content) for num, title, content in chapters_with_numbers}
            
            # ÊåâÈ°∫Â∫èÂÜôÂÖ•Á´†ËäÇÔºåÂ§ÑÁêÜÁº∫Â§±Á´†ËäÇ
            for chapter_num in range(min_chapter, max_chapter + 1):
                if chapter_num in chapter_dict:
                    title, chapter_content = chapter_dict[chapter_num]
                    f.write(f'\n{title}{fg}')
                    if self.config.kg == 0:
                        f.write(f'{chapter_content}\n')
                    else:
                        modified_content = chapter_content.replace("\n", fg)
                        f.write(f'{modified_content}\n')
                else:
                    # Â§ÑÁêÜÁº∫Â§±Á´†ËäÇ
                    missing_title = f'Á¨¨ {chapter_num} Á´† ÂΩìÂâçÁ´†ËäÇÁº∫Â§±'
                    f.write(f'\n{missing_title}{fg}')
                    f.write(f'Êä±Ê≠âÔºåÂΩìÂâçÁ´†ËäÇ‰∏ãËΩΩÂ§±Ë¥•ÊàñÊöÇ‰∏çÂèØÁî®\n')
                    self.log_callback(f'‚ö†Ô∏è Ê£ÄÊµãÂà∞Áº∫Â§±Á´†ËäÇ: Á¨¨ {chapter_num} Á´†')
        
        return 's'  # ËøîÂõûÊàêÂäüÊ†áËØÜ

    def _save_split_txt_to_folder(self, name: str, content: Dict, output_dir: str) -> str:
        """Save each chapter to a separate TXT file in specified folder"""
        chapter_output_dir = os.path.join(output_dir, name)
        os.makedirs(chapter_output_dir, exist_ok=True)

        for title, chapter_content in content.items():
            # Ë∑≥ËøáÂÖÉÊï∞ÊçÆÈ°π
            if title.startswith('_'):
                continue
                
            chapter_path = os.path.join(
                chapter_output_dir,
                f'{self._sanitize_filename(title)}.txt'
            )
            if self.config.kg == 0:
                replacement_content = chapter_content
            else:
                replacement_content = chapter_content.replace("\n", self.config.kgf * self.config.kg)

            with open(chapter_path, 'w', encoding='UTF-8') as f:
                f.write(f'{replacement_content}\n')

        return 's'

    def _save_split_txt(self, name: str, content: Dict) -> str:
        """Save each chapter to a separate TXT file"""
        output_dir = os.path.join(self.download_dir, name)  # ‰øùÂ≠òÂà∞‰∏ãËΩΩÁõÆÂΩï
        os.makedirs(output_dir, exist_ok=True)

        for title, chapter_content in content.items():
            chapter_path = os.path.join(
                output_dir,
                f'{self._sanitize_filename(title)}.txt'
            )
            if self.config.kg == 0:
                replacement_content = chapter_content
            else:
                replacement_content = chapter_content.replace("\n", self.config.kgf * self.config.kg)

            with open(chapter_path, 'w', encoding='UTF-8') as f:
                f.write(f'{replacement_content}\n')

        return 's'

    def update_all_novels(self):
        """Update all novels in records"""
        if not os.path.exists(self.record_path):
            self.log_callback("No novels to update")
            return

        with open(self.record_path, 'r', encoding='UTF-8') as f:
            novels = json.load(f)

        for novel_id in novels:
            self.log_callback(f"Updating novel {novel_id}")
            status = self.download_novel(novel_id)
            if not status:
                novels.remove(novel_id)

        with open(self.record_path, 'w', encoding='UTF-8') as f:
            json.dump(novels, f)

    def _download_html(self, novel_id: int) -> str:
        """Download novel in HTML format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            html_dir = os.path.join(self.config.save_path, f"{safe_name}(html)")
            os.makedirs(html_dir, exist_ok=True)

            self.log_callback(f'\nÂºÄÂßã‰∏ãËΩΩ„Ää{name}„ÄãÔºåÁä∂ÊÄÅÔºö{status[0]}')

            # Create index.html
            toc_content = self._create_html_index(name, chapters)
            with open(os.path.join(html_dir, "index.html"), "w", encoding='UTF-8') as f:
                f.write(toc_content)

            total_chapters = len(chapters)
            completed_chapters = 0

            # Download chapters with progress tracking
            with tqdm(total=total_chapters, desc='‰∏ãËΩΩËøõÂ∫¶') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter_for_html,
                            title,
                            chapter_id,
                            html_dir,
                            list(chapters.keys())
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            future.result()
                        except Exception as e:
                            self.log_callback(f'‰∏ãËΩΩÁ´†ËäÇÂ§±Ë¥• {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            '‰∏ãËΩΩËøõÂ∫¶',
                            chapter_title
                        )

            return 's'

        finally:
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, '‰∏ãËΩΩÂÆåÊàê')

    def _download_latex(self, novel_id: int) -> str:
        """Download novel in LaTeX format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nÂºÄÂßã‰∏ãËΩΩ„Ää{name}„ÄãÔºåÁä∂ÊÄÅÔºö{status[0]}')

            # Create LaTeX document header
            latex_content = self._create_latex_header(name)

            total_chapters = len(chapters)
            completed_chapters = 0
            chapter_contents = []

            # Download chapters with progress tracking
            with tqdm(total=total_chapters, desc='‰∏ãËΩΩËøõÂ∫¶') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter_for_latex,
                            title,
                            chapter_id
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            chapter_content = future.result()
                            if chapter_content:
                                chapter_contents.append((chapter_title, chapter_content))
                        except Exception as e:
                            self.log_callback(f'‰∏ãËΩΩÁ´†ËäÇÂ§±Ë¥• {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            '‰∏ãËΩΩËøõÂ∫¶',
                            chapter_title
                        )

            # Sort chapters and add to document
            chapter_contents.sort(key=lambda x: list(chapters.keys()).index(x[0]))
            for title, content in chapter_contents:
                latex_content += self._format_latex_chapter(title, content)

            # Add document footer and save
            latex_content += "\n\\end{document}"
            latex_path = os.path.join(self.config.save_path, f'{safe_name}.tex')
            with open(latex_path, 'w', encoding='UTF-8') as f:
                f.write(latex_content)

            return 's'

        finally:
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, '‰∏ãËΩΩÂÆåÊàê')

    def _create_html_index(self, title: str, chapters: Dict[str, str]) -> str:
        """Create HTML index page with CSS styling"""
        return f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title} - ÁõÆÂΩï</title>
    <style>
        :root {{
            --bg-color: #f5f5f5;
            --text-color: #333;
            --link-color: #007bff;
            --hover-color: #0056b3;
        }}
        @media (prefers-color-scheme: dark) {{
            :root {{
                --bg-color: #222;
                --text-color: #fff;
                --link-color: #66b0ff;
                --hover-color: #99ccff;
            }}
        }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: var(--bg-color);
            color: var(--text-color);
        }}
        h1 {{
            text-align: center;
            margin-bottom: 30px;
        }}
        .toc {{
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
        }}
        .toc a {{
            color: var(--link-color);
            text-decoration: none;
            display: block;
            padding: 8px 0;
            transition: all 0.2s;
        }}
        .toc a:hover {{
            color: var(--hover-color);
            transform: translateX(10px);
        }}
    </style>
</head>
<body>
    <h1>{title}</h1>
    <div class="toc">
        {''.join(f'<a href="{self._sanitize_filename(title)}.html">{title}</a>' for title in chapters.keys())}
    </div>
</body>
</html>
"""

    def _create_latex_header(self, title: str) -> str:
        """Create LaTeX document header"""
        return f"""\\documentclass[12pt,a4paper]{{article}}
\\usepackage{{ctex}}
\\usepackage{{geometry}}
\\usepackage{{hyperref}}
\\usepackage{{bookmark}}

\\geometry{{
    top=2.54cm,
    bottom=2.54cm,
    left=3.18cm,
    right=3.18cm
}}

\\title{{{title}}}
\\author{{Generated by NovelDownloader}}
\\date{{\\today}}

\\begin{{document}}
\\maketitle
\\tableofcontents
\\newpage
"""

    def _download_chapter_for_html(self, title: str, chapter_id: str, output_dir: str, all_titles: List[str]) -> None:
        """Download and format chapter for HTML"""
        content = self._download_chapter(title, chapter_id, {})
        if not content:
            return

        current_index = all_titles.index(title)
        prev_link = f'<a href="{self._sanitize_filename(all_titles[current_index - 1])}.html">‰∏ä‰∏ÄÁ´†</a>' if current_index > 0 else ''
        next_link = f'<a href="{self._sanitize_filename(all_titles[current_index + 1])}.html">‰∏ã‰∏ÄÁ´†</a>' if current_index < len(
            all_titles) - 1 else ''

        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        /* ... Same CSS variables as index ... */
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.8;
            margin: 0;
            padding: 20px;
            background-color: var(--bg-color);
            color: var(--text-color);
            max-width: 800px;
            margin: 0 auto;
        }}
        .navigation {{
            display: flex;
            justify-content: space-between;
            padding: 20px 0;
            position: sticky;
            top: 0;
            background-color: var(--bg-color);
        }}
        .navigation a {{
            color: var(--link-color);
            text-decoration: none;
            padding: 8px 16px;
            border: 1px solid var(--link-color);
            border-radius: 4px;
        }}
        .content {{
            text-indent: 2em;
            margin-bottom: 40px;
        }}
    </style>
</head>
<body>
    <div class="navigation">
        <a href="index.html">ÁõÆÂΩï</a>
        {prev_link}
        {next_link}
    </div>
    <h1>{title}</h1>
    <div class="content">
        {content.replace(chr(10), '<br>' + self.config.kgf * self.config.kg)}
    </div>
    <div class="navigation">
        <a href="index.html">ÁõÆÂΩï</a>
        {prev_link}
        {next_link}
    </div>
</body>
</html>
"""

        with open(os.path.join(output_dir, f"{self._sanitize_filename(title)}.html"), "w", encoding='UTF-8') as f:
            f.write(html_content)

    def _download_chapter_for_latex(self, title: str, chapter_id: str) -> Optional[str]:
        """Download and format chapter for LaTeX"""
        content = self._download_chapter(title, chapter_id, {})
        if not content:
            return None
        return self._format_latex_chapter(title, content)

    def _format_latex_chapter(self, title: str, content: str) -> str:
        """Format chapter content for LaTeX"""
        # Escape special LaTeX characters
        special_chars = ['\\', '{', '}', '&', '#', '$', '^', '_', '~', '%']
        for char in special_chars:
            content = content.replace(char, f'\\{char}')
            title = title.replace(char, f'\\{char}')

        # Format content with proper spacing
        content = content.replace('\n', '\n\n' + self.config.kgf * self.config.kg)

        return f"""
\\section{{{title}}}
{content}
"""

    def _test_cookie(self, chapter_id: int, cookie: str) -> str:
        """Test if cookie is valid"""
        self.cookie = cookie
        if len(self._download_chapter_content(chapter_id, test_mode=True)) > 200:
            return 's'
        return 'err'

    def _get_chapter_list(self, novel_id: int) -> tuple:
        """Get novel info and chapter list with detailed logging"""
        url = f'https://fanqienovel.com/page/{novel_id}'
        
        # ËØ¶ÁªÜËÆ∞ÂΩïËØ∑Ê±Ç‰ø°ÊÅØ
        self._write_debug_log(f"üåê ËØ∑Ê±ÇÁ´†ËäÇÂàóË°®: {url}")
        self._write_debug_log(f"üîë ‰ΩøÁî®Cookie: {self.cookie}")
        
        response = req.get(url, headers=self.headers)
        self._write_debug_log(f"üì° ÂìçÂ∫îÁä∂ÊÄÅÁ†Å: {response.status_code}")
        self._write_debug_log(f"üìè ÂìçÂ∫îÂÜÖÂÆπÈïøÂ∫¶: {len(response.text)} Â≠óÁ¨¶")
        
        ele = etree.HTML(response.text)

        chapters = {}
        a_elements = ele.xpath('//div[@class="chapter"]/div/a')
        self._write_debug_log(f"üìö ÊâæÂà∞Á´†ËäÇÂÖÉÁ¥†Êï∞Èáè: {len(a_elements)}")
        
        if not a_elements:
            self._write_debug_log("‚ùå Êú™ÊâæÂà∞‰ªª‰ΩïÁ´†ËäÇÂÖÉÁ¥†ÔºåÂèØËÉΩÊòØÈ°µÈù¢ÁªìÊûÑÂèòÂåñÊàñËÆøÈóÆÂèóÈôê")
            return 'err', {}, []

        null_title_count = 0
        valid_chapters = 0
        
        for i, a in enumerate(a_elements):
            href = a.xpath('@href')
            if not href:
                self._write_debug_log(f"‚ö†Ô∏è Á¨¨{i+1}‰∏™Á´†ËäÇÂÖÉÁ¥†Áº∫Â∞ëhrefÂ±ûÊÄß")
                continue
                
            chapter_title = a.text
            chapter_id = href[0].split('/')[-1]
            
            # ËØ¶ÁªÜËÆ∞ÂΩïÊØè‰∏™Á´†ËäÇÁöÑ‰ø°ÊÅØ
            if not chapter_title or not chapter_title.strip():
                null_title_count += 1
                self._write_debug_log(f"üö® Á¨¨{i+1}‰∏™Á´†ËäÇÊ†áÈ¢ò‰∏∫Á©∫! Á´†ËäÇID: {chapter_id}")
                self._write_debug_log(f"   - ÂÖÉÁ¥†HTML: {etree.tostring(a, encoding='unicode')[:200]}")
                # ‰∏çÁîüÊàêÂÅáÊ†áÈ¢òÔºå‰øùÁïôÈóÆÈ¢òËÆ©Áî®Êà∑Áü•ÈÅì
                continue
            else:
                chapters[chapter_title.strip()] = chapter_id
                valid_chapters += 1
                if i < 5 or i % 100 == 0:  # ËÆ∞ÂΩïÂâç5‰∏™ÂíåÊØè100‰∏™Á´†ËäÇ
                    self._write_debug_log(f"‚úÖ Á´†ËäÇ{i+1}: „Äå{chapter_title.strip()}„Äç-> ID: {chapter_id}")

        self._write_debug_log(f"üìä Á´†ËäÇÁªüËÆ°: ÊúâÊïàÁ´†ËäÇ {valid_chapters} ‰∏™ÔºåÁ©∫Ê†áÈ¢òÁ´†ËäÇ {null_title_count} ‰∏™")
        
        if null_title_count > 0:
            self.log_callback(f"‚ö†Ô∏è ÂèëÁé∞ {null_title_count} ‰∏™Á©∫Ê†áÈ¢òÁ´†ËäÇÔºåËøô‰∫õÁ´†ËäÇÂ∞ÜË¢´Ë∑≥Ëøá")
            self.log_callback(f"üí° Âª∫ËÆÆÊ£ÄÊü•ÁΩëÁªúËøûÊé•ÊàñÁ®çÂêéÈáçËØïÔºå‰πüÂèØËÉΩÊòØÁΩëÁ´ôÂèçÁà¨Ëô´Êú∫Âà∂")

        title = ele.xpath('//h1/text()')
        status = ele.xpath('//span[@class="info-label-yellow"]/text()')
        
        self._write_debug_log(f"üìñ Â∞èËØ¥Ê†áÈ¢ò: {title[0] if title else 'Êú™ÊâæÂà∞'}")
        self._write_debug_log(f"üìä Â∞èËØ¥Áä∂ÊÄÅ: {status[0] if status else 'Êú™ÊâæÂà∞'}")

        if not title or not status:
            self._write_debug_log("‚ùå Êó†Ê≥ïËé∑ÂèñÂ∞èËØ¥Âü∫Êú¨‰ø°ÊÅØÔºàÊ†áÈ¢òÊàñÁä∂ÊÄÅÔºâ")
            return 'err', {}, []

        return title[0], chapters, status

    def _download_chapter_content(self, chapter_id: int, test_mode: bool = False) -> str:
        """Download content with fallback and enhanced error handling"""
        # üé≠ Á≠ñÁï•3Ôºö‰ΩøÁî®ÈöèÊú∫ÂåñÁöÑÁúüÂÆûËØ∑Ê±ÇÂ§¥
        headers = self._get_randomized_headers()
        headers['cookie'] = self.cookie

        for attempt in range(3):
            try:
                self._write_debug_log(f"üì° Â∞ùËØïÊñπÊ≥ï1: Ê†áÂáÜAPI (Á´†ËäÇID: {chapter_id}, Â∞ùËØï: {attempt + 1}/3)")
                
                # Try primary method
                response = req.get(
                    f'https://fanqienovel.com/reader/{chapter_id}',
                    headers=headers,
                    timeout=10
                )
                response.raise_for_status()
                
                self._write_debug_log(f"üì• APIÂìçÂ∫îÁä∂ÊÄÅ: {response.status_code}, ÂÜÖÂÆπÈïøÂ∫¶: {len(response.text)}")

                content = '\n'.join(
                    etree.HTML(response.text).xpath(
                        '//div[@class="muye-reader-content noselect"]//p/text()'
                    )
                )
                
                self._write_debug_log(f"üìù XPathÊèêÂèñÁªìÊûúÈïøÂ∫¶: {len(content)} Â≠óÁ¨¶")

                if test_mode:
                    return content

                # Ê£ÄÊü•ÂÜÖÂÆπÊòØÂê¶ÊúâÊïà
                if not content or len(content.strip()) < 10:
                    self._write_debug_log(f"‚ö†Ô∏è ÊñπÊ≥ï1ÂÜÖÂÆπËøáÁü≠Êàñ‰∏∫Á©∫: {repr(content[:100])}")
                    raise Exception(f"Content too short or empty (length: {len(content)})")

                try:
                    decoded = self._decode_content(content)
                    self._write_debug_log(f"‚úÖ ÂÜÖÂÆπËß£Á†ÅÊàêÂäüÔºåÊúÄÁªàÈïøÂ∫¶: {len(decoded)} Â≠óÁ¨¶")
                    return decoded
                except Exception as decode_err:
                    self._write_debug_log(f"‚ö†Ô∏è Ëß£Á†ÅÊ®°Âºè0Â§±Ë¥•: {str(decode_err)}")
                    # Try alternative decoding mode
                    try:
                        decoded = self._decode_content(content, mode=1)
                        self._write_debug_log(f"‚úÖ Ëß£Á†ÅÊ®°Âºè1ÊàêÂäüÔºåÊúÄÁªàÈïøÂ∫¶: {len(decoded)} Â≠óÁ¨¶")
                        return decoded
                    except Exception as decode_err2:
                        self._write_debug_log(f"‚ö†Ô∏è Ëß£Á†ÅÊ®°Âºè1Â§±Ë¥•: {str(decode_err2)}")
                        # Fallback HTML processing
                        self._write_debug_log(f"üîÑ ‰ΩøÁî®ÂêéÂ§áHTMLÂ§ÑÁêÜ")
                        content = content[6:]
                        tmp = 1
                        result = ''
                        for i in content:
                            if i == '<':
                                tmp += 1
                            elif i == '>':
                                tmp -= 1
                            elif tmp == 0:
                                result += i
                            elif tmp == 1 and i == 'p':
                                result = (result + '\n').replace('\n\n', '\n')
                        
                        if result and len(result.strip()) > 10:
                            self._write_debug_log(f"‚úÖ ÂêéÂ§áÂ§ÑÁêÜÊàêÂäüÔºåÊúÄÁªàÈïøÂ∫¶: {len(result)} Â≠óÁ¨¶")
                            return result
                        else:
                            raise Exception(f"Fallback processing failed, result too short: {len(result)}")

            except Exception as e:
                self._write_debug_log(f"‚ùå ÊñπÊ≥ï1Â§±Ë¥•: {str(e)}")
                
                # Try alternative API endpoint
                try:
                    self._write_debug_log(f"üîÑ Â∞ùËØïÊñπÊ≥ï2: Â§áÁî®API (Á´†ËäÇID: {chapter_id})")
                    
                    response = req.get(
                        f'https://fanqienovel.com/api/reader/full?itemId={chapter_id}',
                        headers=headers,
                        timeout=10
                    )
                    response.raise_for_status()
                    
                    self._write_debug_log(f"üì• Â§áÁî®APIÂìçÂ∫îÁä∂ÊÄÅ: {response.status_code}")
                    
                    data = json.loads(response.text)
                    content = data['data']['chapterData']['content']
                    
                    self._write_debug_log(f"üìù Â§áÁî®APIÂÜÖÂÆπÈïøÂ∫¶: {len(content)} Â≠óÁ¨¶")

                    if test_mode:
                        return content
                    
                    # Ê£ÄÊü•ÂÜÖÂÆπÊòØÂê¶ÊúâÊïà
                    if not content or len(content.strip()) < 10:
                        self._write_debug_log(f"‚ö†Ô∏è ÊñπÊ≥ï2ÂÜÖÂÆπËøáÁü≠Êàñ‰∏∫Á©∫: {repr(content[:100])}")
                        raise Exception(f"Backup API content too short (length: {len(content)})")

                    decoded = self._decode_content(content)
                    self._write_debug_log(f"‚úÖ Â§áÁî®APIËß£Á†ÅÊàêÂäüÔºåÊúÄÁªàÈïøÂ∫¶: {len(decoded)} Â≠óÁ¨¶")
                    return decoded
                    
                except Exception as backup_err:
                    self._write_debug_log(f"‚ùå ÊñπÊ≥ï2‰πüÂ§±Ë¥•: {str(backup_err)}")
                    
                    if attempt == 2:  # Last attempt
                        self._write_debug_log(f"üí• ÊâÄÊúâÊñπÊ≥ïÂùáÂ§±Ë¥•ÔºåÁ´†ËäÇID: {chapter_id}")
                        if test_mode:
                            return 'err'
                        raise Exception(f"All download methods failed. Primary: {str(e)}, Backup: {str(backup_err)}")
                    
                    self._write_debug_log(f"‚è≥ Á≠âÂæÖ1ÁßíÂêéÈáçËØï...")
                    time.sleep(1)

    def _get_author_info(self, novel_id: int) -> Optional[str]:
        """Get author information from novel page"""
        url = f'https://fanqienovel.com/page/{novel_id}'
        try:
            response = req.get(url, headers=self.headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            script_tag = soup.find('script', type="application/ld+json")
            if script_tag:
                data = json.loads(script_tag.string)
                if 'author' in data:
                    return data['author'][0]['name']
        except Exception as e:
            self.log_callback(f"Ëé∑Âèñ‰ΩúËÄÖ‰ø°ÊÅØÂ§±Ë¥•: {str(e)}")
        return None

    def _get_cover_url(self, novel_id: int) -> Optional[str]:
        """Get cover image URL from novel page"""
        url = f'https://fanqienovel.com/page/{novel_id}'
        try:
            response = req.get(url, headers=self.headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            script_tag = soup.find('script', type="application/ld+json")
            if script_tag:
                data = json.loads(script_tag.string)
                if 'image' in data:
                    return data['image'][0]
        except Exception as e:
            self.log_callback(f"Ëé∑ÂèñÂ∞ÅÈù¢ÂõæÁâáÂ§±Ë¥•: {str(e)}")
        return None

    def _add_cover_to_epub(self, book: epub.EpubBook, cover_url: str):
        """Add cover image to EPUB book"""
        try:
            response = req.get(cover_url)
            if response.status_code == 200:
                book.set_cover('cover.jpg', response.content)

                # Add cover page
                cover_content = f'''
                    <div style="text-align: center; padding: 0; margin: 0;">
                        <img src="cover.jpg" alt="Cover" style="max-width: 100%; height: auto;"/>
                    </div>
                '''
                cover_page = epub.EpubHtml(
                    title='Cover',
                    file_name='cover.xhtml',
                    content=cover_content,
                    media_type='image/jpeg'
                )
                book.add_item(cover_page)
                book.spine.insert(0, cover_page)
        except Exception as e:
            self.log_callback(f"Ê∑ªÂä†Â∞ÅÈù¢Â§±Ë¥•: {str(e)}")

    def _extract_chapter_number(self, title: str) -> int:
        """Extract chapter number from title for sorting"""
        # Â∞ùËØïÊèêÂèñÁ´†ËäÇÁºñÂè∑ÁöÑÂ§öÁßçÊ®°Âºè
        patterns = [
            r'Á¨¨\s*(\d+)\s*Á´†',      # Á¨¨1Á´†, Á¨¨ 1 Á´†
            r'Á¨¨\s*([‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅÁôæÂçÉ‰∏á]+)\s*Á´†',  # Á¨¨‰∏ÄÁ´†, Á¨¨‰∫åÂçÅÁ´†
            r'Á´†ËäÇ?\s*(\d+)',        # Á´†ËäÇ1, Á´†1  
            r'(\d+)\s*Á´†',           # 1Á´†
            r'Chapter\s*(\d+)',      # Chapter 1
            r'Ch\s*(\d+)',           # Ch 1
            r'^(\d+)',               # ÂºÄÂ§¥ÁöÑÊï∞Â≠ó
        ]
        
        for pattern in patterns:
            match = re.search(pattern, title, re.IGNORECASE)
            if match:
                chapter_num_str = match.group(1)
                
                # Â§ÑÁêÜ‰∏≠ÊñáÊï∞Â≠ó
                if chapter_num_str in ['‰∏Ä', '‰∫å', '‰∏â', 'Âõõ', '‰∫î', 'ÂÖ≠', '‰∏É', 'ÂÖ´', '‰πù', 'ÂçÅ']:
                    chinese_numbers = {'‰∏Ä': 1, '‰∫å': 2, '‰∏â': 3, 'Âõõ': 4, '‰∫î': 5, 
                                     'ÂÖ≠': 6, '‰∏É': 7, 'ÂÖ´': 8, '‰πù': 9, 'ÂçÅ': 10}
                    return chinese_numbers.get(chapter_num_str, 0)
                
                # Â§ÑÁêÜÈòøÊãâ‰ºØÊï∞Â≠ó
                try:
                    return int(chapter_num_str)
                except ValueError:
                    continue
        
        # Â¶ÇÊûúÊ≤°ÊúâÊâæÂà∞Á´†ËäÇÁºñÂè∑ÔºåËøîÂõû0ÔºàÂ∞ÜÊéíÂú®ÊúÄÂâçÈù¢Ôºâ
        return 0

    def _get_failure_reason(self, exception: Exception) -> str:
        """Ê†πÊçÆÂºÇÂ∏∏Á±ªÂûãËøîÂõûÁî®Êà∑ÂèãÂ•ΩÁöÑÂ§±Ë¥•ÂéüÂõ†"""
        error_str = str(exception).lower()
        
        if "chapter download failed" in error_str:
            if "apiËøîÂõûÈîôËØØ" in error_str:
                return "APIËøîÂõûÈîôËØØ"
            elif "ËøîÂõûÂÜÖÂÆπ‰∏∫none" in error_str:
                return "ÂìçÂ∫îÂÜÖÂÆπ‰∏∫Á©∫(None)"
            elif "ËøîÂõûÂÜÖÂÆπ‰∏∫Á©∫Â≠óÁ¨¶‰∏≤" in error_str:
                return "ÂìçÂ∫îÂÜÖÂÆπ‰∏∫Á©∫Â≠óÁ¨¶‰∏≤"
            else:
                return "ÂÜÖÂÆπËé∑ÂèñÂ§±Ë¥•"
        elif "timeout" in error_str or "timed out" in error_str:
            return "ÁΩëÁªúË∂ÖÊó∂"
        elif "connection" in error_str:
            return "ÁΩëÁªúËøûÊé•ÈîôËØØ"
        elif "404" in error_str:
            return "Á´†ËäÇ‰∏çÂ≠òÂú®(404)"
        elif "403" in error_str:
            return "ËÆøÈóÆË¢´ÊãíÁªù(403)"
        elif "500" in error_str:
            return "ÊúçÂä°Âô®ÈîôËØØ(500)"
        elif "nonetype" in error_str and "pathlike" in error_str:
            return "Êñá‰ª∂Ë∑ØÂæÑÈîôËØØ(ÂèòÈáè‰∏∫None)"
        elif "decode" in error_str or "encoding" in error_str:
            return "ÂÜÖÂÆπËß£Á†ÅÈîôËØØ"
        elif "json" in error_str:
            return "JSONËß£ÊûêÈîôËØØ"
        else:
            # üö® Áî®Êà∑Ë¶ÅÊ±ÇÔºö‰∏çË¶ÅÊà™Êñ≠ÈîôËØØ‰ø°ÊÅØÔºåÊòæÁ§∫ÂÆåÊï¥ÂÜÖÂÆπ
            return f"Êú™Áü•ÈîôËØØ: {str(exception)}"

    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize filename for different platforms with enhanced debugging"""
        self._write_debug_log(f"üîß _sanitize_filenameË∞ÉÁî® - ËæìÂÖ•: {repr(filename)} (Á±ªÂûã: {type(filename).__name__})")
        
        # Â§ÑÁêÜNoneÊàñÁ©∫ÂÄºÁöÑÊÉÖÂÜµ
        if filename is None:
            self._write_debug_log(f"‚ùå _sanitize_filename: ËæìÂÖ•‰∏∫None!")
            result = "ERROR_None_filename"
            self._write_debug_log(f"üîß _sanitize_filenameËøîÂõû: {repr(result)}")
            return result
        
        if not filename:
            self._write_debug_log(f"‚ùå _sanitize_filename: ËæìÂÖ•‰∏∫Á©∫Â≠óÁ¨¶‰∏≤!")
            result = "ERROR_Empty_filename"
            self._write_debug_log(f"üîß _sanitize_filenameËøîÂõû: {repr(result)}")
            return result
        
        # Á°Æ‰øùËæìÂÖ•ÊòØÂ≠óÁ¨¶‰∏≤Á±ªÂûã
        if not isinstance(filename, str):
            self._write_debug_log(f"‚ùå _sanitize_filename: ËæìÂÖ•‰∏çÊòØÂ≠óÁ¨¶‰∏≤Á±ªÂûã: {type(filename)}")
            filename_str = str(filename)
            self._write_debug_log(f"üîÑ ËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤: {repr(filename_str)}")
            filename = filename_str
        
        original_filename = filename
        illegal_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*']
        illegal_chars_rep = ['Ôºú', 'Ôºû', 'Ôºö', 'ÔºÇ', 'Ôºè', 'Ôºº', 'ÔΩú', 'Ôºü', 'Ôºä']
        
        for old, new in zip(illegal_chars, illegal_chars_rep):
            if old in filename:
                self._write_debug_log(f"üîÑ ÊõøÊç¢Â≠óÁ¨¶: '{old}' -> '{new}'")
                filename = filename.replace(old, new)
        
        self._write_debug_log(f"üîß _sanitize_filenameÂÆåÊàê - ÂéüÂßã: {repr(original_filename)} -> ÁªìÊûú: {repr(filename)}")
        return filename

    def _parse_novel_id(self, novel_id: Union[str, int]) -> Optional[int]:
        """Parse novel ID from input (URL or ID)"""
        if isinstance(novel_id, str) and novel_id.startswith('http'):
            novel_id = novel_id.split('?')[0].split('/')[-1]
        try:
            return int(novel_id)
        except ValueError:
            self.log_callback(f'Invalid novel ID: {novel_id}')
            return None

    def get_downloaded_novels(self) -> List[Dict[str, str]]:
        """Get list of downloaded novels with their paths"""
        novels = []
        for filename in os.listdir(self.bookstore_dir):
            if filename.endswith('.json'):
                novel_name = filename[:-5]  # Remove .json extension
                json_path = os.path.join(self.bookstore_dir, filename)

                try:
                    with open(json_path, 'r', encoding='UTF-8') as f:
                        novel_data = json.load(f)
                        metadata = novel_data.get('_metadata', {})

                        novels.append({
                            'name': novel_name,
                            'novel_id': metadata.get('novel_id'),
                            'status': metadata.get('status'),
                            'last_updated': metadata.get('last_updated'),
                            'json_path': json_path,
                            'txt_path': os.path.join(self.config.save_path, f'{novel_name}.txt'),
                            'epub_path': os.path.join(self.config.save_path, f'{novel_name}.epub'),
                            'html_path': os.path.join(self.config.save_path, f'{novel_name}(html)'),
                            'latex_path': os.path.join(self.config.save_path, f'{novel_name}.tex')
                        })
                except Exception as e:
                    self.log_callback(f"Error reading novel data for {novel_name}: {str(e)}")
                    # Add novel with minimal info if metadata can't be read
                    novels.append({
                        'name': novel_name,
                        'novel_id': None,
                        'status': None,
                        'last_updated': None,
                        'json_path': json_path,
                        'txt_path': os.path.join(self.config.save_path, f'{novel_name}.txt'),
                        'epub_path': os.path.join(self.config.save_path, f'{novel_name}.epub'),
                        'html_path': os.path.join(self.config.save_path, f'{novel_name}(html)'),
                        'latex_path': os.path.join(self.config.save_path, f'{novel_name}.tex')
                    })
        return novels

    def backup_data(self, backup_dir: str):
        """Backup all data to specified directory"""
        os.makedirs(backup_dir, exist_ok=True)

        # Backup configuration
        if os.path.exists(self.config_path):
            shutil.copy2(self.config_path, os.path.join(backup_dir, 'config.json'))

        # Backup records
        if os.path.exists(self.record_path):
            shutil.copy2(self.record_path, os.path.join(backup_dir, 'record.json'))

        # Backup novels
        novels_backup_dir = os.path.join(backup_dir, 'novels')
        os.makedirs(novels_backup_dir, exist_ok=True)
        for novel in self.get_downloaded_novels():
            shutil.copy2(novel['json_path'], novels_backup_dir)

    def _decode_content(self, content: str, mode: int = 0) -> str:
        """Decode novel content using both charset modes"""
        result = ''
        for char in content:
            uni = ord(char)
            if self.CODE[mode][0] <= uni <= self.CODE[mode][1]:
                bias = uni - self.CODE[mode][0]
                if 0 <= bias < len(self.charset[mode]) and self.charset[mode][bias] != '?':
                    result += self.charset[mode][bias]
                else:
                    result += char
            else:
                result += char
        return result

    def _update_records(self, novel_id: int):
        """Update download records"""
        if os.path.exists(self.record_path):
            with open(self.record_path, 'r', encoding='UTF-8') as f:
                records = json.load(f)
        else:
            records = []

        if novel_id not in records:
            records.append(novel_id)
            with open(self.record_path, 'w', encoding='UTF-8') as f:
                json.dump(records, f)

    def _save_progress(self, title: str, content: str):
        """Save download progress"""
        self.zj[title] = content
        with open(self.book_json_path, 'w', encoding='UTF-8') as f:
            json.dump(self.zj, f, ensure_ascii=False)

    def _save_epub_from_content(self, safe_name: str, novel_content: dict, output_dir: str, novel_id: int) -> str:
        """Âü∫‰∫éÂ∑≤‰∏ãËΩΩÂÜÖÂÆπÁîüÊàêEPUBÊñá‰ª∂Ôºå‰øùÂ≠òÂà∞ÊåáÂÆöÁõÆÂΩï"""
        try:
            # Ëé∑ÂèñÂ∞èËØ¥‰ø°ÊÅØ
            book = epub.EpubBook()
            book.set_identifier(str(novel_id))
            book.set_title(safe_name)
            book.set_language('zh')
            
            # Â∞ùËØïËé∑Âèñ‰ΩúËÄÖ‰ø°ÊÅØ
            try:
                author = self._get_author_info(novel_id)
                if author:
                    book.add_author(author)
                else:
                    book.add_author('Êú™Áü•‰ΩúËÄÖ')
            except:
                book.add_author('Êú™Áü•‰ΩúËÄÖ')
            
            # Ê∑ªÂä†Â∞ÅÈù¢ÔºàÂ¶ÇÊûúÂèØ‰ª•Ëé∑ÂèñÔºâ
            try:
                cover_url = self._get_cover_url(novel_id)
                if cover_url:
                    self._add_cover_to_epub(book, cover_url)
            except:
                pass  # Â∞ÅÈù¢Ëé∑ÂèñÂ§±Ë¥•‰∏çÂΩ±Âìç‰∏ªË¶ÅÊµÅÁ®ã
            
            # ‰∏∫ÊØè‰∏™Á´†ËäÇÂàõÂª∫EPUBÁ´†ËäÇ
            for i, (title, content) in enumerate(novel_content.items()):
                if title.startswith('_'):  # Ë∑≥ËøáÂÖÉÊï∞ÊçÆ
                    continue
                    
                chapter = epub.EpubHtml(
                    title=title,
                    file_name=f'chapter_{i+1}.xhtml',
                    lang='zh'
                )
                
                # Ê†ºÂºèÂåñÂÜÖÂÆπ
                formatted_content = ''.join(f'<p>{para.strip()}</p>' for para in content.split('\n') if para.strip())
                chapter.content = f'<h1>{title}</h1>{formatted_content}'
                
                book.add_item(chapter)
            
            # Ê∑ªÂä†ÂØºËà™
            chapters = [item for item in book.get_items() if isinstance(item, epub.EpubHtml)]
            book.toc = chapters
            book.spine = ['nav'] + chapters
            book.add_item(epub.EpubNcx())
            book.add_item(epub.EpubNav())
            
            # ‰øùÂ≠òEPUBÊñá‰ª∂Âà∞ÊåáÂÆöÁõÆÂΩï
            epub_path = os.path.join(output_dir, f'{safe_name}.epub')
            epub.write_epub(epub_path, book)
            
            return 's'
            
        except Exception as e:
            self.log_callback(f'EPUBÁîüÊàêÂ§±Ë¥•: {str(e)}')
            return 'err'
    
    def _save_html_from_content(self, safe_name: str, novel_content: dict, output_dir: str) -> str:
        """Âü∫‰∫éÂ∑≤‰∏ãËΩΩÂÜÖÂÆπÁîüÊàêHTMLÊñá‰ª∂Ôºå‰øùÂ≠òÂà∞ÊåáÂÆöÁõÆÂΩï"""
        try:
            html_dir = os.path.join(output_dir, f"{safe_name}(html)")
            os.makedirs(html_dir, exist_ok=True)
            
            # ÁîüÊàêÁ´†ËäÇÊñá‰ª∂
            all_titles = []
            for i, (title, content) in enumerate(novel_content.items()):
                if title.startswith('_'):  # Ë∑≥ËøáÂÖÉÊï∞ÊçÆ
                    continue
                    
                all_titles.append(title)
                filename = f"chapter_{i+1}.html"
                chapter_path = os.path.join(html_dir, filename)
                
                # ÂàõÂª∫HTMLÂÜÖÂÆπ
                html_content = f"""<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{ font-family: serif; line-height: 1.8; margin: 40px; background: #f9f9f9; }}
        .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        h1 {{ color: #333; border-bottom: 2px solid #eee; padding-bottom: 10px; }}
        p {{ text-indent: 2em; margin: 1em 0; }}
        .navigation {{ margin: 20px 0; text-align: center; }}
        .navigation a {{ margin: 0 10px; padding: 8px 16px; background: #007bff; color: white; text-decoration: none; border-radius: 4px; }}
        .navigation a:hover {{ background: #0056b3; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="navigation">
            <a href="index.html">ÁõÆÂΩï</a>
        </div>
        <h1>{title}</h1>
"""
                
                # Ê∑ªÂä†Á´†ËäÇÂÜÖÂÆπ
                for paragraph in content.split('\n'):
                    if paragraph.strip():
                        html_content += f"        <p>{paragraph.strip()}</p>\n"
                
                html_content += """    </div>
</body>
</html>"""
                
                with open(chapter_path, 'w', encoding='UTF-8') as f:
                    f.write(html_content)
            
            # ÁîüÊàêÁõÆÂΩïÊñá‰ª∂
            index_content = self._create_html_index(safe_name, novel_content)
            index_path = os.path.join(html_dir, 'index.html')
            with open(index_path, 'w', encoding='UTF-8') as f:
                f.write(index_content)
            
            return 's'
            
        except Exception as e:
            self.log_callback(f'HTMLÁîüÊàêÂ§±Ë¥•: {str(e)}')
            return 'err'
    
    def _save_latex_from_content(self, safe_name: str, novel_content: dict, output_dir: str) -> str:
        """Âü∫‰∫éÂ∑≤‰∏ãËΩΩÂÜÖÂÆπÁîüÊàêLaTeXÊñá‰ª∂Ôºå‰øùÂ≠òÂà∞ÊåáÂÆöÁõÆÂΩï"""
        try:
            latex_path = os.path.join(output_dir, f'{safe_name}.tex')
            
            with open(latex_path, 'w', encoding='UTF-8') as f:
                # LaTeXÊñáÊ°£Â§¥ÈÉ®
                f.write(self._create_latex_header(safe_name))
                
                # Ê∑ªÂä†Á´†ËäÇÂÜÖÂÆπ
                for title, content in novel_content.items():
                    if title.startswith('_'):  # Ë∑≥ËøáÂÖÉÊï∞ÊçÆ
                        continue
                        
                    formatted_chapter = self._format_latex_chapter(title, content)
                    f.write(formatted_chapter)
                
                # LaTeXÊñáÊ°£Â∞æÈÉ®
                f.write('\n\\end{document}\n')
            
            return 's'
            
        except Exception as e:
            self.log_callback(f'LaTeXÁîüÊàêÂ§±Ë¥•: {str(e)}')
            return 'err'
    
    def _generate_pdf_from_latex(self, safe_name: str, output_dir: str) -> str:
        """‰ΩøÁî®xelatexÂ∞ÜLaTeXÊñá‰ª∂ÁºñËØë‰∏∫PDF"""
        try:
            import subprocess
            
            latex_file = f'{safe_name}.tex'
            latex_path = os.path.join(output_dir, latex_file)
            
            # Ê£ÄÊü•LaTeXÊñá‰ª∂ÊòØÂê¶Â≠òÂú®
            if not os.path.exists(latex_path):
                raise Exception(f'LaTeXÊñá‰ª∂‰∏çÂ≠òÂú®: {latex_path}')
            
            # Ê£ÄÊü•xelatexÊòØÂê¶ÂèØÁî®
            try:
                subprocess.run(['xelatex', '--version'], capture_output=True, check=True)
            except (subprocess.CalledProcessError, FileNotFoundError):
                raise Exception('xelatexÊú™ÂÆâË£ÖÊàñ‰∏çÂú®PATH‰∏≠„ÄÇËØ∑ÂÆâË£ÖLaTeXÂèëË°åÁâàÔºàÂ¶ÇTeX LiveÊàñMiKTeXÔºâ')
            
            # ÁºñËØëLaTeX‰∏∫PDF
            self.log_callback('Ê≠£Âú®‰ΩøÁî®xelatexÁºñËØëPDF...')
            
            # ÂàáÊç¢Âà∞ËæìÂá∫ÁõÆÂΩïÊâßË°åxelatexÔºåÁ°Æ‰øùÂ∑•‰ΩúÁõÆÂΩïÂ∞±ÊòØlatexÊñá‰ª∂ÁöÑÁõÆÂΩï
            original_cwd = os.getcwd()
            try:
                os.chdir(output_dir)
                
                # ËøêË°åxelatexÔºåÂøÖÈ°ªËøêË°å‰∏§Ê¨°‰ª•Ê≠£Á°ÆÁîüÊàêÁõÆÂΩïÂíåÂºïÁî®
                for i in range(2):
                    self.log_callback(f'ÊâßË°åÁ¨¨{i+1}Ê¨°xelatexÁºñËØë...')
                    # ‰øÆÂ§çÁºñÁ†ÅÈóÆÈ¢òÔºö‰ΩøÁî®bytesÊ®°ÂºèËÄå‰∏çÊòØtextÊ®°Âºè
                    result = subprocess.run(
                        ['xelatex', '-interaction=nonstopmode', latex_file],
                        capture_output=True,
                        text=False,  # ‰ΩøÁî®bytesÊ®°ÂºèÈÅøÂÖçÁºñÁ†ÅÈóÆÈ¢ò
                        timeout=300  # 5ÂàÜÈíüË∂ÖÊó∂
                    )
                    
                    if result.returncode != 0:
                        # Â¶ÇÊûúÂ§±Ë¥•ÔºåÂ∞ùËØïÊü•ÁúãÊó•Âøó
                        log_file = f'{safe_name}.log'
                        error_info = f'xelatexÁºñËØëÂ§±Ë¥• (ËøîÂõûÁ†Å: {result.returncode})'
                        
                        # Ëé∑ÂèñstderrËæìÂá∫ÔºàÂ¶ÇÊûúÊúâÔºâ
                        if result.stderr:
                            try:
                                # Â∞ùËØïÂ§öÁßçÁºñÁ†ÅËß£Á†Åstderr
                                stderr_text = None
                                for encoding in ['utf-8', 'gbk', 'latin1']:
                                    try:
                                        stderr_text = result.stderr.decode(encoding)
                                        break
                                    except UnicodeDecodeError:
                                        continue
                                
                                if stderr_text:
                                    error_info += f'\nÁºñËØëËæìÂá∫: {stderr_text[:500]}...'  # ÈôêÂà∂ÈïøÂ∫¶
                            except:
                                error_info += '\nÁºñËØëËæìÂá∫: <Êó†Ê≥ïËß£Á†ÅÁöÑËæìÂá∫>'
                        
                        # Â∞ùËØïËØªÂèñÊó•ÂøóÊñá‰ª∂
                        if os.path.exists(log_file):
                            try:
                                # Â∞ùËØïÂ§öÁßçÁºñÁ†ÅËØªÂèñÊó•ÂøóÊñá‰ª∂
                                log_content = None
                                for encoding in ['utf-8', 'gbk', 'latin1']:
                                    try:
                                        with open(log_file, 'r', encoding=encoding) as log_f:
                                            lines = log_f.readlines()
                                            # ÂèñÊúÄÂêé20Ë°å
                                            error_lines = lines[-20:] if len(lines) > 20 else lines
                                            log_content = ''.join(error_lines)
                                            break
                                    except UnicodeDecodeError:
                                        continue
                                
                                if log_content:
                                    error_info += f'\nÊúÄÂêéÂá†Ë°åÊó•Âøó:\n{log_content}'
                                else:
                                    error_info += '\nÊó•ÂøóÊñá‰ª∂: <Êó†Ê≥ïËß£Á†Å>'
                            except Exception as e:
                                error_info += f'\nËØªÂèñÊó•ÂøóÂ§±Ë¥•: {str(e)}'
                        
                        raise Exception(error_info)
                
                # Ê£ÄÊü•PDFÊòØÂê¶ÁîüÊàêÊàêÂäü
                pdf_file = f'{safe_name}.pdf'
                if not os.path.exists(pdf_file):
                    raise Exception('PDFÊñá‰ª∂Êú™ÁîüÊàê')
                
                # Ê∏ÖÁêÜËæÖÂä©Êñá‰ª∂
                aux_extensions = ['.aux', '.log', '.out', '.toc', '.fls', '.fdb_latexmk']
                for ext in aux_extensions:
                    aux_file = f'{safe_name}{ext}'
                    if os.path.exists(aux_file):
                        try:
                            os.remove(aux_file)
                        except:
                            pass  # Ê∏ÖÁêÜÂ§±Ë¥•‰∏çÂΩ±Âìç‰∏ªË¶ÅÊµÅÁ®ã
                
                return 's'
                
            finally:
                os.chdir(original_cwd)
            
        except Exception as e:
            self.log_callback(f'PDFÁîüÊàêÂ§±Ë¥•: {str(e)}')
            return 'err'


def create_cli():
    """Create CLI interface using the NovelDownloader class"""
    print('Êú¨Á®ãÂ∫èÂÆåÂÖ®ÂÖçË¥π(Ê≠§ÁâàÊú¨‰∏∫WEBÁâàÔºåÁõÆÂâçÂ§Ñ‰∫éÊµãËØïÈò∂ÊÆµ)\nGithub: https://github.com/ying-ck/fanqienovel-downloader\n‰ΩúËÄÖÔºöYck & qxqycb & lingo34')
    print('‰ºòÂåñÂ¢ûÂº∫Áâà - ÊîØÊåÅYAMLÈÖçÁΩÆÊñá‰ª∂')

    # Ëß£ÊûêÂëΩ‰ª§Ë°åÂèÇÊï∞
    parser = argparse.ArgumentParser(description='Áï™ËåÑÂ∞èËØ¥‰∏ãËΩΩÂô®', add_help=False)
    parser.add_argument('--id', type=str, help='Áõ¥Êé•‰∏ãËΩΩÊåáÂÆöIDÁöÑÂ∞èËØ¥')
    parser.add_argument('--config', type=str, default='config.yaml', help='ÈÖçÁΩÆÊñá‰ª∂Ë∑ØÂæÑ')
    parser.add_argument('-h', '--help', action='store_true', help='ÊòæÁ§∫Â∏ÆÂä©‰ø°ÊÅØ')
    parser.add_argument('config_file', nargs='?', help='ÈÖçÁΩÆÊñá‰ª∂Ë∑ØÂæÑÔºàÂÖºÂÆπÊóßÊ†ºÂºèÔºâ')
    
    args = parser.parse_args()
    
    if args.help:
        print('\n‰ΩøÁî®ÊñπÊ≥ï:')
        print('  python src/main.py                    # ‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆÊñá‰ª∂Âπ∂ËøõÂÖ•‰∫§‰∫íÊ®°Âºè')
        print('  python src/main.py --config [ÈÖçÁΩÆÊñá‰ª∂] # ‰ΩøÁî®ÊåáÂÆöÈÖçÁΩÆÊñá‰ª∂')
        print('  python src/main.py --id [Â∞èËØ¥ID]      # Áõ¥Êé•‰∏ãËΩΩÊåáÂÆöIDÁöÑÂ∞èËØ¥')
        print('  python src/main.py --help            # ÊòæÁ§∫Ê≠§Â∏ÆÂä©‰ø°ÊÅØ')
        print('\nÁ§∫‰æã:')
        print('  python src/main.py --id 7520128677003136024')
        print('  python src/main.py --config my_config.yaml --id 7520128677003136024')
        print('\nÈÖçÁΩÆÊñá‰ª∂Á§∫‰æãËØ∑ÂèÇËÄÉ config.yaml')
        return
    
    # Á°ÆÂÆöÈÖçÁΩÆÊñá‰ª∂Ë∑ØÂæÑ (ÂÖºÂÆπÊóßÊ†ºÂºè)
    config_path = args.config
    if args.config_file:
        config_path = args.config_file
    
    # Âä†ËΩΩÈÖçÁΩÆ
    if os.path.exists(config_path):
        print(f'üìÑ Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂: {config_path}')
        config = Config.from_yaml(config_path)
    else:
        if config_path != 'config.yaml':
            print(f'‚ö†Ô∏è ÈÖçÁΩÆÊñá‰ª∂‰∏çÂ≠òÂú®: {config_path}')
        print('üìÑ ‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ')
        config = Config()
    
    # ÊòæÁ§∫ÂΩìÂâçÈÖçÁΩÆÊëòË¶Å
    print(f'\nüìã ÂΩìÂâçÈÖçÁΩÆÊëòË¶Å:')
    print(f'  üóÇÔ∏è  ËæìÂá∫Ê†ºÂºè: TXT({config.enable_txt}) JSON(ÂøÖÈ°ª) EPUB({config.enable_epub}) HTML({config.enable_html}) LaTeX({config.enable_latex}) PDF({config.enable_pdf})')
    print(f'  ‚ö° Á∫øÁ®ãÊï∞: {config.thread_count}')
    print(f'  ‚è±Ô∏è  Âª∂Êó∂Ê®°Âºè: {config.delay_mode} ({config.delay[0]}-{config.delay[1]}ms)')
    print(f'  üìÅ JSONÁõÆÂΩï: {config.bookstore_dir}')
    print(f'  üìÅ ‰∏ãËΩΩÁõÆÂΩï: {config.download_dir}')
    
    downloader = NovelDownloader(config)

    # Check for backup
    backup_folder_path = 'C:\\Users\\Administrator\\fanqie_down_backup'
    if os.path.exists(backup_folder_path):
        choice = input("Ê£ÄÊµãÂà∞Â§á‰ªΩÊñá‰ª∂Â§πÔºåÂê¶‰ΩøÁî®Â§á‰ªΩÊçÆÔºü1.‰ΩøÁî®Â§á‰ªΩ  2.Ë∑≥ËøáÔºö")
        if choice == '1':
            if os.path.isdir(backup_folder_path):
                source_folder_path = os.path.dirname(os.path.abspath(__file__))
                for item in os.listdir(backup_folder_path):
                    source_item_path = os.path.join(backup_folder_path, item)
                    target_item_path = os.path.join(source_folder_path, item)
                    if os.path.isfile(source_item_path):
                        if os.path.exists(target_item_path):
                            os.remove(target_item_path)
                        shutil.copy2(source_item_path, target_item_path)
                    elif os.path.isdir(source_item_path):
                        if os.path.exists(target_item_path):
                            shutil.rmtree(target_item_path)
                        shutil.copytree(source_item_path, target_item_path)
            else:
                print("Â§á‰ªΩÊñá‰ª∂Â§π‰∏çÂ≠òÂú®ÔºåÊó†Ê≥ï‰ΩøÁî®Â§á‰ªΩÊï∞ÊçÆ„ÄÇ")
        elif choice != '2':
            print("ÂÖ•Êó†ÊïàÔºåËØ∑ÈáçÊñ∞ËøêË°åÁ®ãÂ∫èÂπ∂Ê≠£Á°ÆËæìÂÖ•„ÄÇ")
    else:
        print("Á®ãÂ∫èËøòÊú™Â§á‰ªΩ")
    
    # Â¶ÇÊûúÊèê‰æõ‰∫Ü--idÂèÇÊï∞ÔºåÁõ¥Êé•‰∏ãËΩΩÂπ∂ÈÄÄÂá∫
    if args.id:
        print(f'\nüöÄ ÂºÄÂßãÁõ¥Êé•‰∏ãËΩΩÂ∞èËØ¥ID: {args.id}')
        result = downloader.download_novel(args.id)
        if result:
            print('‚úÖ ‰∏ãËΩΩÂÆåÊàê')
        else:
            print('‚ùå ‰∏ãËΩΩÂ§±Ë¥•ÔºåËØ∑Ê£ÄÊü•Â∞èËØ¥IDÊòØÂê¶Ê≠£Á°Æ')
        return

    while True:
        print('\nËæìÂÖ•‰π¶ÁöÑidÁõ¥Êé•‰∏ãËΩΩ\nËæìÂÖ•‰∏ãÈù¢ÁöÑÊï∞Â≠óËøõÂÖ•ÂÖ∂‰ªñÂäüËÉΩ:')
        print('''
1. Êõ¥Êñ∞Â∞èËØ¥
2. ÊêúÁ¥¢
3. ÊâπÈáè‰∏ãËΩΩ
4. ËÆæÁΩÆ
5. Â§á‰ªΩ
6. ÈÄÄÂá∫
        ''')

        inp = input()

        if inp == '1':
            downloader.update_all_novels()

        elif inp == '2':
            while True:
                key = input("ËØ∑ËæìÂÖ•ÊêúÁ¥¢ÂÖ≥ÈîÆËØçÔºàÁõ¥Êé•EnterËøîÂõûÔºâÔºö")
                if key == '':
                    break
                results = downloader.search_novel(key)
                if not results:
                    print("Ê≤°ÊúâÊâæÂà∞Áõ∏ÂÖ≥‰π¶Á±ç„ÄÇ")
                    continue

                for i, book in enumerate(results):
                    print(f"{i + 1}. ÂêçÁß∞Ôºö{book['book_data'][0]['book_name']} "
                          f"‰ΩúËÄÖÔºö{book['book_data'][0]['author']} "
                          f"IDÔºö{book['book_data'][0]['book_id']} "
                          f"Â≠óÊï∞Ôºö{book['book_data'][0]['word_number']}")

                while True:
                    choice = input("ËØ∑ÈÄâÊã©‰∏Ä‰∏™ÁªìÊûú, ËæìÂÖ• r ‰ª•ÈáçÊñ∞ÊêúÁ¥¢Ôºö")
                    if choice == "r":
                        break
                    elif choice.isdigit() and 1 <= int(choice) <= len(results):
                        chosen_book = results[int(choice) - 1]
                        downloader.download_novel(chosen_book['book_data'][0]['book_id'])
                        break
                    else:
                        print("ËæìÂÖ•Êó†ÊïàÔºåËØ∑ÈáçÊñ∞ËæìÂÖ•„ÄÇ")

        elif inp == '3':
            urls_path = 'urls.txt'
            if not os.path.exists(urls_path):
                print(f"Êú™ÊâæÂà∞'{urls_path}'ÔºåÂ∞Ü‰∏∫ÊÇ®ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÊñá‰ª∂„ÄÇ")
                with open(urls_path, 'w', encoding='UTF-8') as file:
                    file.write("# ËæìÂÖ•Â∞èËØ¥ÈìæÊé•Ôºå‰∏ÄË°å‰∏Ä‰∏™\n")

            print(f"\nËØ∑Âú®ÊñáÊú¨ÁºñËæëÂô®‰∏≠ÊâìÂºÄÂπ∂ÁºñËæë '{urls_path}'")
            print("Âú®Êñá‰ª∂‰∏≠ËæìÂÖ•Â∞èËØ¥ÈìæÊé•Ôºå‰∏ÄË°å‰∏Ä‰∏™")

            if platform.system() == "Windows":
                os.system(f'notepad "{urls_path}"')
            elif platform.system() == "Darwin":
                os.system(f'open -e "{urls_path}"')
            else:
                if os.system('which nano > /dev/null') == 0:
                    os.system(f'nano "{urls_path}"')
                elif os.system('which vim > /dev/null') == 0:
                    os.system(f'vim "{urls_path}"')
                else:
                    print(f"ËØ∑‰ΩøÁî®‰ªªÊÑèÊñáÊú¨ÁºñËæëÂô®ÊâãÂä®ÁºñËæë {urls_path} Êñá‰ª∂")

            print("\nÁºñËæëÂÆåÊàêÂêéÊåâEnterÈîÆÁªßÁª≠...")
            input()

            with open(urls_path, 'r', encoding='UTF-8') as file:
                content = file.read()
                urls = content.replace(' ', '').split('\n')

            for url in urls:
                if url and url[0] != '#':
                    print(f'ÂºÄÂßã‰∏ãËΩΩÈìæÊé•: {url}')
                    status = downloader.download_novel(url)
                    if not status:
                        print(f'ÈìæÊé•: {url} ‰∏ãËΩΩÂ§±Ë¥•„ÄÇ')
                    else:
                        print(f'ÈìæÊé•: {url} ‰∏ãËΩΩÂÆåÊàê„ÄÇ')

        elif inp == '4':
            print('ËØ∑ÈÄâÊã©È°πÁõÆÔºö1.Ê≠£ÊñáÊÆµÈ¶ñÂç†‰ΩçÁ¨¶ 2.Á´†ËäÇ‰∏ãËΩΩÈó¥ÈöîÂª∂Ëøü 3.Â∞èËØ¥‰øùÂ≠òË∑ØÂæÑ 4.Â∞èËØ¥‰øùÂ≠òÊñπÂºè 5.ËÆæÁΩÆ‰∏ãËΩΩÁ∫øÁ®ãÊï∞')
            inp2 = input()
            if inp2 == '1':
                tmp = input('ËØ∑ËæìÂÖ•Ê≠£ÊñáÊÆµÈ¶ñÂç†‰ΩçÁ¨¶(ÂΩìÂâç‰∏∫"%s")(Áõ¥Êé•Enter‰∏çÊõ¥Êîπ)Ôºö' % config.kgf)
                if tmp != '':
                    config.kgf = tmp
                config.kg = int(input('ËØ∑ËæìÂÖ•Ê≠£ÊñáÊÆµÈ¶ñÂç†‰ΩçÁ¨¶Êï∞ÔºàÂΩìÂâç‰∏∫%dÔºâÔºö' % config.kg))
            elif inp2 == '2':
                print('Áî±‰∫éËøüËøáÂ∞èÈÄ†ÊàêÁöÑÂêéÊûúËØ∑Ëá™Ë°åË¥üË¥£„ÄÇ\nËØ∑ËæìÂÖ•‰∏ãËΩΩÈó¥ÈöîÈöèÊú∫Âª∂Ëøü')
                config.delay[0] = int(input('‰∏ãÈôêÔºàÂΩìÂâç‰∏∫%dÔºâÊØ´ÁßíÔºâÔºö' % config.delay[0]))
                config.delay[1] = int(input('‰∏äÈôêÔºàÂΩìÂâç‰∏∫%dÔºâÔºàÊØ´ÁßíÔºâÔºö' % config.delay[1]))
            elif inp2 == '3':
                print('tip:ËÆæÁΩÆ‰∏∫ÂΩìÂâçÁõÆÂΩïÁÇπÂèñÊ∂à')
                time.sleep(1)
                path = input("\nËØ∑ËæìÂÖ•‰øùÂ≠òÁõÆÂΩïÁöÑÂÆåÊï¥Ë∑ØÂæÑ:\n(Áõ¥Êé•ÊåâEnterÁî®ÂΩìÂâçÁõÆÂΩï)\n").strip()
                if path == "":
                    config.save_path = os.getcwd()
                else:
                    if not os.path.exists(path):
                        try:
                            os.makedirs(path)
                            config.save_path = path
                        except:
                            print("Êó†Ê≥ïÂàõÂª∫ÁõÆÂΩïÔºåÂ∞Ü‰ΩøÁî®ÂΩìÂâçÁõÆÂΩï")
                            config.save_path = os.getcwd()
                    else:
                        config.save_path = path
            elif inp2 == '4':
                print('ËØ∑ÈÄâÊã©Ôºö1.‰øùÂ≠ò‰∏∫Âçï‰∏™ txt 2.ÂàÜÁ´†‰øùÂ≠ò 3.‰øùÂ≠ò‰∏∫ epub 4.‰øùÂ≠ò‰∏∫ HTML ÁΩëÈ°µÊ†ºÂºè 5.‰øùÂ≠ò‰∏∫ LaTeX')
                inp3 = input()
                try:
                    config.save_mode = SaveMode(int(inp3))
                except ValueError:
                    print('ËØ∑Ê≠£Á°ÆËæìÂÖ•!')
                    continue
            elif inp2 == '5':
                config.xc = int(input('ËØ∑ËæìÂÖ•‰∏ãËΩΩÁ∫øÁ®ãÊï∞Ôºö'))
            else:
                print('ËØ∑Ê≠£Á°ÆËæìÂÖ•!')
                continue

            # Save config
            with open(downloader.config_path, 'w', encoding='UTF-8') as f:
                json.dump({
                    'kg': config.kg,
                    'kgf': config.kgf,
                    'delay': config.delay,
                    'save_path': config.save_path,
                    'save_mode': config.save_mode.value,
                    'space_mode': config.space_mode,
                    'xc': config.xc
                }, f)
            print('ËÆæÁΩÆÂÆåÊàê')

        elif inp == '5':
            downloader.backup_data('C:\\Users\\Administrator\\fanqie_down_backup')
            print('Â§á‰ªΩÂÆåÊàê')

        elif inp == '6':
            break

        else:
            # Try to download novel directly
            if downloader.download_novel(inp):
                print('‰∏ãËΩΩÂÆåÊàê')
            else:
                print('ËØ∑ËæìÂÖ•ÊúâÊïàÁöÑÈÄâÈ°πÊàñ‰π¶Á±çID„ÄÇ')


if __name__ == "__main__":
    create_cli()