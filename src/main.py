# -*- coding: utf-8 -*-
"""
ä¿®å¤ç‰ˆmain.py - è§£å†³cookieç”Ÿæˆæ—¶çš„å·¨å¤§å¾ªç¯å¡æ­»é—®é¢˜
åŸç‰ˆæœ¬åœ¨_get_new_cookieå‡½æ•°ä¸­ä½¿ç”¨6Ã—10^18åˆ°9Ã—10^18çš„å·¨å¤§å¾ªç¯èŒƒå›´ï¼Œå¯¼è‡´ç¨‹åºå¡ä½
ä¿®å¤ç‰ˆæœ¬ä½¿ç”¨åŸºäºæ—¶é—´æˆ³çš„åˆç†èŒƒå›´ï¼Œé¿å…é•¿æ—¶é—´ç­‰å¾…
"""
import requests as req
from lxml import etree
from ebooklib import epub
from tqdm import tqdm
from bs4 import BeautifulSoup
import json
import yaml  # æ·»åŠ YAMLæ”¯æŒ
import time
import random
import re  # æ·»åŠ æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—
import os
import platform
import shutil
import concurrent.futures
import argparse  # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°è§£æ
from typing import Callable, Optional, Dict, List, Union
from dataclasses import dataclass, field
from enum import Enum


class SaveMode(Enum):
    SINGLE_TXT = 1
    SPLIT_TXT = 2
    EPUB = 3
    HTML = 4
    LATEX = 5


@dataclass
class Config:
    # æ–‡ä»¶æ ¼å¼æ§åˆ¶
    enable_txt: bool = True
    enable_epub: bool = False
    enable_html: bool = False
    enable_latex: bool = False
    enable_pdf: bool = False
    
    # ç›®å½•é…ç½® (ç®€åŒ–ç‰ˆ)
    bookstore_dir: str = "bookstore"    # JSONæ–‡ä»¶å­˜æ”¾ç›®å½•
    download_dir: str = "downloads"     # å…¶ä»–æ ¼å¼æ–‡ä»¶å­˜æ”¾ç›®å½•
    
    # æ€§èƒ½é…ç½®
    thread_count: int = 8
    delay_mode: str = "normal"
    custom_delay: List[int] = field(default_factory=lambda: [150, 300])
    
    # æ–‡ä»¶ç®¡ç†
    delete_chapters_after_merge: bool = False
    conflict_resolution: str = "rename"
    encoding: str = "UTF-8"
    preserve_original_order: bool = False
    
    # Cookieé…ç½®
    cookie_mode: str = "auto"
    manual_cookie: str = ""
    cookie_file: str = "data/cookie.json"
    validate_cookie: bool = False
    
    # å†…å®¹å¤„ç†
    paragraph_spacing: int = 0
    indent_character: str = "ã€€"
    decode_mode: str = "auto"
    filter_special_chars: bool = False
    
    # ç½‘ç»œé…ç½®
    timeout: int = 30
    retry_count: int = 3
    retry_delays: List[int] = field(default_factory=lambda: [1, 2, 4])  # é‡è¯•é—´éš”(ç§’)
    rotate_user_agent: bool = True
    
    # æ—¥å¿—é…ç½®
    log_level: str = "normal"
    save_log_to_file: bool = False
    log_file: str = "logs/download.log"
    
    # é«˜çº§é€‰é¡¹
    enable_experimental: bool = False
    memory_mode: str = "normal"
    show_progress_bar: bool = True
    
    # å…¼å®¹æ€§å­—æ®µï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    kg: int = 0
    kgf: str = 'ã€€'
    delay: List[int] = field(default_factory=lambda: [100, 200])
    save_path: str = ''
    save_mode: SaveMode = SaveMode.SINGLE_TXT
    space_mode: str = 'halfwidth'
    xc: int = 8
    
    def __post_init__(self):
        # å¤„ç†å»¶æ—¶é…ç½®
        if self.delay_mode == "fast":
            self.delay = [50, 100]
        elif self.delay_mode == "normal":
            self.delay = [100, 200]
        elif self.delay_mode == "safe":
            self.delay = [200, 500]
        elif self.delay_mode == "custom":
            self.delay = self.custom_delay.copy()
        
        # åŒæ­¥çº¿ç¨‹æ•°é…ç½®
        self.xc = self.thread_count
        
        # åŒæ­¥æ®µè½é…ç½®
        self.kg = self.paragraph_spacing
        self.kgf = self.indent_character
    
    @classmethod
    def from_yaml(cls, yaml_path: str) -> 'Config':
        """ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            with open(yaml_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
            
            config = cls()
            
            # æ–‡ä»¶æ ¼å¼é…ç½®
            if 'formats' in data:
                formats = data['formats']
                config.enable_txt = formats.get('enable_txt', True)
                config.enable_epub = formats.get('enable_epub', False)
                config.enable_html = formats.get('enable_html', False)
                config.enable_latex = formats.get('enable_latex', False)
                config.enable_pdf = formats.get('enable_pdf', False)
            
            # ç›®å½•é…ç½® (ç®€åŒ–ç‰ˆ)
            if 'directories' in data:
                dirs = data['directories']
                config.bookstore_dir = dirs.get('bookstore_dir', "bookstore")
                config.download_dir = dirs.get('download_dir', "downloads")
            
            # æ€§èƒ½é…ç½®
            if 'performance' in data:
                perf = data['performance']
                config.thread_count = perf.get('thread_count', 8)
                config.delay_mode = perf.get('delay_mode', "normal")
                config.custom_delay = perf.get('custom_delay', [150, 300])
            
            # æ–‡ä»¶ç®¡ç†é…ç½®
            if 'file_management' in data:
                fm = data['file_management']
                config.delete_chapters_after_merge = fm.get('delete_chapters_after_merge', False)
                config.conflict_resolution = fm.get('conflict_resolution', "rename")
                config.encoding = fm.get('encoding', "UTF-8")
                config.preserve_original_order = fm.get('preserve_original_order', False)
            
            # Cookieé…ç½®
            if 'authentication' in data:
                auth = data['authentication']
                config.cookie_mode = auth.get('cookie_mode', "auto")
                config.manual_cookie = auth.get('manual_cookie', "")
                config.cookie_file = auth.get('cookie_file', "data/cookie.json")
                config.validate_cookie = auth.get('validate_cookie', False)
            
            # å†…å®¹å¤„ç†é…ç½®
            if 'content' in data:
                content = data['content']
                config.paragraph_spacing = content.get('paragraph_spacing', 0)
                config.indent_character = content.get('indent_character', "ã€€")
                config.decode_mode = content.get('decode_mode', "auto")
                config.filter_special_chars = content.get('filter_special_chars', False)
            
            # ç½‘ç»œé…ç½®
            if 'network' in data:
                net = data['network']
                config.timeout = net.get('timeout', 30)
                config.retry_count = net.get('retry_count', 3)
                config.retry_delays = net.get('retry_delays', [1, 2, 4])
                config.rotate_user_agent = net.get('rotate_user_agent', True)
            
            # æ—¥å¿—é…ç½®
            if 'logging' in data:
                log = data['logging']
                config.log_level = log.get('level', "normal")
                config.save_log_to_file = log.get('save_to_file', False)
                config.log_file = log.get('log_file', "logs/download.log")
            
            # é«˜çº§é…ç½®
            if 'advanced' in data:
                adv = data['advanced']
                config.enable_experimental = adv.get('enable_experimental', False)
                config.memory_mode = adv.get('memory_mode', "normal")
                config.show_progress_bar = adv.get('show_progress_bar', True)
            
            return config
            
        except Exception as e:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            print("ä½¿ç”¨é»˜è®¤é…ç½®")
            return cls()
    
    def get_delay_range(self) -> List[int]:
        """è·å–å½“å‰çš„å»¶æ—¶èŒƒå›´"""
        return self.delay


class NovelDownloader:
    def __init__(self,
                 config: Config,
                 progress_callback: Optional[Callable] = None,
                 log_callback: Optional[Callable] = None):
        self.config = config
        self.progress_callback = progress_callback or self._default_progress
        self.log_callback = log_callback or print

        # Initialize headers first
        self.headers_lib = [
            {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36'},
            {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0'},
            {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36 Edg/93.0.961.47'}
        ]
        self.headers = random.choice(self.headers_lib)

        # Use absolute paths based on script location
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        self.data_dir = os.path.join(self.script_dir, 'data')
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ç›®å½•è®¾ç½® (ç®€åŒ–ç‰ˆ)
        self.bookstore_dir = os.path.join(self.script_dir, self.config.bookstore_dir)  # JSONæ–‡ä»¶ç›®å½•
        self.download_dir = os.path.join(self.script_dir, self.config.download_dir)    # å…¶ä»–æ ¼å¼æ–‡ä»¶ç›®å½•
        
        self.record_path = os.path.join(self.data_dir, 'record.json')
        self.config_path = os.path.join(self.data_dir, 'config.json')
        
        # Cookieè·¯å¾„æ ¹æ®é…ç½®å†³å®š
        if self.config.cookie_mode == "file":
            self.cookie_path = os.path.join(self.script_dir, self.config.cookie_file)
        else:
            self.cookie_path = os.path.join(self.data_dir, 'cookie.json')

        self.CODE = [[58344, 58715], [58345, 58716]]

        # Load charset for text decoding
        charset_path = os.path.join(self.script_dir, 'charset.json')
        with open(charset_path, 'r', encoding='UTF-8') as f:
            self.charset = json.load(f)

        self._setup_directories()
        self._init_cookie()

        # Add these variables
        self.zj = {}  # For storing chapter data
        self.cs = 0  # Chapter counter
        self.tcs = 0  # Test counter
        self.tzj = None  # Test chapter ID
        self.book_json_path = None  # Current book's JSON path
        
        # åçˆ¬æ£€æµ‹å’Œè‡ªé€‚åº”å»¶æ—¶
        self.empty_content_count = 0  # è¿ç»­ç©ºå†…å®¹è®¡æ•°
        self.total_empty_count = 0    # æ€»è®¡ç©ºå†…å®¹è®¡æ•°
        self.adaptive_delay_multiplier = 1.0  # è‡ªé€‚åº”å»¶æ—¶å€æ•°
        self.last_successful_time = time.time()  # ä¸Šæ¬¡æˆåŠŸæ—¶é—´

    def _setup_directories(self):
        """Create necessary directories if they don't exist"""
        os.makedirs(self.data_dir, exist_ok=True)
        
        # åˆ›å»ºåŸºç¡€ç›®å½•
        os.makedirs(self.bookstore_dir, exist_ok=True)  # JSONæ–‡ä»¶ç›®å½•ï¼ˆæ€»æ˜¯éœ€è¦ï¼‰
        os.makedirs(self.download_dir, exist_ok=True)   # å…¶ä»–æ ¼å¼æ–‡ä»¶ç›®å½•
            
        # å¦‚æœéœ€è¦ä¿å­˜æ—¥å¿—ï¼Œåˆ›å»ºæ—¥å¿—ç›®å½•
        if self.config.save_log_to_file:
            log_dir = os.path.dirname(os.path.join(self.script_dir, self.config.log_file))
            if log_dir:
                os.makedirs(log_dir, exist_ok=True)

    def _init_cookie(self):
        """Initialize cookie for downloads - ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥ä½¿ç”¨é»˜è®¤cookie"""
        self.log_callback('æ­£åœ¨åˆå§‹åŒ–cookie')
        
        # ç›´æ¥ä½¿ç”¨æ—¶é—´æˆ³ç”Ÿæˆé»˜è®¤cookieï¼Œæ— éœ€éªŒè¯
        base_timestamp = int(time.time() * 1000)
        self.cookie = f'novel_web_id={base_timestamp}'
        
        # ä¿å­˜cookieåˆ°æ–‡ä»¶
        try:
            with open(self.cookie_path, 'w', encoding='UTF-8') as f:
                json.dump(self.cookie, f)
        except Exception:
            pass  # å¿½ç•¥ä¿å­˜å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å†…å­˜ä¸­çš„cookie
            
        self.log_callback('Cookieåˆå§‹åŒ–å®Œæˆ')

    def _default_progress(self, current: int, total: int, desc: str = '',
                          chapter_title: str = None):
        """Progress tracking for both CLI and web"""
        # For CLI: Don't create additional progress bar, tqdm is already handled in download_novel
        # For web: Return progress info as dict
        return {
            'current': current,
            'total': total,
            'percentage': (current / total * 100) if total > 0 else 0,
            'description': desc,
            'chapter_title': chapter_title
        }
    
    def _write_debug_log(self, message: str):
        """å†™å…¥è°ƒè¯•æ—¥å¿—åˆ°æ–‡ä»¶å’Œæ§åˆ¶å°"""
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_message = f"[{timestamp}] {message}"
        
        # è¾“å‡ºåˆ°æ§åˆ¶å°ï¼ˆå¦‚æœå¯ç”¨äº†è¯¦ç»†æ—¥å¿—ï¼‰
        if hasattr(self.config, 'log_level') and self.config.log_level == 'debug':
            self.log_callback(log_message)
        
        # å†™å…¥æ—¥å¿—æ–‡ä»¶
        log_dir = "logs"
        os.makedirs(log_dir, exist_ok=True)
        log_file = os.path.join(log_dir, "download_debug.log")
        
        try:
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(log_message + '\n')
        except Exception as e:
            # é¿å…æ—¥å¿—å†™å…¥å¤±è´¥å½±å“ä¸»ç¨‹åº
            pass

    def download_novel(self, novel_id: int) -> str:
        """Download a novel"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nå¼€å§‹ä¸‹è½½ã€Š{name}ã€‹ï¼ŒçŠ¶æ€ï¼š{status[0]}')

            # åˆ›å»º"ä¹¦å-id"æ–‡ä»¶å¤¹ç»“æ„
            book_folder_name = f"{safe_name}-{novel_id}"
            book_download_dir = os.path.join(self.download_dir, book_folder_name)    # å…¶ä»–æ ¼å¼æ–‡ä»¶ç›®å½•
            book_json_dir = os.path.join(self.bookstore_dir, book_folder_name)       # JSONæ–‡ä»¶ç›®å½•
            chapters_dir = os.path.join(book_download_dir, "Chapters")
            
            # åˆ›å»ºå¿…éœ€çš„ç›®å½•
            os.makedirs(book_download_dir, exist_ok=True)
            os.makedirs(book_json_dir, exist_ok=True) 
            os.makedirs(chapters_dir, exist_ok=True)
            
            self.log_callback(f'åˆ›å»ºæ–‡ä»¶å¤¹: {book_folder_name}')

            # ä½¿ç”¨åŸå§‹ç« èŠ‚åˆ—è¡¨çš„é¡ºåº
            chapter_list = list(chapters.items())  # è½¬æ¢ä¸ºåˆ—è¡¨ä¿æŒé¡ºåº
            total_chapters = len(chapter_list)
            completed_chapters = 0

            # åˆ›å»ºä¸€ä¸ªæœ‰åºå­—å…¸æ¥ä¿å­˜ç« èŠ‚å†…å®¹
            novel_content = {}

            # ä¸‹è½½ç« èŠ‚
            with tqdm(total=total_chapters, desc='ä¸‹è½½è¿›åº¦') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter,
                            title,
                            chapter_id,
                            {}
                        ): (title, chapter_id) for title, chapter_id in chapter_list
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        title, chapter_id = future_to_chapter[future]
                        try:
                            content = future.result()
                            if content:
                                # è®°å½•è¯¦ç»†çš„ç« èŠ‚ä¸‹è½½ä¿¡æ¯
                                self._write_debug_log(f"âœ… æˆåŠŸä¸‹è½½ç« èŠ‚: ã€Œ{title}ã€(ID: {chapter_id}) - å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                                
                                # ğŸš¨ å…³é”®è°ƒè¯•ç‚¹ï¼šæ£€æŸ¥æ ‡é¢˜å¤„ç†è¿‡ç¨‹
                                self._write_debug_log(f"ğŸ” ã€æ–‡ä»¶ä¿å­˜è°ƒè¯•ã€‘å¼€å§‹å¤„ç†ç« èŠ‚æ–‡ä»¶ä¿å­˜")
                                self._write_debug_log(f"ğŸ” åŸå§‹title: {repr(title)} (ç±»å‹: {type(title).__name__})")
                                
                                clean_title = title.strip()
                                self._write_debug_log(f"ğŸ” clean_title: {repr(clean_title)} (ç±»å‹: {type(clean_title).__name__})")
                                
                                novel_content[clean_title] = content
                                
                                # ğŸš¨ å…³é”®è°ƒè¯•ç‚¹ï¼šæ–‡ä»¶åç”Ÿæˆè¿‡ç¨‹
                                self._write_debug_log(f"ğŸ” è°ƒç”¨_sanitize_filenameå‰: {repr(clean_title)}")
                                sanitized_title = self._sanitize_filename(clean_title)
                                self._write_debug_log(f"ğŸ” _sanitize_filenameè¿”å›: {repr(sanitized_title)} (ç±»å‹: {type(sanitized_title).__name__})")
                                
                                chapter_filename = f"{sanitized_title}.txt"
                                self._write_debug_log(f"ğŸ” chapter_filename: {repr(chapter_filename)} (ç±»å‹: {type(chapter_filename).__name__})")
                                
                                # ğŸš¨ å…³é”®è°ƒè¯•ç‚¹ï¼šè·¯å¾„æ‹¼æ¥è¿‡ç¨‹
                                self._write_debug_log(f"ğŸ” chapters_dir: {repr(chapters_dir)} (ç±»å‹: {type(chapters_dir).__name__})")
                                self._write_debug_log(f"ğŸ” å‡†å¤‡è°ƒç”¨os.path.join({repr(chapters_dir)}, {repr(chapter_filename)})")
                                
                                chapter_path = os.path.join(chapters_dir, chapter_filename)
                                self._write_debug_log(f"ğŸ” chapter_path: {repr(chapter_path)} (ç±»å‹: {type(chapter_path).__name__})")
                                
                                # ğŸš¨ å…³é”®è°ƒè¯•ç‚¹ï¼šæ–‡ä»¶å†™å…¥è¿‡ç¨‹
                                self._write_debug_log(f"ğŸ” å‡†å¤‡æ‰“å¼€æ–‡ä»¶: {repr(chapter_path)}")
                                with open(chapter_path, 'w', encoding='UTF-8') as f:
                                    f.write(f"{clean_title}\n\n{content}")
                                self._write_debug_log(f"âœ… ç« èŠ‚æ–‡ä»¶ä¿å­˜æˆåŠŸ: {chapter_path}")
                            else:
                                # å†…å®¹ä¸ºç©ºçš„æƒ…å†µ
                                self._write_debug_log(f"âš ï¸ ç« èŠ‚å†…å®¹ä¸ºç©º: ã€Œ{title}ã€(ID: {chapter_id})")
                                self.log_callback(f"âš ï¸ ç« èŠ‚ã€Œ{title}ã€ä¸‹è½½å¤±è´¥: å†…å®¹ä¸ºç©º")
                                    
                        except Exception as e:
                            # ğŸš¨ğŸš¨ğŸš¨ å®Œæ•´çš„é”™è¯¯ä¿¡æ¯è¾“å‡º - ç”¨æˆ·å¼ºè°ƒçš„å…³é”®éœ€æ±‚ï¼ğŸš¨ğŸš¨ğŸš¨
                            self._write_debug_log(f"âŒâŒâŒ ã€å®Œæ•´é”™è¯¯æŠ¥å‘Šã€‘ç« èŠ‚ä¸‹è½½å¼‚å¸¸: ã€Œ{title}ã€(ID: {chapter_id}) âŒâŒâŒ")
                            self._write_debug_log(f"=" * 100)
                            
                            # åŸºæœ¬ä¿¡æ¯
                            self._write_debug_log(f"ğŸ” æ ‡é¢˜ä¿¡æ¯:")
                            self._write_debug_log(f"   - æ ‡é¢˜ç±»å‹: {type(title).__name__}")
                            self._write_debug_log(f"   - æ ‡é¢˜å†…å®¹: {repr(title)}")
                            self._write_debug_log(f"   - æ ‡é¢˜é•¿åº¦: {len(title) if title else 'None'}")
                            self._write_debug_log(f"ğŸ” ç« èŠ‚IDä¿¡æ¯:")
                            self._write_debug_log(f"   - ç« èŠ‚IDç±»å‹: {type(chapter_id).__name__}")
                            self._write_debug_log(f"   - ç« èŠ‚IDå†…å®¹: {repr(chapter_id)}")
                            
                            # é”™è¯¯è¯¦æƒ…
                            self._write_debug_log(f"âŒ é”™è¯¯è¯¦æƒ…:")
                            self._write_debug_log(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
                            self._write_debug_log(f"   - é”™è¯¯è¯¦æƒ…: {str(e)}")
                            self._write_debug_log(f"   - é”™è¯¯å‚æ•°: {getattr(e, 'args', 'No args')}")
                            self._write_debug_log(f"   - å®Œæ•´å¼‚å¸¸ä¿¡æ¯: {repr(e)}")
                            
                            # ğŸš¨ å…³é”®ï¼šå°è¯•è·å–è¯¥ç« èŠ‚çš„å®Œæ•´å“åº”å†…å®¹
                            self._write_debug_log(f"ğŸŒ å°è¯•è·å–è¯¥ç« èŠ‚çš„å®Œæ•´ç½‘ç»œå“åº”:")
                            try:
                                # å¼ºåˆ¶è·å–è¯¥ç« èŠ‚çš„åŸå§‹å“åº”
                                test_content = self._download_chapter_content(int(chapter_id), test_mode=True)
                                self._write_debug_log(f"ğŸ“¥ åŸå§‹å“åº”å†…å®¹ç±»å‹: {type(test_content).__name__}")
                                self._write_debug_log(f"ğŸ“¥ åŸå§‹å“åº”é•¿åº¦: {len(test_content) if test_content else 'None'}")
                                self._write_debug_log(f"ğŸ“¥ åŸå§‹å“åº”å‰500å­—ç¬¦: {repr(test_content[:500]) if test_content else 'None'}")
                                if test_content and len(test_content) > 500:
                                    self._write_debug_log(f"ğŸ“¥ åŸå§‹å“åº”å200å­—ç¬¦: {repr(test_content[-200:])}")
                                self._write_debug_log(f"ğŸ“¥ å®Œæ•´åŸå§‹å“åº”: {repr(test_content)}")
                            except Exception as response_error:
                                self._write_debug_log(f"ğŸ’¥ è·å–åŸå§‹å“åº”å¤±è´¥: {str(response_error)}")
                                self._write_debug_log(f"ğŸ’¥ å“åº”é”™è¯¯ç±»å‹: {type(response_error).__name__}")
                                self._write_debug_log(f"ğŸ’¥ å“åº”é”™è¯¯è¯¦æƒ…: {repr(response_error)}")
                            
                            # ç¯å¢ƒçŠ¶æ€ä¿¡æ¯
                            self._write_debug_log(f"ğŸŒ ç¯å¢ƒçŠ¶æ€:")
                            self._write_debug_log(f"   - chapters_dir: {repr(chapters_dir)}")
                            self._write_debug_log(f"   - chapters_dirç±»å‹: {type(chapters_dir).__name__}")
                            self._write_debug_log(f"   - chapters_dirå­˜åœ¨: {os.path.exists(chapters_dir) if chapters_dir else 'chapters_dir is None'}")
                            self._write_debug_log(f"   - å½“å‰å·¥ä½œç›®å½•: {repr(os.getcwd())}")
                            
                            # å±€éƒ¨å˜é‡çŠ¶æ€
                            self._write_debug_log(f"ğŸ“Š å±€éƒ¨å˜é‡çŠ¶æ€:")
                            local_vars = ['content', 'clean_title', 'sanitized_title', 'chapter_filename', 'chapter_path']
                            for var_name in local_vars:
                                if var_name in locals():
                                    var_value = locals()[var_name]
                                    self._write_debug_log(f"   - {var_name}: {repr(var_value)} (ç±»å‹: {type(var_value).__name__})")
                                else:
                                    self._write_debug_log(f"   - {var_name}: æœªå®šä¹‰")
                            
                            # ç‰¹æ®Šå¤„ç†è·¯å¾„ç›¸å…³é”™è¯¯
                            if "PathLike" in str(e) or "NoneType" in str(e):
                                self._write_debug_log(f"ğŸš¨ æ£€æµ‹åˆ°è·¯å¾„æˆ–NoneTypeé”™è¯¯ - æ·±åº¦åˆ†æ:")
                                
                                # æµ‹è¯•_sanitize_filenameå‡½æ•°
                                try:
                                    test_title = title.strip() if title else "ERROR_None_Title"
                                    sanitized = self._sanitize_filename(test_title)
                                    self._write_debug_log(f"   ğŸ”§ _sanitize_filenameæµ‹è¯•: {repr(test_title)} -> {repr(sanitized)}")
                                except Exception as sanitize_error:
                                    self._write_debug_log(f"   ğŸ’¥ _sanitize_filenameæµ‹è¯•å¤±è´¥: {str(sanitize_error)}")
                                    self._write_debug_log(f"   ğŸ’¥ _sanitize_filenameé”™è¯¯è¯¦æƒ…: {repr(sanitize_error)}")
                            
                            self._write_debug_log(f"=" * 100)
                            self._write_debug_log(f"âŒâŒâŒ ã€å®Œæ•´é”™è¯¯æŠ¥å‘Šç»“æŸã€‘ âŒâŒâŒ")
                            
                            # è¾“å‡ºåˆ°æ§åˆ¶å°è®©ç”¨æˆ·çœ‹åˆ°çœŸæ­£çš„é—®é¢˜
                            self.log_callback(f'âŒ ä¸‹è½½ç« èŠ‚å¤±è´¥ã€Œ{title}ã€: {str(e)}')
                            
                            # ç»§ç»­å¤„ç†å…¶ä»–ç« èŠ‚ï¼Œä½†ä¿ç•™å®Œæ•´çš„é”™è¯¯è®°å½•

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            'ä¸‹è½½è¿›åº¦',
                            title
                        )

            # æ ¹æ®é…ç½®å†³å®šä¿å­˜å“ªäº›æ ¼å¼
            results = []
            
            # ä¿å­˜JSONæ–‡ä»¶ï¼ˆå¿…é¡»è¦çš„ï¼‰
            json_path = os.path.join(book_json_dir, f'{safe_name}.json')
            with open(json_path, 'w', encoding='UTF-8') as f:
                json.dump(novel_content, f, ensure_ascii=False, indent=4)
            self.log_callback(f'âœ… JSONæ–‡ä»¶å·²ä¿å­˜: {json_path}')
            results.append('json')
            
            # ä¿å­˜TXTæ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.config.enable_txt:
                result = self._save_single_txt_to_folder(safe_name, novel_content, book_download_dir)
                if result == 's':
                    self.log_callback(f'âœ… TXTæ–‡ä»¶å·²ä¿å­˜')
                    results.append('txt')
                    
                    # å¦‚æœé…ç½®è¦æ±‚åˆ é™¤ç« èŠ‚æ–‡ä»¶å¤¹
                    if self.config.delete_chapters_after_merge:
                        try:
                            import shutil
                            shutil.rmtree(chapters_dir)
                            self.log_callback(f'ğŸ—‘ï¸ å·²åˆ é™¤ç« èŠ‚æ–‡ä»¶å¤¹: {chapters_dir}')
                        except Exception as e:
                            self.log_callback(f'âš ï¸ åˆ é™¤ç« èŠ‚æ–‡ä»¶å¤¹å¤±è´¥: {e}')
            
            # ä¿å­˜EPUBæ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.config.enable_epub:
                try:
                    epub_result = self._save_epub_from_content(safe_name, novel_content, book_download_dir, novel_id)
                    if epub_result == 's':
                        self.log_callback(f'âœ… EPUBæ–‡ä»¶å·²ä¿å­˜')
                        results.append('epub')
                except Exception as e:
                    self.log_callback(f'âš ï¸ EPUBä¿å­˜å¤±è´¥: {e}')
            
            # ä¿å­˜HTMLæ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.config.enable_html:
                try:
                    html_result = self._save_html_from_content(safe_name, novel_content, book_download_dir)
                    if html_result == 's':
                        self.log_callback(f'âœ… HTMLæ–‡ä»¶å·²ä¿å­˜')
                        results.append('html')
                except Exception as e:
                    self.log_callback(f'âš ï¸ HTMLä¿å­˜å¤±è´¥: {e}')
            
            # ä¿å­˜LaTeXæ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.config.enable_latex:
                try:
                    latex_result = self._save_latex_from_content(safe_name, novel_content, book_download_dir)
                    if latex_result == 's':
                        self.log_callback(f'âœ… LaTeXæ–‡ä»¶å·²ä¿å­˜')
                        results.append('latex')
                        
                        # å¦‚æœä¹Ÿå¯ç”¨äº†PDFï¼Œä»LaTeXç”ŸæˆPDF
                        if self.config.enable_pdf:
                            try:
                                pdf_result = self._generate_pdf_from_latex(safe_name, book_download_dir)
                                if pdf_result == 's':
                                    self.log_callback(f'âœ… PDFæ–‡ä»¶å·²ä¿å­˜')
                                    results.append('pdf')
                            except Exception as e:
                                self.log_callback(f'âš ï¸ PDFç”Ÿæˆå¤±è´¥: {e}')
                except Exception as e:
                    self.log_callback(f'âš ï¸ LaTeXä¿å­˜å¤±è´¥: {e}')
            elif self.config.enable_pdf:
                # å¦‚æœåªå¯ç”¨äº†PDFè€Œæ²¡æœ‰å¯ç”¨LaTeXï¼Œå…ˆç”ŸæˆLaTeXå†è½¬PDF
                try:
                    latex_result = self._save_latex_from_content(safe_name, novel_content, book_download_dir)
                    if latex_result == 's':
                        pdf_result = self._generate_pdf_from_latex(safe_name, book_download_dir)
                        if pdf_result == 's':
                            self.log_callback(f'âœ… PDFæ–‡ä»¶å·²ä¿å­˜')
                            results.append('pdf')
                            # åˆ é™¤ä¸´æ—¶LaTeXæ–‡ä»¶
                            try:
                                latex_path = os.path.join(book_download_dir, f'{safe_name}.tex')
                                if os.path.exists(latex_path):
                                    os.remove(latex_path)
                            except:
                                pass
                except Exception as e:
                    self.log_callback(f'âš ï¸ PDFç”Ÿæˆå¤±è´¥: {e}')
            
            # è¿”å›ç»“æœ
            if results:
                self.log_callback(f'ğŸ‰ ä¸‹è½½å®Œæˆï¼å·²ä¿å­˜æ ¼å¼: {", ".join(results)}')
                return 's'
            else:
                self.log_callback(f'âš ï¸ æœªå¯ç”¨ä»»ä½•è¾“å‡ºæ ¼å¼')
                return 'err'

        except Exception as e:
            self.log_callback(f'ä¸‹è½½å¤±è´¥: {str(e)}')
            return 'err'

    def search_novel(self, keyword: str) -> List[Dict]:
        """
        Search for novels by keyword
        Returns list of novel info dictionaries
        """
        if not keyword:
            return []

        # Use the correct API endpoint from ref_main.py
        url = f"https://api5-normal-lf.fqnovel.com/reading/bookapi/search/page/v/"
        params = {
            "query": keyword,
            "aid": "1967",
            "channel": "0",
            "os_version": "0",
            "device_type": "0",
            "device_platform": "0",
            "iid": "466614321180296",
            "passback": "{(page-1)*10}",
            "version_code": "999"
        }

        try:
            response = req.get(url, params=params, headers=self.headers)
            response.raise_for_status()
            data = response.json()

            if data['code'] == 0 and data['data']:
                return data['data']
            else:
                self.log_callback("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¹¦ç±ã€‚")
                return []

        except req.RequestException as e:
            self.log_callback(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
            return []
        except json.JSONDecodeError as e:
            self.log_callback(f"è§£ææœç´¢ç»“æœå¤±è´¥: {str(e)}")
            return []
        except Exception as e:
            self.log_callback(f'æœç´¢å¤±è´¥: {str(e)}')
            return []

    # ... Additional helper methods would go here ...

    def _get_initial_chapter_id(self) -> int:
        """Get an initial chapter ID for cookie testing"""
        test_novel_id = 7143038691944959011  # Example novel ID
        chapters = self._get_chapter_list(test_novel_id)
        if chapters and len(chapters[1]) > 21:
            return int(random.choice(list(chapters[1].values())[21:]))
        raise Exception("Failed to get initial chapter ID")

    def _get_new_cookie(self, chapter_id: int):
        """Generate new cookie - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œå‡å°‘éªŒè¯æ¬¡æ•°"""
        base_timestamp = int(time.time() * 1000)
        
        # åªå°è¯•5æ¬¡ï¼Œå‡å°‘ç­‰å¾…æ—¶é—´
        for i in range(5):
            cookie_id = base_timestamp + random.randint(1000, 999999)
            time.sleep(0.1)  # å‡å°‘å»¶è¿Ÿåˆ°100ms
            self.cookie = f'novel_web_id={cookie_id}'
            
            try:
                if len(self._download_chapter_content(chapter_id, test_mode=True)) > 200:
                    with open(self.cookie_path, 'w', encoding='UTF-8') as f:
                        json.dump(self.cookie, f)
                    return
            except:
                continue
        
        # å¿«é€Ÿå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤cookie
        self.cookie = f'novel_web_id={base_timestamp}'
        print("âš ï¸ Cookieç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")

    def _download_txt(self, novel_id: int) -> str:
        """Download novel in TXT format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nå¼€å§‹ä¸‹è½½ã€Š{name}ã€‹ï¼ŒçŠ¶æ€ï¼š{status[0]}')

            # Set book_json_path for the current download
            self.book_json_path = os.path.join(self.bookstore_dir, f'{safe_name}.json')

            # Initialize global variables for this download
            self.zj = {}
            self.cs = 0
            self.tcs = 0

            # Store metadata at the start
            metadata = {
                '_metadata': {
                    'novel_id': str(novel_id),  # ç¡®ä¿å­˜å‚¨ä¸ºå­—ç¬¦ä¸²
                    'name': name,
                    'status': status[0] if status else None,
                    'last_updated': time.strftime('%Y-%m-%d %H:%M:%S')
                }
            }

            # Load existing content and merge with metadata
            existing_content = {}
            if os.path.exists(self.book_json_path):
                with open(self.book_json_path, 'r', encoding='UTF-8') as f:
                    existing_content = json.load(f)
                    # Keep existing chapters but update metadata
                    if isinstance(existing_content, dict):
                        existing_content.update(metadata)
            else:
                existing_content = metadata
                # Save initial metadata
                with open(self.book_json_path, 'w', encoding='UTF-8') as f:
                    json.dump(existing_content, f, ensure_ascii=False)

            total_chapters = len(chapters)
            completed_chapters = 0

            # Create CLI progress bar
            with tqdm(total=total_chapters, desc='ä¸‹è½½è¿›åº¦') as pbar:
                # Download chapters
                content = existing_content.copy()  # Start with existing content including metadata
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter,
                            title,
                            chapter_id,
                            existing_content
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            chapter_content = future.result()
                            if chapter_content:
                                content[chapter_title] = chapter_content
                                # Save progress periodically
                                if completed_chapters % 5 == 0:
                                    with open(self.book_json_path, 'w', encoding='UTF-8') as f:
                                        json.dump(content, f, ensure_ascii=False)
                        except Exception as e:
                            self.log_callback(f'ä¸‹è½½ç« èŠ‚å¤±è´¥ {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            'ä¸‹è½½è¿›åº¦',
                            chapter_title
                        )

                # Save final content
                with open(self.book_json_path, 'w', encoding='UTF-8') as f:
                    json.dump(content, f, ensure_ascii=False)

                # Generate output file
                if self.config.save_mode == SaveMode.SINGLE_TXT:
                    return self._save_single_txt(safe_name, content)
                else:
                    return self._save_split_txt(safe_name, content)

        finally:
            # Send 100% completion if not already sent
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, 'ä¸‹è½½å®Œæˆ')

    def _download_epub(self, novel_id: int) -> str:
        """Download novel in EPUB format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nå¼€å§‹ä¸‹è½½ã€Š{name}ã€‹ï¼ŒçŠ¶æ€ï¼š{status[0]}')

            # Create EPUB book
            book = epub.EpubBook()
            book.set_title(name)
            book.set_language('zh')

            # Get author info and cover
            author = self._get_author_info(novel_id)
            if author:
                book.add_author(author)
            cover_url = self._get_cover_url(novel_id)
            if cover_url:
                self._add_cover_to_epub(book, cover_url)

            total_chapters = len(chapters)
            completed_chapters = 0

            # Download chapters with progress tracking
            epub_chapters = []
            with tqdm(total=total_chapters, desc='ä¸‹è½½è¿›åº¦') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter_for_epub,
                            title,
                            chapter_id
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            epub_chapter = future.result()
                            if epub_chapter:
                                epub_chapters.append((chapter_title, epub_chapter))
                        except Exception as e:
                            self.log_callback(f'ä¸‹è½½ç« èŠ‚å¤±è´¥ {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            'ä¸‹è½½è¿›åº¦',
                            chapter_title
                        )

            # Sort chapters by their original order
            epub_chapters.sort(key=lambda x: list(chapters.keys()).index(x[0]))
            for _, chapter in epub_chapters:
                book.add_item(chapter)

            # Add navigation
            book.toc = [chapter for _, chapter in epub_chapters]
            book.spine = ['nav'] + [chapter for _, chapter in epub_chapters]
            book.add_item(epub.EpubNcx())
            book.add_item(epub.EpubNav())

            # Save EPUB file
            epub_path = os.path.join(self.config.save_path, f'{safe_name}.epub')
            epub.write_epub(epub_path, book)
            return 's'

        finally:
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, 'ä¸‹è½½å®Œæˆ')

    def _download_chapter(self, title: str, chapter_id: str, existing_content: Dict) -> Optional[str]:
        """Download a single chapter with retries and intelligent error handling"""
        if title in existing_content:
            self.zj[title] = existing_content[title]
            return existing_content[title]

        self.log_callback(f'ä¸‹è½½ç« èŠ‚: {title}')
        retries = self.config.retry_count
        last_error = None
        
        # è¯¦ç»†è®°å½•é‡è¯•è¿‡ç¨‹
        self._write_debug_log(f"ğŸ”„ å¼€å§‹ä¸‹è½½ç« èŠ‚ã€Œ{title}ã€(ID: {chapter_id}) - æœ€å¤§é‡è¯•æ¬¡æ•°: {retries}")
        self._write_debug_log(f"ğŸ“‹ é‡è¯•é—´éš”é…ç½®: {self.config.retry_delays}")

        while retries > 0:
            try:
                self._write_debug_log(f"ğŸ“¡ å°è¯•ä¸‹è½½ç« èŠ‚ã€Œ{title}ã€- å‰©ä½™é‡è¯•æ¬¡æ•°: {retries}")
                
                content = self._download_chapter_content(chapter_id)
                
                # ç»Ÿä¸€å¤„ç†å„ç§å¤±è´¥æƒ…å†µ
                if content == 'err' or not content or not content.strip():
                    self.tcs += 1
                    
                    if content == 'err':
                        error_msg = "APIè¿”å›é”™è¯¯"
                    elif not content:
                        error_msg = "è¿”å›å†…å®¹ä¸ºNone"
                    else:
                        error_msg = "è¿”å›å†…å®¹ä¸ºç©ºå­—ç¬¦ä¸²"
                    
                    # æ›´æ–°åçˆ¬æ£€æµ‹ç»Ÿè®¡
                    self.empty_content_count += 1
                    self.total_empty_count += 1
                    
                    # æ£€æµ‹åçˆ¬æƒ…å†µå¹¶è°ƒæ•´ç­–ç•¥
                    if self.empty_content_count >= 3:
                        self.adaptive_delay_multiplier = min(5.0, self.adaptive_delay_multiplier + 0.5)
                        self._write_debug_log(f"ğŸš¨ è¿ç»­å¤±è´¥ {self.empty_content_count} æ¬¡ï¼Œç–‘ä¼¼åçˆ¬æ£€æµ‹ï¼")
                        self._write_debug_log(f"ğŸ“Š è°ƒæ•´å»¶æ—¶å€æ•°è‡³: {self.adaptive_delay_multiplier:.1f}")
                        self.log_callback(f"ğŸš¨ æ£€æµ‹åˆ°è¿ç»­å¤±è´¥ï¼Œå·²è°ƒæ•´ä¸‹è½½ç­–ç•¥")
                    
                    # è®°å½•è¯¦ç»†çš„å¤±è´¥ä¿¡æ¯
                    time_since_success = time.time() - self.last_successful_time
                    self._write_debug_log(f"âš ï¸ ç« èŠ‚ã€Œ{title}ã€ä¸‹è½½å¼‚å¸¸: {error_msg}")
                    self._write_debug_log(f"ğŸ“Š å¤±è´¥ç»Ÿè®¡ - è¿ç»­: {self.empty_content_count}, æ€»è®¡: {self.total_empty_count}")
                    self._write_debug_log(f"â° è·ç¦»ä¸Šæ¬¡æˆåŠŸ: {time_since_success:.1f}ç§’")
                    
                    # Cookie åˆ·æ–°æœºåˆ¶
                    if self.tcs > 7:
                        self.tcs = 0
                        self._write_debug_log(f"ğŸ”„ è§¦å‘Cookieåˆ·æ–° (chapter_id: {chapter_id})")
                        self._get_new_cookie(self.tzj)
                        self.log_callback(f"ğŸ”„ æ£€æµ‹åˆ°å¤šæ¬¡å¤±è´¥ï¼Œå·²åˆ·æ–°Cookie")
                    
                    raise Exception(f"Chapter download failed: {error_msg}")

                # æˆåŠŸæ—¶æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.empty_content_count = 0  # é‡ç½®è¿ç»­ç©ºå†…å®¹è®¡æ•°
                self.last_successful_time = time.time()
                
                # æ ¹æ®æˆåŠŸæƒ…å†µè°ƒæ•´å»¶æ—¶å€æ•°
                if self.adaptive_delay_multiplier > 1.0:
                    self.adaptive_delay_multiplier = max(1.0, self.adaptive_delay_multiplier - 0.1)
                    self._write_debug_log(f"ğŸ“ˆ ä¸‹è½½æˆåŠŸï¼Œé™ä½å»¶æ—¶å€æ•°è‡³: {self.adaptive_delay_multiplier:.1f}")
                
                # è‡ªé€‚åº”å»¶æ—¶
                base_delay_ms = random.randint(self.config.delay[0], self.config.delay[1])
                actual_delay_ms = int(base_delay_ms * self.adaptive_delay_multiplier)
                self._write_debug_log(f"â±ï¸ ç« èŠ‚ã€Œ{title}ã€ä¸‹è½½æˆåŠŸï¼Œå»¶æ—¶ {actual_delay_ms}ms (åŸºç¡€:{base_delay_ms}ms Ã— å€æ•°:{self.adaptive_delay_multiplier:.1f})")
                time.sleep(actual_delay_ms / 1000)

                # Save progress periodically
                self.cs += 1
                if self.cs >= 5:
                    self.cs = 0
                    self._save_progress(title, content)

                self.zj[title] = content
                self._write_debug_log(f"âœ… ç« èŠ‚ã€Œ{title}ã€ä¸‹è½½å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                return content

            except Exception as e:
                last_error = e
                retries -= 1
                
                self._write_debug_log(f"âŒ ç« èŠ‚ã€Œ{title}ã€é‡è¯•å¤±è´¥: {str(e)} (å‰©ä½™é‡è¯•: {retries})")
                
                if retries > 0:
                    # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é‡è¯•é—´éš”
                    attempt_index = self.config.retry_count - retries
                    if attempt_index < len(self.config.retry_delays):
                        retry_delay = self.config.retry_delays[attempt_index]
                    else:
                        # å¦‚æœé‡è¯•æ¬¡æ•°è¶…è¿‡é…ç½®çš„é—´éš”æ•°ç»„ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªå€¼
                        retry_delay = self.config.retry_delays[-1]
                    
                    # ğŸš¨ ç”¨æˆ·è¦æ±‚ï¼šæ˜ç¡®å¤±è´¥åŸå› 
                    failure_reason = self._get_failure_reason(e)
                    
                    # ğŸš¨ ç”¨æˆ·è¦æ±‚ï¼šé‡è¯•æ—¶çš„Cookieåˆ·æ–°æ£€æŸ¥
                    cookie_action = ""
                    if self.tcs > 3:  # é™ä½Cookieåˆ·æ–°é˜ˆå€¼ï¼Œè®©é‡è¯•æ—¶æ›´å®¹æ˜“è§¦å‘
                        self.tcs = 0
                        # ä¿®å¤Cookieåˆ·æ–°ï¼šä½¿ç”¨æœ‰æ•ˆçš„chapter_id
                        effective_chapter_id = int(chapter_id) if chapter_id else (self.tzj if self.tzj else 1)
                        self._write_debug_log(f"ğŸ”„ é‡è¯•æ—¶è§¦å‘Cookieåˆ·æ–° (effective_chapter_id: {effective_chapter_id})")
                        self._get_new_cookie(effective_chapter_id)
                        cookie_action = " (å·²åˆ·æ–°Cookie)"
                    
                    self._write_debug_log(f"â³ ç­‰å¾… {retry_delay}s åé‡è¯•... (é‡è¯•é—´éš”é…ç½®ç´¢å¼•: {attempt_index})")
                    
                    # ğŸš¨ ç”¨æˆ·è¦æ±‚ï¼šåŒ…å«å…·ä½“å¤±è´¥åŸå› çš„é‡è¯•æ—¥å¿—
                    self.log_callback(f"âš ï¸ ç« èŠ‚ã€Œ{title}ã€ä¸‹è½½å¤±è´¥ ({failure_reason})ï¼Œ{retry_delay}såé‡è¯• (å‰©ä½™{retries}æ¬¡){cookie_action}")
                    
                    # å¿…è¦æ—¶è¾“å‡ºå®Œæ•´å“åº”
                    if "å†…å®¹ä¸ºç©º" not in failure_reason and "ç½‘ç»œ" not in failure_reason:
                        self._write_debug_log(f"ğŸ“¥ é‡è¯•å‰è·å–å®Œæ•´å“åº”å†…å®¹:")
                        try:
                            debug_content = self._download_chapter_content(int(chapter_id), test_mode=True)
                            self._write_debug_log(f"ğŸ“¥ å®Œæ•´å“åº”: {repr(debug_content[:1000])}{'...' if len(debug_content) > 1000 else ''}")
                        except:
                            self._write_debug_log(f"ğŸ“¥ æ— æ³•è·å–å“åº”å†…å®¹")
                    
                    time.sleep(retry_delay)
                else:
                    self._write_debug_log(f"ğŸ’¥ ç« èŠ‚ã€Œ{title}ã€æœ€ç»ˆä¸‹è½½å¤±è´¥: {str(e)}")
                    self.log_callback(f'ä¸‹è½½å¤±è´¥ {title}: {str(e)}')

        if last_error:
            raise last_error
        return None

    def _download_chapter_for_epub(self, title: str, chapter_id: str) -> Optional[epub.EpubHtml]:
        """Download and format chapter for EPUB"""
        content = self._download_chapter(title, chapter_id, {})
        if not content:
            return None

        chapter = epub.EpubHtml(
            title=title,
            file_name=f'chapter_{chapter_id}.xhtml',
            lang='zh'
        )

        # ä½¿ç”¨<p>æ ‡ç­¾åŒ…è£¹æ¯ä¸ªæ®µè½ï¼Œç¡®ä¿æ²¡æœ‰å¤šä½™çš„æ¢è¡Œç¬¦
        formatted_content = ''.join(f'<p>{para.strip()}</p>' for para in content.split('\n') if para.strip())
        chapter.content = f'<h1>{title}</h1>{formatted_content}'
        return chapter

    def _save_single_txt(self, name: str, content: dict) -> str:
        """Save all chapters to a single TXT file"""
        output_path = os.path.join(self.download_dir, f'{name}.txt')  # ä¿å­˜åˆ°ä¸‹è½½ç›®å½•
        fg = '\n' + self.config.kgf * self.config.kg

        with open(output_path, 'w', encoding='UTF-8') as f:
            for title, chapter_content in content.items():
                # è·³è¿‡å…ƒæ•°æ®é¡¹
                if title.startswith('_'):
                    continue
                    
                f.write(f'\n{title}{fg}')
                if self.config.kg == 0:
                    f.write(f'{chapter_content}\n')
                else:
                    # å°†æ›¿æ¢ç»“æœå­˜å‚¨åœ¨ä¸€ä¸ªå˜é‡ä¸­
                    modified_content = chapter_content.replace("\n", fg)
                    # åœ¨ f-string ä¸­ä½¿ç”¨è¿™ä¸ªå˜é‡
                    f.write(f'{modified_content}\n')
        
        return 's'  # è¿”å›æˆåŠŸæ ‡è¯†

    def _save_single_txt_to_folder(self, name: str, content: dict, output_dir: str) -> str:
        """Save all chapters to a single TXT file in specified folder with smart chapter ordering"""
        output_path = os.path.join(output_dir, f'{name}.txt')
        fg = '\n' + self.config.kgf * self.config.kg

        # æå–æ‰€æœ‰ç« èŠ‚åŠå…¶ç¼–å·ï¼Œè·³è¿‡å…ƒæ•°æ®
        chapters_with_numbers = []
        for title, chapter_content in content.items():
            if title.startswith('_'):
                continue
            chapter_num = self._extract_chapter_number(title)
            chapters_with_numbers.append((chapter_num, title, chapter_content))
        
        # æŒ‰ç« èŠ‚ç¼–å·æ’åº
        chapters_with_numbers.sort(key=lambda x: x[0])
        
        self.log_callback(f'æŒ‰é¡ºåºåˆå¹¶ç« èŠ‚: å…± {len(chapters_with_numbers)} ç« ')
        
        with open(output_path, 'w', encoding='UTF-8') as f:
            if not chapters_with_numbers:
                f.write('æš‚æ— ç« èŠ‚å†…å®¹\n')
                return 's'
            
            # è·å–ç« èŠ‚ç¼–å·èŒƒå›´
            min_chapter = chapters_with_numbers[0][0]
            max_chapter = chapters_with_numbers[-1][0]
            
            # åˆ›å»ºç« èŠ‚å­—å…¸ä»¥ä¾¿å¿«é€ŸæŸ¥æ‰¾
            chapter_dict = {num: (title, content) for num, title, content in chapters_with_numbers}
            
            # æŒ‰é¡ºåºå†™å…¥ç« èŠ‚ï¼Œå¤„ç†ç¼ºå¤±ç« èŠ‚
            for chapter_num in range(min_chapter, max_chapter + 1):
                if chapter_num in chapter_dict:
                    title, chapter_content = chapter_dict[chapter_num]
                    f.write(f'\n{title}{fg}')
                    if self.config.kg == 0:
                        f.write(f'{chapter_content}\n')
                    else:
                        modified_content = chapter_content.replace("\n", fg)
                        f.write(f'{modified_content}\n')
                else:
                    # å¤„ç†ç¼ºå¤±ç« èŠ‚
                    missing_title = f'ç¬¬ {chapter_num} ç«  å½“å‰ç« èŠ‚ç¼ºå¤±'
                    f.write(f'\n{missing_title}{fg}')
                    f.write(f'æŠ±æ­‰ï¼Œå½“å‰ç« èŠ‚ä¸‹è½½å¤±è´¥æˆ–æš‚ä¸å¯ç”¨\n')
                    self.log_callback(f'âš ï¸ æ£€æµ‹åˆ°ç¼ºå¤±ç« èŠ‚: ç¬¬ {chapter_num} ç« ')
        
        return 's'  # è¿”å›æˆåŠŸæ ‡è¯†

    def _save_split_txt_to_folder(self, name: str, content: Dict, output_dir: str) -> str:
        """Save each chapter to a separate TXT file in specified folder"""
        chapter_output_dir = os.path.join(output_dir, name)
        os.makedirs(chapter_output_dir, exist_ok=True)

        for title, chapter_content in content.items():
            # è·³è¿‡å…ƒæ•°æ®é¡¹
            if title.startswith('_'):
                continue
                
            chapter_path = os.path.join(
                chapter_output_dir,
                f'{self._sanitize_filename(title)}.txt'
            )
            if self.config.kg == 0:
                replacement_content = chapter_content
            else:
                replacement_content = chapter_content.replace("\n", self.config.kgf * self.config.kg)

            with open(chapter_path, 'w', encoding='UTF-8') as f:
                f.write(f'{replacement_content}\n')

        return 's'

    def _save_split_txt(self, name: str, content: Dict) -> str:
        """Save each chapter to a separate TXT file"""
        output_dir = os.path.join(self.download_dir, name)  # ä¿å­˜åˆ°ä¸‹è½½ç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        for title, chapter_content in content.items():
            chapter_path = os.path.join(
                output_dir,
                f'{self._sanitize_filename(title)}.txt'
            )
            if self.config.kg == 0:
                replacement_content = chapter_content
            else:
                replacement_content = chapter_content.replace("\n", self.config.kgf * self.config.kg)

            with open(chapter_path, 'w', encoding='UTF-8') as f:
                f.write(f'{replacement_content}\n')

        return 's'

    def update_all_novels(self):
        """Update all novels in records"""
        if not os.path.exists(self.record_path):
            self.log_callback("No novels to update")
            return

        with open(self.record_path, 'r', encoding='UTF-8') as f:
            novels = json.load(f)

        for novel_id in novels:
            self.log_callback(f"Updating novel {novel_id}")
            status = self.download_novel(novel_id)
            if not status:
                novels.remove(novel_id)

        with open(self.record_path, 'w', encoding='UTF-8') as f:
            json.dump(novels, f)

    def _download_html(self, novel_id: int) -> str:
        """Download novel in HTML format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            html_dir = os.path.join(self.config.save_path, f"{safe_name}(html)")
            os.makedirs(html_dir, exist_ok=True)

            self.log_callback(f'\nå¼€å§‹ä¸‹è½½ã€Š{name}ã€‹ï¼ŒçŠ¶æ€ï¼š{status[0]}')

            # Create index.html
            toc_content = self._create_html_index(name, chapters)
            with open(os.path.join(html_dir, "index.html"), "w", encoding='UTF-8') as f:
                f.write(toc_content)

            total_chapters = len(chapters)
            completed_chapters = 0

            # Download chapters with progress tracking
            with tqdm(total=total_chapters, desc='ä¸‹è½½è¿›åº¦') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter_for_html,
                            title,
                            chapter_id,
                            html_dir,
                            list(chapters.keys())
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            future.result()
                        except Exception as e:
                            self.log_callback(f'ä¸‹è½½ç« èŠ‚å¤±è´¥ {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            'ä¸‹è½½è¿›åº¦',
                            chapter_title
                        )

            return 's'

        finally:
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, 'ä¸‹è½½å®Œæˆ')

    def _download_latex(self, novel_id: int) -> str:
        """Download novel in LaTeX format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nå¼€å§‹ä¸‹è½½ã€Š{name}ã€‹ï¼ŒçŠ¶æ€ï¼š{status[0]}')

            # Create LaTeX document header
            latex_content = self._create_latex_header(name)

            total_chapters = len(chapters)
            completed_chapters = 0
            chapter_contents = []

            # Download chapters with progress tracking
            with tqdm(total=total_chapters, desc='ä¸‹è½½è¿›åº¦') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter_for_latex,
                            title,
                            chapter_id
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            chapter_content = future.result()
                            if chapter_content:
                                chapter_contents.append((chapter_title, chapter_content))
                        except Exception as e:
                            self.log_callback(f'ä¸‹è½½ç« èŠ‚å¤±è´¥ {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            'ä¸‹è½½è¿›åº¦',
                            chapter_title
                        )

            # Sort chapters and add to document
            chapter_contents.sort(key=lambda x: list(chapters.keys()).index(x[0]))
            for title, content in chapter_contents:
                latex_content += self._format_latex_chapter(title, content)

            # Add document footer and save
            latex_content += "\n\\end{document}"
            latex_path = os.path.join(self.config.save_path, f'{safe_name}.tex')
            with open(latex_path, 'w', encoding='UTF-8') as f:
                f.write(latex_content)

            return 's'

        finally:
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, 'ä¸‹è½½å®Œæˆ')

    def _create_html_index(self, title: str, chapters: Dict[str, str]) -> str:
        """Create HTML index page with CSS styling"""
        return f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title} - ç›®å½•</title>
    <style>
        :root {{
            --bg-color: #f5f5f5;
            --text-color: #333;
            --link-color: #007bff;
            --hover-color: #0056b3;
        }}
        @media (prefers-color-scheme: dark) {{
            :root {{
                --bg-color: #222;
                --text-color: #fff;
                --link-color: #66b0ff;
                --hover-color: #99ccff;
            }}
        }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: var(--bg-color);
            color: var(--text-color);
        }}
        h1 {{
            text-align: center;
            margin-bottom: 30px;
        }}
        .toc {{
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
        }}
        .toc a {{
            color: var(--link-color);
            text-decoration: none;
            display: block;
            padding: 8px 0;
            transition: all 0.2s;
        }}
        .toc a:hover {{
            color: var(--hover-color);
            transform: translateX(10px);
        }}
    </style>
</head>
<body>
    <h1>{title}</h1>
    <div class="toc">
        {''.join(f'<a href="{self._sanitize_filename(title)}.html">{title}</a>' for title in chapters.keys())}
    </div>
</body>
</html>
"""

    def _create_latex_header(self, title: str) -> str:
        """Create LaTeX document header"""
        return f"""\\documentclass[12pt,a4paper]{{article}}
\\usepackage{{ctex}}
\\usepackage{{geometry}}
\\usepackage{{hyperref}}
\\usepackage{{bookmark}}

\\geometry{{
    top=2.54cm,
    bottom=2.54cm,
    left=3.18cm,
    right=3.18cm
}}

\\title{{{title}}}
\\author{{Generated by NovelDownloader}}
\\date{{\\today}}

\\begin{{document}}
\\maketitle
\\tableofcontents
\\newpage
"""

    def _download_chapter_for_html(self, title: str, chapter_id: str, output_dir: str, all_titles: List[str]) -> None:
        """Download and format chapter for HTML"""
        content = self._download_chapter(title, chapter_id, {})
        if not content:
            return

        current_index = all_titles.index(title)
        prev_link = f'<a href="{self._sanitize_filename(all_titles[current_index - 1])}.html">ä¸Šä¸€ç« </a>' if current_index > 0 else ''
        next_link = f'<a href="{self._sanitize_filename(all_titles[current_index + 1])}.html">ä¸‹ä¸€ç« </a>' if current_index < len(
            all_titles) - 1 else ''

        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        /* ... Same CSS variables as index ... */
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.8;
            margin: 0;
            padding: 20px;
            background-color: var(--bg-color);
            color: var(--text-color);
            max-width: 800px;
            margin: 0 auto;
        }}
        .navigation {{
            display: flex;
            justify-content: space-between;
            padding: 20px 0;
            position: sticky;
            top: 0;
            background-color: var(--bg-color);
        }}
        .navigation a {{
            color: var(--link-color);
            text-decoration: none;
            padding: 8px 16px;
            border: 1px solid var(--link-color);
            border-radius: 4px;
        }}
        .content {{
            text-indent: 2em;
            margin-bottom: 40px;
        }}
    </style>
</head>
<body>
    <div class="navigation">
        <a href="index.html">ç›®å½•</a>
        {prev_link}
        {next_link}
    </div>
    <h1>{title}</h1>
    <div class="content">
        {content.replace(chr(10), '<br>' + self.config.kgf * self.config.kg)}
    </div>
    <div class="navigation">
        <a href="index.html">ç›®å½•</a>
        {prev_link}
        {next_link}
    </div>
</body>
</html>
"""

        with open(os.path.join(output_dir, f"{self._sanitize_filename(title)}.html"), "w", encoding='UTF-8') as f:
            f.write(html_content)

    def _download_chapter_for_latex(self, title: str, chapter_id: str) -> Optional[str]:
        """Download and format chapter for LaTeX"""
        content = self._download_chapter(title, chapter_id, {})
        if not content:
            return None
        return self._format_latex_chapter(title, content)

    def _format_latex_chapter(self, title: str, content: str) -> str:
        """Format chapter content for LaTeX"""
        # Escape special LaTeX characters
        special_chars = ['\\', '{', '}', '&', '#', '$', '^', '_', '~', '%']
        for char in special_chars:
            content = content.replace(char, f'\\{char}')
            title = title.replace(char, f'\\{char}')

        # Format content with proper spacing
        content = content.replace('\n', '\n\n' + self.config.kgf * self.config.kg)

        return f"""
\\section{{{title}}}
{content}
"""

    def _test_cookie(self, chapter_id: int, cookie: str) -> str:
        """Test if cookie is valid"""
        self.cookie = cookie
        if len(self._download_chapter_content(chapter_id, test_mode=True)) > 200:
            return 's'
        return 'err'

    def _get_chapter_list(self, novel_id: int) -> tuple:
        """Get novel info and chapter list with detailed logging"""
        url = f'https://fanqienovel.com/page/{novel_id}'
        
        # è¯¦ç»†è®°å½•è¯·æ±‚ä¿¡æ¯
        self._write_debug_log(f"ğŸŒ è¯·æ±‚ç« èŠ‚åˆ—è¡¨: {url}")
        self._write_debug_log(f"ğŸ”‘ ä½¿ç”¨Cookie: {self.cookie}")
        
        response = req.get(url, headers=self.headers)
        self._write_debug_log(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
        self._write_debug_log(f"ğŸ“ å“åº”å†…å®¹é•¿åº¦: {len(response.text)} å­—ç¬¦")
        
        ele = etree.HTML(response.text)

        chapters = {}
        a_elements = ele.xpath('//div[@class="chapter"]/div/a')
        self._write_debug_log(f"ğŸ“š æ‰¾åˆ°ç« èŠ‚å…ƒç´ æ•°é‡: {len(a_elements)}")
        
        if not a_elements:
            self._write_debug_log("âŒ æœªæ‰¾åˆ°ä»»ä½•ç« èŠ‚å…ƒç´ ï¼Œå¯èƒ½æ˜¯é¡µé¢ç»“æ„å˜åŒ–æˆ–è®¿é—®å—é™")
            return 'err', {}, []

        null_title_count = 0
        valid_chapters = 0
        
        for i, a in enumerate(a_elements):
            href = a.xpath('@href')
            if not href:
                self._write_debug_log(f"âš ï¸ ç¬¬{i+1}ä¸ªç« èŠ‚å…ƒç´ ç¼ºå°‘hrefå±æ€§")
                continue
                
            chapter_title = a.text
            chapter_id = href[0].split('/')[-1]
            
            # è¯¦ç»†è®°å½•æ¯ä¸ªç« èŠ‚çš„ä¿¡æ¯
            if not chapter_title or not chapter_title.strip():
                null_title_count += 1
                self._write_debug_log(f"ğŸš¨ ç¬¬{i+1}ä¸ªç« èŠ‚æ ‡é¢˜ä¸ºç©º! ç« èŠ‚ID: {chapter_id}")
                self._write_debug_log(f"   - å…ƒç´ HTML: {etree.tostring(a, encoding='unicode')[:200]}")
                # ä¸ç”Ÿæˆå‡æ ‡é¢˜ï¼Œä¿ç•™é—®é¢˜è®©ç”¨æˆ·çŸ¥é“
                continue
            else:
                chapters[chapter_title.strip()] = chapter_id
                valid_chapters += 1
                if i < 5 or i % 100 == 0:  # è®°å½•å‰5ä¸ªå’Œæ¯100ä¸ªç« èŠ‚
                    self._write_debug_log(f"âœ… ç« èŠ‚{i+1}: ã€Œ{chapter_title.strip()}ã€-> ID: {chapter_id}")

        self._write_debug_log(f"ğŸ“Š ç« èŠ‚ç»Ÿè®¡: æœ‰æ•ˆç« èŠ‚ {valid_chapters} ä¸ªï¼Œç©ºæ ‡é¢˜ç« èŠ‚ {null_title_count} ä¸ª")
        
        if null_title_count > 0:
            self.log_callback(f"âš ï¸ å‘ç° {null_title_count} ä¸ªç©ºæ ‡é¢˜ç« èŠ‚ï¼Œè¿™äº›ç« èŠ‚å°†è¢«è·³è¿‡")
            self.log_callback(f"ğŸ’¡ å»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ï¼Œä¹Ÿå¯èƒ½æ˜¯ç½‘ç«™åçˆ¬è™«æœºåˆ¶")

        title = ele.xpath('//h1/text()')
        status = ele.xpath('//span[@class="info-label-yellow"]/text()')
        
        self._write_debug_log(f"ğŸ“– å°è¯´æ ‡é¢˜: {title[0] if title else 'æœªæ‰¾åˆ°'}")
        self._write_debug_log(f"ğŸ“Š å°è¯´çŠ¶æ€: {status[0] if status else 'æœªæ‰¾åˆ°'}")

        if not title or not status:
            self._write_debug_log("âŒ æ— æ³•è·å–å°è¯´åŸºæœ¬ä¿¡æ¯ï¼ˆæ ‡é¢˜æˆ–çŠ¶æ€ï¼‰")
            return 'err', {}, []

        return title[0], chapters, status

    def _download_chapter_content(self, chapter_id: int, test_mode: bool = False) -> str:
        """Download content with fallback and enhanced error handling"""
        headers = self.headers.copy()
        headers['cookie'] = self.cookie

        for attempt in range(3):
            try:
                self._write_debug_log(f"ğŸ“¡ å°è¯•æ–¹æ³•1: æ ‡å‡†API (ç« èŠ‚ID: {chapter_id}, å°è¯•: {attempt + 1}/3)")
                
                # Try primary method
                response = req.get(
                    f'https://fanqienovel.com/reader/{chapter_id}',
                    headers=headers,
                    timeout=10
                )
                response.raise_for_status()
                
                self._write_debug_log(f"ğŸ“¥ APIå“åº”çŠ¶æ€: {response.status_code}, å†…å®¹é•¿åº¦: {len(response.text)}")

                content = '\n'.join(
                    etree.HTML(response.text).xpath(
                        '//div[@class="muye-reader-content noselect"]//p/text()'
                    )
                )
                
                self._write_debug_log(f"ğŸ“ XPathæå–ç»“æœé•¿åº¦: {len(content)} å­—ç¬¦")

                if test_mode:
                    return content

                # æ£€æŸ¥å†…å®¹æ˜¯å¦æœ‰æ•ˆ
                if not content or len(content.strip()) < 10:
                    self._write_debug_log(f"âš ï¸ æ–¹æ³•1å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º: {repr(content[:100])}")
                    raise Exception(f"Content too short or empty (length: {len(content)})")

                try:
                    decoded = self._decode_content(content)
                    self._write_debug_log(f"âœ… å†…å®¹è§£ç æˆåŠŸï¼Œæœ€ç»ˆé•¿åº¦: {len(decoded)} å­—ç¬¦")
                    return decoded
                except Exception as decode_err:
                    self._write_debug_log(f"âš ï¸ è§£ç æ¨¡å¼0å¤±è´¥: {str(decode_err)}")
                    # Try alternative decoding mode
                    try:
                        decoded = self._decode_content(content, mode=1)
                        self._write_debug_log(f"âœ… è§£ç æ¨¡å¼1æˆåŠŸï¼Œæœ€ç»ˆé•¿åº¦: {len(decoded)} å­—ç¬¦")
                        return decoded
                    except Exception as decode_err2:
                        self._write_debug_log(f"âš ï¸ è§£ç æ¨¡å¼1å¤±è´¥: {str(decode_err2)}")
                        # Fallback HTML processing
                        self._write_debug_log(f"ğŸ”„ ä½¿ç”¨åå¤‡HTMLå¤„ç†")
                        content = content[6:]
                        tmp = 1
                        result = ''
                        for i in content:
                            if i == '<':
                                tmp += 1
                            elif i == '>':
                                tmp -= 1
                            elif tmp == 0:
                                result += i
                            elif tmp == 1 and i == 'p':
                                result = (result + '\n').replace('\n\n', '\n')
                        
                        if result and len(result.strip()) > 10:
                            self._write_debug_log(f"âœ… åå¤‡å¤„ç†æˆåŠŸï¼Œæœ€ç»ˆé•¿åº¦: {len(result)} å­—ç¬¦")
                            return result
                        else:
                            raise Exception(f"Fallback processing failed, result too short: {len(result)}")

            except Exception as e:
                self._write_debug_log(f"âŒ æ–¹æ³•1å¤±è´¥: {str(e)}")
                
                # Try alternative API endpoint
                try:
                    self._write_debug_log(f"ğŸ”„ å°è¯•æ–¹æ³•2: å¤‡ç”¨API (ç« èŠ‚ID: {chapter_id})")
                    
                    response = req.get(
                        f'https://fanqienovel.com/api/reader/full?itemId={chapter_id}',
                        headers=headers,
                        timeout=10
                    )
                    response.raise_for_status()
                    
                    self._write_debug_log(f"ğŸ“¥ å¤‡ç”¨APIå“åº”çŠ¶æ€: {response.status_code}")
                    
                    data = json.loads(response.text)
                    content = data['data']['chapterData']['content']
                    
                    self._write_debug_log(f"ğŸ“ å¤‡ç”¨APIå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")

                    if test_mode:
                        return content
                    
                    # æ£€æŸ¥å†…å®¹æ˜¯å¦æœ‰æ•ˆ
                    if not content or len(content.strip()) < 10:
                        self._write_debug_log(f"âš ï¸ æ–¹æ³•2å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º: {repr(content[:100])}")
                        raise Exception(f"Backup API content too short (length: {len(content)})")

                    decoded = self._decode_content(content)
                    self._write_debug_log(f"âœ… å¤‡ç”¨APIè§£ç æˆåŠŸï¼Œæœ€ç»ˆé•¿åº¦: {len(decoded)} å­—ç¬¦")
                    return decoded
                    
                except Exception as backup_err:
                    self._write_debug_log(f"âŒ æ–¹æ³•2ä¹Ÿå¤±è´¥: {str(backup_err)}")
                    
                    if attempt == 2:  # Last attempt
                        self._write_debug_log(f"ğŸ’¥ æ‰€æœ‰æ–¹æ³•å‡å¤±è´¥ï¼Œç« èŠ‚ID: {chapter_id}")
                        if test_mode:
                            return 'err'
                        raise Exception(f"All download methods failed. Primary: {str(e)}, Backup: {str(backup_err)}")
                    
                    self._write_debug_log(f"â³ ç­‰å¾…1ç§’åé‡è¯•...")
                    time.sleep(1)

    def _get_author_info(self, novel_id: int) -> Optional[str]:
        """Get author information from novel page"""
        url = f'https://fanqienovel.com/page/{novel_id}'
        try:
            response = req.get(url, headers=self.headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            script_tag = soup.find('script', type="application/ld+json")
            if script_tag:
                data = json.loads(script_tag.string)
                if 'author' in data:
                    return data['author'][0]['name']
        except Exception as e:
            self.log_callback(f"è·å–ä½œè€…ä¿¡æ¯å¤±è´¥: {str(e)}")
        return None

    def _get_cover_url(self, novel_id: int) -> Optional[str]:
        """Get cover image URL from novel page"""
        url = f'https://fanqienovel.com/page/{novel_id}'
        try:
            response = req.get(url, headers=self.headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            script_tag = soup.find('script', type="application/ld+json")
            if script_tag:
                data = json.loads(script_tag.string)
                if 'image' in data:
                    return data['image'][0]
        except Exception as e:
            self.log_callback(f"è·å–å°é¢å›¾ç‰‡å¤±è´¥: {str(e)}")
        return None

    def _add_cover_to_epub(self, book: epub.EpubBook, cover_url: str):
        """Add cover image to EPUB book"""
        try:
            response = req.get(cover_url)
            if response.status_code == 200:
                book.set_cover('cover.jpg', response.content)

                # Add cover page
                cover_content = f'''
                    <div style="text-align: center; padding: 0; margin: 0;">
                        <img src="cover.jpg" alt="Cover" style="max-width: 100%; height: auto;"/>
                    </div>
                '''
                cover_page = epub.EpubHtml(
                    title='Cover',
                    file_name='cover.xhtml',
                    content=cover_content,
                    media_type='image/jpeg'
                )
                book.add_item(cover_page)
                book.spine.insert(0, cover_page)
        except Exception as e:
            self.log_callback(f"æ·»åŠ å°é¢å¤±è´¥: {str(e)}")

    def _extract_chapter_number(self, title: str) -> int:
        """Extract chapter number from title for sorting"""
        # å°è¯•æå–ç« èŠ‚ç¼–å·çš„å¤šç§æ¨¡å¼
        patterns = [
            r'ç¬¬\s*(\d+)\s*ç« ',      # ç¬¬1ç« , ç¬¬ 1 ç« 
            r'ç¬¬\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡]+)\s*ç« ',  # ç¬¬ä¸€ç« , ç¬¬äºŒåç« 
            r'ç« èŠ‚?\s*(\d+)',        # ç« èŠ‚1, ç« 1  
            r'(\d+)\s*ç« ',           # 1ç« 
            r'Chapter\s*(\d+)',      # Chapter 1
            r'Ch\s*(\d+)',           # Ch 1
            r'^(\d+)',               # å¼€å¤´çš„æ•°å­—
        ]
        
        for pattern in patterns:
            match = re.search(pattern, title, re.IGNORECASE)
            if match:
                chapter_num_str = match.group(1)
                
                # å¤„ç†ä¸­æ–‡æ•°å­—
                if chapter_num_str in ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å']:
                    chinese_numbers = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 
                                     'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10}
                    return chinese_numbers.get(chapter_num_str, 0)
                
                # å¤„ç†é˜¿æ‹‰ä¼¯æ•°å­—
                try:
                    return int(chapter_num_str)
                except ValueError:
                    continue
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç« èŠ‚ç¼–å·ï¼Œè¿”å›0ï¼ˆå°†æ’åœ¨æœ€å‰é¢ï¼‰
        return 0

    def _get_failure_reason(self, exception: Exception) -> str:
        """æ ¹æ®å¼‚å¸¸ç±»å‹è¿”å›ç”¨æˆ·å‹å¥½çš„å¤±è´¥åŸå› """
        error_str = str(exception).lower()
        
        if "chapter download failed" in error_str:
            if "apiè¿”å›é”™è¯¯" in error_str:
                return "APIè¿”å›é”™è¯¯"
            elif "è¿”å›å†…å®¹ä¸ºnone" in error_str:
                return "å“åº”å†…å®¹ä¸ºç©º(None)"
            elif "è¿”å›å†…å®¹ä¸ºç©ºå­—ç¬¦ä¸²" in error_str:
                return "å“åº”å†…å®¹ä¸ºç©ºå­—ç¬¦ä¸²"
            else:
                return "å†…å®¹è·å–å¤±è´¥"
        elif "timeout" in error_str or "timed out" in error_str:
            return "ç½‘ç»œè¶…æ—¶"
        elif "connection" in error_str:
            return "ç½‘ç»œè¿æ¥é”™è¯¯"
        elif "404" in error_str:
            return "ç« èŠ‚ä¸å­˜åœ¨(404)"
        elif "403" in error_str:
            return "è®¿é—®è¢«æ‹’ç»(403)"
        elif "500" in error_str:
            return "æœåŠ¡å™¨é”™è¯¯(500)"
        elif "nonetype" in error_str and "pathlike" in error_str:
            return "æ–‡ä»¶è·¯å¾„é”™è¯¯(å˜é‡ä¸ºNone)"
        elif "decode" in error_str or "encoding" in error_str:
            return "å†…å®¹è§£ç é”™è¯¯"
        elif "json" in error_str:
            return "JSONè§£æé”™è¯¯"
        else:
            # ğŸš¨ ç”¨æˆ·è¦æ±‚ï¼šä¸è¦æˆªæ–­é”™è¯¯ä¿¡æ¯ï¼Œæ˜¾ç¤ºå®Œæ•´å†…å®¹
            return f"æœªçŸ¥é”™è¯¯: {str(exception)}"

    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize filename for different platforms with enhanced debugging"""
        self._write_debug_log(f"ğŸ”§ _sanitize_filenameè°ƒç”¨ - è¾“å…¥: {repr(filename)} (ç±»å‹: {type(filename).__name__})")
        
        # å¤„ç†Noneæˆ–ç©ºå€¼çš„æƒ…å†µ
        if filename is None:
            self._write_debug_log(f"âŒ _sanitize_filename: è¾“å…¥ä¸ºNone!")
            result = "ERROR_None_filename"
            self._write_debug_log(f"ğŸ”§ _sanitize_filenameè¿”å›: {repr(result)}")
            return result
        
        if not filename:
            self._write_debug_log(f"âŒ _sanitize_filename: è¾“å…¥ä¸ºç©ºå­—ç¬¦ä¸²!")
            result = "ERROR_Empty_filename"
            self._write_debug_log(f"ğŸ”§ _sanitize_filenameè¿”å›: {repr(result)}")
            return result
        
        # ç¡®ä¿è¾“å…¥æ˜¯å­—ç¬¦ä¸²ç±»å‹
        if not isinstance(filename, str):
            self._write_debug_log(f"âŒ _sanitize_filename: è¾“å…¥ä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹: {type(filename)}")
            filename_str = str(filename)
            self._write_debug_log(f"ğŸ”„ è½¬æ¢ä¸ºå­—ç¬¦ä¸²: {repr(filename_str)}")
            filename = filename_str
        
        original_filename = filename
        illegal_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*']
        illegal_chars_rep = ['ï¼œ', 'ï¼', 'ï¼š', 'ï¼‚', 'ï¼', 'ï¼¼', 'ï½œ', 'ï¼Ÿ', 'ï¼Š']
        
        for old, new in zip(illegal_chars, illegal_chars_rep):
            if old in filename:
                self._write_debug_log(f"ğŸ”„ æ›¿æ¢å­—ç¬¦: '{old}' -> '{new}'")
                filename = filename.replace(old, new)
        
        self._write_debug_log(f"ğŸ”§ _sanitize_filenameå®Œæˆ - åŸå§‹: {repr(original_filename)} -> ç»“æœ: {repr(filename)}")
        return filename

    def _parse_novel_id(self, novel_id: Union[str, int]) -> Optional[int]:
        """Parse novel ID from input (URL or ID)"""
        if isinstance(novel_id, str) and novel_id.startswith('http'):
            novel_id = novel_id.split('?')[0].split('/')[-1]
        try:
            return int(novel_id)
        except ValueError:
            self.log_callback(f'Invalid novel ID: {novel_id}')
            return None

    def get_downloaded_novels(self) -> List[Dict[str, str]]:
        """Get list of downloaded novels with their paths"""
        novels = []
        for filename in os.listdir(self.bookstore_dir):
            if filename.endswith('.json'):
                novel_name = filename[:-5]  # Remove .json extension
                json_path = os.path.join(self.bookstore_dir, filename)

                try:
                    with open(json_path, 'r', encoding='UTF-8') as f:
                        novel_data = json.load(f)
                        metadata = novel_data.get('_metadata', {})

                        novels.append({
                            'name': novel_name,
                            'novel_id': metadata.get('novel_id'),
                            'status': metadata.get('status'),
                            'last_updated': metadata.get('last_updated'),
                            'json_path': json_path,
                            'txt_path': os.path.join(self.config.save_path, f'{novel_name}.txt'),
                            'epub_path': os.path.join(self.config.save_path, f'{novel_name}.epub'),
                            'html_path': os.path.join(self.config.save_path, f'{novel_name}(html)'),
                            'latex_path': os.path.join(self.config.save_path, f'{novel_name}.tex')
                        })
                except Exception as e:
                    self.log_callback(f"Error reading novel data for {novel_name}: {str(e)}")
                    # Add novel with minimal info if metadata can't be read
                    novels.append({
                        'name': novel_name,
                        'novel_id': None,
                        'status': None,
                        'last_updated': None,
                        'json_path': json_path,
                        'txt_path': os.path.join(self.config.save_path, f'{novel_name}.txt'),
                        'epub_path': os.path.join(self.config.save_path, f'{novel_name}.epub'),
                        'html_path': os.path.join(self.config.save_path, f'{novel_name}(html)'),
                        'latex_path': os.path.join(self.config.save_path, f'{novel_name}.tex')
                    })
        return novels

    def backup_data(self, backup_dir: str):
        """Backup all data to specified directory"""
        os.makedirs(backup_dir, exist_ok=True)

        # Backup configuration
        if os.path.exists(self.config_path):
            shutil.copy2(self.config_path, os.path.join(backup_dir, 'config.json'))

        # Backup records
        if os.path.exists(self.record_path):
            shutil.copy2(self.record_path, os.path.join(backup_dir, 'record.json'))

        # Backup novels
        novels_backup_dir = os.path.join(backup_dir, 'novels')
        os.makedirs(novels_backup_dir, exist_ok=True)
        for novel in self.get_downloaded_novels():
            shutil.copy2(novel['json_path'], novels_backup_dir)

    def _decode_content(self, content: str, mode: int = 0) -> str:
        """Decode novel content using both charset modes"""
        result = ''
        for char in content:
            uni = ord(char)
            if self.CODE[mode][0] <= uni <= self.CODE[mode][1]:
                bias = uni - self.CODE[mode][0]
                if 0 <= bias < len(self.charset[mode]) and self.charset[mode][bias] != '?':
                    result += self.charset[mode][bias]
                else:
                    result += char
            else:
                result += char
        return result

    def _update_records(self, novel_id: int):
        """Update download records"""
        if os.path.exists(self.record_path):
            with open(self.record_path, 'r', encoding='UTF-8') as f:
                records = json.load(f)
        else:
            records = []

        if novel_id not in records:
            records.append(novel_id)
            with open(self.record_path, 'w', encoding='UTF-8') as f:
                json.dump(records, f)

    def _save_progress(self, title: str, content: str):
        """Save download progress"""
        self.zj[title] = content
        with open(self.book_json_path, 'w', encoding='UTF-8') as f:
            json.dump(self.zj, f, ensure_ascii=False)

    def _save_epub_from_content(self, safe_name: str, novel_content: dict, output_dir: str, novel_id: int) -> str:
        """åŸºäºå·²ä¸‹è½½å†…å®¹ç”ŸæˆEPUBæ–‡ä»¶ï¼Œä¿å­˜åˆ°æŒ‡å®šç›®å½•"""
        try:
            # è·å–å°è¯´ä¿¡æ¯
            book = epub.EpubBook()
            book.set_identifier(str(novel_id))
            book.set_title(safe_name)
            book.set_language('zh')
            
            # å°è¯•è·å–ä½œè€…ä¿¡æ¯
            try:
                author = self._get_author_info(novel_id)
                if author:
                    book.add_author(author)
                else:
                    book.add_author('æœªçŸ¥ä½œè€…')
            except:
                book.add_author('æœªçŸ¥ä½œè€…')
            
            # æ·»åŠ å°é¢ï¼ˆå¦‚æœå¯ä»¥è·å–ï¼‰
            try:
                cover_url = self._get_cover_url(novel_id)
                if cover_url:
                    self._add_cover_to_epub(book, cover_url)
            except:
                pass  # å°é¢è·å–å¤±è´¥ä¸å½±å“ä¸»è¦æµç¨‹
            
            # ä¸ºæ¯ä¸ªç« èŠ‚åˆ›å»ºEPUBç« èŠ‚
            for i, (title, content) in enumerate(novel_content.items()):
                if title.startswith('_'):  # è·³è¿‡å…ƒæ•°æ®
                    continue
                    
                chapter = epub.EpubHtml(
                    title=title,
                    file_name=f'chapter_{i+1}.xhtml',
                    lang='zh'
                )
                
                # æ ¼å¼åŒ–å†…å®¹
                formatted_content = ''.join(f'<p>{para.strip()}</p>' for para in content.split('\n') if para.strip())
                chapter.content = f'<h1>{title}</h1>{formatted_content}'
                
                book.add_item(chapter)
            
            # æ·»åŠ å¯¼èˆª
            chapters = [item for item in book.get_items() if isinstance(item, epub.EpubHtml)]
            book.toc = chapters
            book.spine = ['nav'] + chapters
            book.add_item(epub.EpubNcx())
            book.add_item(epub.EpubNav())
            
            # ä¿å­˜EPUBæ–‡ä»¶åˆ°æŒ‡å®šç›®å½•
            epub_path = os.path.join(output_dir, f'{safe_name}.epub')
            epub.write_epub(epub_path, book)
            
            return 's'
            
        except Exception as e:
            self.log_callback(f'EPUBç”Ÿæˆå¤±è´¥: {str(e)}')
            return 'err'
    
    def _save_html_from_content(self, safe_name: str, novel_content: dict, output_dir: str) -> str:
        """åŸºäºå·²ä¸‹è½½å†…å®¹ç”ŸæˆHTMLæ–‡ä»¶ï¼Œä¿å­˜åˆ°æŒ‡å®šç›®å½•"""
        try:
            html_dir = os.path.join(output_dir, f"{safe_name}(html)")
            os.makedirs(html_dir, exist_ok=True)
            
            # ç”Ÿæˆç« èŠ‚æ–‡ä»¶
            all_titles = []
            for i, (title, content) in enumerate(novel_content.items()):
                if title.startswith('_'):  # è·³è¿‡å…ƒæ•°æ®
                    continue
                    
                all_titles.append(title)
                filename = f"chapter_{i+1}.html"
                chapter_path = os.path.join(html_dir, filename)
                
                # åˆ›å»ºHTMLå†…å®¹
                html_content = f"""<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{ font-family: serif; line-height: 1.8; margin: 40px; background: #f9f9f9; }}
        .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        h1 {{ color: #333; border-bottom: 2px solid #eee; padding-bottom: 10px; }}
        p {{ text-indent: 2em; margin: 1em 0; }}
        .navigation {{ margin: 20px 0; text-align: center; }}
        .navigation a {{ margin: 0 10px; padding: 8px 16px; background: #007bff; color: white; text-decoration: none; border-radius: 4px; }}
        .navigation a:hover {{ background: #0056b3; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="navigation">
            <a href="index.html">ç›®å½•</a>
        </div>
        <h1>{title}</h1>
"""
                
                # æ·»åŠ ç« èŠ‚å†…å®¹
                for paragraph in content.split('\n'):
                    if paragraph.strip():
                        html_content += f"        <p>{paragraph.strip()}</p>\n"
                
                html_content += """    </div>
</body>
</html>"""
                
                with open(chapter_path, 'w', encoding='UTF-8') as f:
                    f.write(html_content)
            
            # ç”Ÿæˆç›®å½•æ–‡ä»¶
            index_content = self._create_html_index(safe_name, novel_content)
            index_path = os.path.join(html_dir, 'index.html')
            with open(index_path, 'w', encoding='UTF-8') as f:
                f.write(index_content)
            
            return 's'
            
        except Exception as e:
            self.log_callback(f'HTMLç”Ÿæˆå¤±è´¥: {str(e)}')
            return 'err'
    
    def _save_latex_from_content(self, safe_name: str, novel_content: dict, output_dir: str) -> str:
        """åŸºäºå·²ä¸‹è½½å†…å®¹ç”ŸæˆLaTeXæ–‡ä»¶ï¼Œä¿å­˜åˆ°æŒ‡å®šç›®å½•"""
        try:
            latex_path = os.path.join(output_dir, f'{safe_name}.tex')
            
            with open(latex_path, 'w', encoding='UTF-8') as f:
                # LaTeXæ–‡æ¡£å¤´éƒ¨
                f.write(self._create_latex_header(safe_name))
                
                # æ·»åŠ ç« èŠ‚å†…å®¹
                for title, content in novel_content.items():
                    if title.startswith('_'):  # è·³è¿‡å…ƒæ•°æ®
                        continue
                        
                    formatted_chapter = self._format_latex_chapter(title, content)
                    f.write(formatted_chapter)
                
                # LaTeXæ–‡æ¡£å°¾éƒ¨
                f.write('\n\\end{document}\n')
            
            return 's'
            
        except Exception as e:
            self.log_callback(f'LaTeXç”Ÿæˆå¤±è´¥: {str(e)}')
            return 'err'
    
    def _generate_pdf_from_latex(self, safe_name: str, output_dir: str) -> str:
        """ä½¿ç”¨xelatexå°†LaTeXæ–‡ä»¶ç¼–è¯‘ä¸ºPDF"""
        try:
            import subprocess
            
            latex_file = f'{safe_name}.tex'
            latex_path = os.path.join(output_dir, latex_file)
            
            # æ£€æŸ¥LaTeXæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(latex_path):
                raise Exception(f'LaTeXæ–‡ä»¶ä¸å­˜åœ¨: {latex_path}')
            
            # æ£€æŸ¥xelatexæ˜¯å¦å¯ç”¨
            try:
                subprocess.run(['xelatex', '--version'], capture_output=True, check=True)
            except (subprocess.CalledProcessError, FileNotFoundError):
                raise Exception('xelatexæœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­ã€‚è¯·å®‰è£…LaTeXå‘è¡Œç‰ˆï¼ˆå¦‚TeX Liveæˆ–MiKTeXï¼‰')
            
            # ç¼–è¯‘LaTeXä¸ºPDF
            self.log_callback('æ­£åœ¨ä½¿ç”¨xelatexç¼–è¯‘PDF...')
            
            # åˆ‡æ¢åˆ°è¾“å‡ºç›®å½•æ‰§è¡Œxelatexï¼Œç¡®ä¿å·¥ä½œç›®å½•å°±æ˜¯latexæ–‡ä»¶çš„ç›®å½•
            original_cwd = os.getcwd()
            try:
                os.chdir(output_dir)
                
                # è¿è¡Œxelatexï¼Œå¿…é¡»è¿è¡Œä¸¤æ¬¡ä»¥æ­£ç¡®ç”Ÿæˆç›®å½•å’Œå¼•ç”¨
                for i in range(2):
                    self.log_callback(f'æ‰§è¡Œç¬¬{i+1}æ¬¡xelatexç¼–è¯‘...')
                    # ä¿®å¤ç¼–ç é—®é¢˜ï¼šä½¿ç”¨bytesæ¨¡å¼è€Œä¸æ˜¯textæ¨¡å¼
                    result = subprocess.run(
                        ['xelatex', '-interaction=nonstopmode', latex_file],
                        capture_output=True,
                        text=False,  # ä½¿ç”¨bytesæ¨¡å¼é¿å…ç¼–ç é—®é¢˜
                        timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
                    )
                    
                    if result.returncode != 0:
                        # å¦‚æœå¤±è´¥ï¼Œå°è¯•æŸ¥çœ‹æ—¥å¿—
                        log_file = f'{safe_name}.log'
                        error_info = f'xelatexç¼–è¯‘å¤±è´¥ (è¿”å›ç : {result.returncode})'
                        
                        # è·å–stderrè¾“å‡ºï¼ˆå¦‚æœæœ‰ï¼‰
                        if result.stderr:
                            try:
                                # å°è¯•å¤šç§ç¼–ç è§£ç stderr
                                stderr_text = None
                                for encoding in ['utf-8', 'gbk', 'latin1']:
                                    try:
                                        stderr_text = result.stderr.decode(encoding)
                                        break
                                    except UnicodeDecodeError:
                                        continue
                                
                                if stderr_text:
                                    error_info += f'\nç¼–è¯‘è¾“å‡º: {stderr_text[:500]}...'  # é™åˆ¶é•¿åº¦
                            except:
                                error_info += '\nç¼–è¯‘è¾“å‡º: <æ— æ³•è§£ç çš„è¾“å‡º>'
                        
                        # å°è¯•è¯»å–æ—¥å¿—æ–‡ä»¶
                        if os.path.exists(log_file):
                            try:
                                # å°è¯•å¤šç§ç¼–ç è¯»å–æ—¥å¿—æ–‡ä»¶
                                log_content = None
                                for encoding in ['utf-8', 'gbk', 'latin1']:
                                    try:
                                        with open(log_file, 'r', encoding=encoding) as log_f:
                                            lines = log_f.readlines()
                                            # å–æœ€å20è¡Œ
                                            error_lines = lines[-20:] if len(lines) > 20 else lines
                                            log_content = ''.join(error_lines)
                                            break
                                    except UnicodeDecodeError:
                                        continue
                                
                                if log_content:
                                    error_info += f'\næœ€åå‡ è¡Œæ—¥å¿—:\n{log_content}'
                                else:
                                    error_info += '\næ—¥å¿—æ–‡ä»¶: <æ— æ³•è§£ç >'
                            except Exception as e:
                                error_info += f'\nè¯»å–æ—¥å¿—å¤±è´¥: {str(e)}'
                        
                        raise Exception(error_info)
                
                # æ£€æŸ¥PDFæ˜¯å¦ç”ŸæˆæˆåŠŸ
                pdf_file = f'{safe_name}.pdf'
                if not os.path.exists(pdf_file):
                    raise Exception('PDFæ–‡ä»¶æœªç”Ÿæˆ')
                
                # æ¸…ç†è¾…åŠ©æ–‡ä»¶
                aux_extensions = ['.aux', '.log', '.out', '.toc', '.fls', '.fdb_latexmk']
                for ext in aux_extensions:
                    aux_file = f'{safe_name}{ext}'
                    if os.path.exists(aux_file):
                        try:
                            os.remove(aux_file)
                        except:
                            pass  # æ¸…ç†å¤±è´¥ä¸å½±å“ä¸»è¦æµç¨‹
                
                return 's'
                
            finally:
                os.chdir(original_cwd)
            
        except Exception as e:
            self.log_callback(f'PDFç”Ÿæˆå¤±è´¥: {str(e)}')
            return 'err'


def create_cli():
    """Create CLI interface using the NovelDownloader class"""
    print('æœ¬ç¨‹åºå®Œå…¨å…è´¹(æ­¤ç‰ˆæœ¬ä¸ºWEBç‰ˆï¼Œç›®å‰å¤„äºæµ‹è¯•é˜¶æ®µ)\nGithub: https://github.com/ying-ck/fanqienovel-downloader\nä½œè€…ï¼šYck & qxqycb & lingo34')
    print('ä¼˜åŒ–å¢å¼ºç‰ˆ - æ”¯æŒYAMLé…ç½®æ–‡ä»¶')

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ç•ªèŒ„å°è¯´ä¸‹è½½å™¨', add_help=False)
    parser.add_argument('--id', type=str, help='ç›´æ¥ä¸‹è½½æŒ‡å®šIDçš„å°è¯´')
    parser.add_argument('--config', type=str, default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-h', '--help', action='store_true', help='æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯')
    parser.add_argument('config_file', nargs='?', help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰')
    
    args = parser.parse_args()
    
    if args.help:
        print('\nä½¿ç”¨æ–¹æ³•:')
        print('  python src/main.py                    # ä½¿ç”¨é»˜è®¤é…ç½®æ–‡ä»¶å¹¶è¿›å…¥äº¤äº’æ¨¡å¼')
        print('  python src/main.py --config [é…ç½®æ–‡ä»¶] # ä½¿ç”¨æŒ‡å®šé…ç½®æ–‡ä»¶')
        print('  python src/main.py --id [å°è¯´ID]      # ç›´æ¥ä¸‹è½½æŒ‡å®šIDçš„å°è¯´')
        print('  python src/main.py --help            # æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯')
        print('\nç¤ºä¾‹:')
        print('  python src/main.py --id 7520128677003136024')
        print('  python src/main.py --config my_config.yaml --id 7520128677003136024')
        print('\né…ç½®æ–‡ä»¶ç¤ºä¾‹è¯·å‚è€ƒ config.yaml')
        return
    
    # ç¡®å®šé…ç½®æ–‡ä»¶è·¯å¾„ (å…¼å®¹æ—§æ ¼å¼)
    config_path = args.config
    if args.config_file:
        config_path = args.config_file
    
    # åŠ è½½é…ç½®
    if os.path.exists(config_path):
        print(f'ğŸ“„ åŠ è½½é…ç½®æ–‡ä»¶: {config_path}')
        config = Config.from_yaml(config_path)
    else:
        if config_path != 'config.yaml':
            print(f'âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}')
        print('ğŸ“„ ä½¿ç”¨é»˜è®¤é…ç½®')
        config = Config()
    
    # æ˜¾ç¤ºå½“å‰é…ç½®æ‘˜è¦
    print(f'\nğŸ“‹ å½“å‰é…ç½®æ‘˜è¦:')
    print(f'  ğŸ—‚ï¸  è¾“å‡ºæ ¼å¼: TXT({config.enable_txt}) JSON(å¿…é¡») EPUB({config.enable_epub}) HTML({config.enable_html}) LaTeX({config.enable_latex}) PDF({config.enable_pdf})')
    print(f'  âš¡ çº¿ç¨‹æ•°: {config.thread_count}')
    print(f'  â±ï¸  å»¶æ—¶æ¨¡å¼: {config.delay_mode} ({config.delay[0]}-{config.delay[1]}ms)')
    print(f'  ğŸ“ JSONç›®å½•: {config.bookstore_dir}')
    print(f'  ğŸ“ ä¸‹è½½ç›®å½•: {config.download_dir}')
    
    downloader = NovelDownloader(config)

    # Check for backup
    backup_folder_path = 'C:\\Users\\Administrator\\fanqie_down_backup'
    if os.path.exists(backup_folder_path):
        choice = input("æ£€æµ‹åˆ°å¤‡ä»½æ–‡ä»¶å¤¹ï¼Œå¦ä½¿ç”¨å¤‡ä»½æ®ï¼Ÿ1.ä½¿ç”¨å¤‡ä»½  2.è·³è¿‡ï¼š")
        if choice == '1':
            if os.path.isdir(backup_folder_path):
                source_folder_path = os.path.dirname(os.path.abspath(__file__))
                for item in os.listdir(backup_folder_path):
                    source_item_path = os.path.join(backup_folder_path, item)
                    target_item_path = os.path.join(source_folder_path, item)
                    if os.path.isfile(source_item_path):
                        if os.path.exists(target_item_path):
                            os.remove(target_item_path)
                        shutil.copy2(source_item_path, target_item_path)
                    elif os.path.isdir(source_item_path):
                        if os.path.exists(target_item_path):
                            shutil.rmtree(target_item_path)
                        shutil.copytree(source_item_path, target_item_path)
            else:
                print("å¤‡ä»½æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œæ— æ³•ä½¿ç”¨å¤‡ä»½æ•°æ®ã€‚")
        elif choice != '2':
            print("å…¥æ— æ•ˆï¼Œè¯·é‡æ–°è¿è¡Œç¨‹åºå¹¶æ­£ç¡®è¾“å…¥ã€‚")
    else:
        print("ç¨‹åºè¿˜æœªå¤‡ä»½")
    
    # å¦‚æœæä¾›äº†--idå‚æ•°ï¼Œç›´æ¥ä¸‹è½½å¹¶é€€å‡º
    if args.id:
        print(f'\nğŸš€ å¼€å§‹ç›´æ¥ä¸‹è½½å°è¯´ID: {args.id}')
        result = downloader.download_novel(args.id)
        if result:
            print('âœ… ä¸‹è½½å®Œæˆ')
        else:
            print('âŒ ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥å°è¯´IDæ˜¯å¦æ­£ç¡®')
        return

    while True:
        print('\nè¾“å…¥ä¹¦çš„idç›´æ¥ä¸‹è½½\nè¾“å…¥ä¸‹é¢çš„æ•°å­—è¿›å…¥å…¶ä»–åŠŸèƒ½:')
        print('''
1. æ›´æ–°å°è¯´
2. æœç´¢
3. æ‰¹é‡ä¸‹è½½
4. è®¾ç½®
5. å¤‡ä»½
6. é€€å‡º
        ''')

        inp = input()

        if inp == '1':
            downloader.update_all_novels()

        elif inp == '2':
            while True:
                key = input("è¯·è¾“å…¥æœç´¢å…³é”®è¯ï¼ˆç›´æ¥Enterè¿”å›ï¼‰ï¼š")
                if key == '':
                    break
                results = downloader.search_novel(key)
                if not results:
                    print("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¹¦ç±ã€‚")
                    continue

                for i, book in enumerate(results):
                    print(f"{i + 1}. åç§°ï¼š{book['book_data'][0]['book_name']} "
                          f"ä½œè€…ï¼š{book['book_data'][0]['author']} "
                          f"IDï¼š{book['book_data'][0]['book_id']} "
                          f"å­—æ•°ï¼š{book['book_data'][0]['word_number']}")

                while True:
                    choice = input("è¯·é€‰æ‹©ä¸€ä¸ªç»“æœ, è¾“å…¥ r ä»¥é‡æ–°æœç´¢ï¼š")
                    if choice == "r":
                        break
                    elif choice.isdigit() and 1 <= int(choice) <= len(results):
                        chosen_book = results[int(choice) - 1]
                        downloader.download_novel(chosen_book['book_data'][0]['book_id'])
                        break
                    else:
                        print("è¾“å…¥æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

        elif inp == '3':
            urls_path = 'urls.txt'
            if not os.path.exists(urls_path):
                print(f"æœªæ‰¾åˆ°'{urls_path}'ï¼Œå°†ä¸ºæ‚¨åˆ›å»ºä¸€ä¸ªæ–°çš„æ–‡ä»¶ã€‚")
                with open(urls_path, 'w', encoding='UTF-8') as file:
                    file.write("# è¾“å…¥å°è¯´é“¾æ¥ï¼Œä¸€è¡Œä¸€ä¸ª\n")

            print(f"\nè¯·åœ¨æ–‡æœ¬ç¼–è¾‘å™¨ä¸­æ‰“å¼€å¹¶ç¼–è¾‘ '{urls_path}'")
            print("åœ¨æ–‡ä»¶ä¸­è¾“å…¥å°è¯´é“¾æ¥ï¼Œä¸€è¡Œä¸€ä¸ª")

            if platform.system() == "Windows":
                os.system(f'notepad "{urls_path}"')
            elif platform.system() == "Darwin":
                os.system(f'open -e "{urls_path}"')
            else:
                if os.system('which nano > /dev/null') == 0:
                    os.system(f'nano "{urls_path}"')
                elif os.system('which vim > /dev/null') == 0:
                    os.system(f'vim "{urls_path}"')
                else:
                    print(f"è¯·ä½¿ç”¨ä»»æ„æ–‡æœ¬ç¼–è¾‘å™¨æ‰‹åŠ¨ç¼–è¾‘ {urls_path} æ–‡ä»¶")

            print("\nç¼–è¾‘å®ŒæˆåæŒ‰Enteré”®ç»§ç»­...")
            input()

            with open(urls_path, 'r', encoding='UTF-8') as file:
                content = file.read()
                urls = content.replace(' ', '').split('\n')

            for url in urls:
                if url and url[0] != '#':
                    print(f'å¼€å§‹ä¸‹è½½é“¾æ¥: {url}')
                    status = downloader.download_novel(url)
                    if not status:
                        print(f'é“¾æ¥: {url} ä¸‹è½½å¤±è´¥ã€‚')
                    else:
                        print(f'é“¾æ¥: {url} ä¸‹è½½å®Œæˆã€‚')

        elif inp == '4':
            print('è¯·é€‰æ‹©é¡¹ç›®ï¼š1.æ­£æ–‡æ®µé¦–å ä½ç¬¦ 2.ç« èŠ‚ä¸‹è½½é—´éš”å»¶è¿Ÿ 3.å°è¯´ä¿å­˜è·¯å¾„ 4.å°è¯´ä¿å­˜æ–¹å¼ 5.è®¾ç½®ä¸‹è½½çº¿ç¨‹æ•°')
            inp2 = input()
            if inp2 == '1':
                tmp = input('è¯·è¾“å…¥æ­£æ–‡æ®µé¦–å ä½ç¬¦(å½“å‰ä¸º"%s")(ç›´æ¥Enterä¸æ›´æ”¹)ï¼š' % config.kgf)
                if tmp != '':
                    config.kgf = tmp
                config.kg = int(input('è¯·è¾“å…¥æ­£æ–‡æ®µé¦–å ä½ç¬¦æ•°ï¼ˆå½“å‰ä¸º%dï¼‰ï¼š' % config.kg))
            elif inp2 == '2':
                print('ç”±äºè¿Ÿè¿‡å°é€ æˆçš„åæœè¯·è‡ªè¡Œè´Ÿè´£ã€‚\nè¯·è¾“å…¥ä¸‹è½½é—´éš”éšæœºå»¶è¿Ÿ')
                config.delay[0] = int(input('ä¸‹é™ï¼ˆå½“å‰ä¸º%dï¼‰æ¯«ç§’ï¼‰ï¼š' % config.delay[0]))
                config.delay[1] = int(input('ä¸Šé™ï¼ˆå½“å‰ä¸º%dï¼‰ï¼ˆæ¯«ç§’ï¼‰ï¼š' % config.delay[1]))
            elif inp2 == '3':
                print('tip:è®¾ç½®ä¸ºå½“å‰ç›®å½•ç‚¹å–æ¶ˆ')
                time.sleep(1)
                path = input("\nè¯·è¾“å…¥ä¿å­˜ç›®å½•çš„å®Œæ•´è·¯å¾„:\n(ç›´æ¥æŒ‰Enterç”¨å½“å‰ç›®å½•)\n").strip()
                if path == "":
                    config.save_path = os.getcwd()
                else:
                    if not os.path.exists(path):
                        try:
                            os.makedirs(path)
                            config.save_path = path
                        except:
                            print("æ— æ³•åˆ›å»ºç›®å½•ï¼Œå°†ä½¿ç”¨å½“å‰ç›®å½•")
                            config.save_path = os.getcwd()
                    else:
                        config.save_path = path
            elif inp2 == '4':
                print('è¯·é€‰æ‹©ï¼š1.ä¿å­˜ä¸ºå•ä¸ª txt 2.åˆ†ç« ä¿å­˜ 3.ä¿å­˜ä¸º epub 4.ä¿å­˜ä¸º HTML ç½‘é¡µæ ¼å¼ 5.ä¿å­˜ä¸º LaTeX')
                inp3 = input()
                try:
                    config.save_mode = SaveMode(int(inp3))
                except ValueError:
                    print('è¯·æ­£ç¡®è¾“å…¥!')
                    continue
            elif inp2 == '5':
                config.xc = int(input('è¯·è¾“å…¥ä¸‹è½½çº¿ç¨‹æ•°ï¼š'))
            else:
                print('è¯·æ­£ç¡®è¾“å…¥!')
                continue

            # Save config
            with open(downloader.config_path, 'w', encoding='UTF-8') as f:
                json.dump({
                    'kg': config.kg,
                    'kgf': config.kgf,
                    'delay': config.delay,
                    'save_path': config.save_path,
                    'save_mode': config.save_mode.value,
                    'space_mode': config.space_mode,
                    'xc': config.xc
                }, f)
            print('è®¾ç½®å®Œæˆ')

        elif inp == '5':
            downloader.backup_data('C:\\Users\\Administrator\\fanqie_down_backup')
            print('å¤‡ä»½å®Œæˆ')

        elif inp == '6':
            break

        else:
            # Try to download novel directly
            if downloader.download_novel(inp):
                print('ä¸‹è½½å®Œæˆ')
            else:
                print('è¯·è¾“å…¥æœ‰æ•ˆçš„é€‰é¡¹æˆ–ä¹¦ç±IDã€‚')


if __name__ == "__main__":
    create_cli()