# -*- coding: utf-8 -*-
"""
‰øÆÂ§çÁâàmain.py - Ëß£ÂÜ≥cookieÁîüÊàêÊó∂ÁöÑÂ∑®Â§ßÂæ™ÁéØÂç°Ê≠ªÈóÆÈ¢ò
ÂéüÁâàÊú¨Âú®_get_new_cookieÂáΩÊï∞‰∏≠‰ΩøÁî®6√ó10^18Âà∞9√ó10^18ÁöÑÂ∑®Â§ßÂæ™ÁéØËåÉÂõ¥ÔºåÂØºËá¥Á®ãÂ∫èÂç°‰Ωè
‰øÆÂ§çÁâàÊú¨‰ΩøÁî®Âü∫‰∫éÊó∂Èó¥Êà≥ÁöÑÂêàÁêÜËåÉÂõ¥ÔºåÈÅøÂÖçÈïøÊó∂Èó¥Á≠âÂæÖ
"""
import requests as req
from lxml import etree
from ebooklib import epub
from tqdm import tqdm
from bs4 import BeautifulSoup
import json
import yaml  # Ê∑ªÂä†YAMLÊîØÊåÅ
import time
import random
import re  # Ê∑ªÂä†Ê≠£ÂàôË°®ËææÂºèÊ®°Âùó
import os
import platform
import shutil
import concurrent.futures
from typing import Callable, Optional, Dict, List, Union
from dataclasses import dataclass, field
from enum import Enum


class SaveMode(Enum):
    SINGLE_TXT = 1
    SPLIT_TXT = 2
    EPUB = 3
    HTML = 4
    LATEX = 5


@dataclass
class Config:
    # Êñá‰ª∂Ê†ºÂºèÊéßÂà∂
    enable_txt: bool = True
    enable_epub: bool = False
    enable_html: bool = False
    enable_latex: bool = False
    enable_pdf: bool = False
    
    # ÁõÆÂΩïÈÖçÁΩÆ (ÁÆÄÂåñÁâà)
    bookstore_dir: str = "bookstore"    # JSONÊñá‰ª∂Â≠òÊîæÁõÆÂΩï
    download_dir: str = "downloads"     # ÂÖ∂‰ªñÊ†ºÂºèÊñá‰ª∂Â≠òÊîæÁõÆÂΩï
    
    # ÊÄßËÉΩÈÖçÁΩÆ
    thread_count: int = 8
    delay_mode: str = "normal"
    custom_delay: List[int] = field(default_factory=lambda: [150, 300])
    
    # Êñá‰ª∂ÁÆ°ÁêÜ
    delete_chapters_after_merge: bool = False
    conflict_resolution: str = "rename"
    encoding: str = "UTF-8"
    preserve_original_order: bool = False
    
    # CookieÈÖçÁΩÆ
    cookie_mode: str = "auto"
    manual_cookie: str = ""
    cookie_file: str = "data/cookie.json"
    validate_cookie: bool = False
    
    # ÂÜÖÂÆπÂ§ÑÁêÜ
    paragraph_spacing: int = 0
    indent_character: str = "„ÄÄ"
    decode_mode: str = "auto"
    filter_special_chars: bool = False
    
    # ÁΩëÁªúÈÖçÁΩÆ
    timeout: int = 30
    retry_count: int = 3
    rotate_user_agent: bool = True
    
    # Êó•ÂøóÈÖçÁΩÆ
    log_level: str = "normal"
    save_log_to_file: bool = False
    log_file: str = "logs/download.log"
    
    # È´òÁ∫ßÈÄâÈ°π
    enable_experimental: bool = False
    memory_mode: str = "normal"
    show_progress_bar: bool = True
    
    # ÂÖºÂÆπÊÄßÂ≠óÊÆµÔºà‰øùÊåÅÂêëÂêéÂÖºÂÆπÔºâ
    kg: int = 0
    kgf: str = '„ÄÄ'
    delay: List[int] = field(default_factory=lambda: [100, 200])
    save_path: str = ''
    save_mode: SaveMode = SaveMode.SINGLE_TXT
    space_mode: str = 'halfwidth'
    xc: int = 8
    
    def __post_init__(self):
        # Â§ÑÁêÜÂª∂Êó∂ÈÖçÁΩÆ
        if self.delay_mode == "fast":
            self.delay = [50, 100]
        elif self.delay_mode == "normal":
            self.delay = [100, 200]
        elif self.delay_mode == "safe":
            self.delay = [200, 500]
        elif self.delay_mode == "custom":
            self.delay = self.custom_delay.copy()
        
        # ÂêåÊ≠•Á∫øÁ®ãÊï∞ÈÖçÁΩÆ
        self.xc = self.thread_count
        
        # ÂêåÊ≠•ÊÆµËêΩÈÖçÁΩÆ
        self.kg = self.paragraph_spacing
        self.kgf = self.indent_character
    
    @classmethod
    def from_yaml(cls, yaml_path: str) -> 'Config':
        """‰ªéYAMLÊñá‰ª∂Âä†ËΩΩÈÖçÁΩÆ"""
        try:
            with open(yaml_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
            
            config = cls()
            
            # Êñá‰ª∂Ê†ºÂºèÈÖçÁΩÆ
            if 'formats' in data:
                formats = data['formats']
                config.enable_txt = formats.get('enable_txt', True)
                config.enable_epub = formats.get('enable_epub', False)
                config.enable_html = formats.get('enable_html', False)
                config.enable_latex = formats.get('enable_latex', False)
                config.enable_pdf = formats.get('enable_pdf', False)
            
            # ÁõÆÂΩïÈÖçÁΩÆ (ÁÆÄÂåñÁâà)
            if 'directories' in data:
                dirs = data['directories']
                config.bookstore_dir = dirs.get('bookstore_dir', "bookstore")
                config.download_dir = dirs.get('download_dir', "downloads")
            
            # ÊÄßËÉΩÈÖçÁΩÆ
            if 'performance' in data:
                perf = data['performance']
                config.thread_count = perf.get('thread_count', 8)
                config.delay_mode = perf.get('delay_mode', "normal")
                config.custom_delay = perf.get('custom_delay', [150, 300])
            
            # Êñá‰ª∂ÁÆ°ÁêÜÈÖçÁΩÆ
            if 'file_management' in data:
                fm = data['file_management']
                config.delete_chapters_after_merge = fm.get('delete_chapters_after_merge', False)
                config.conflict_resolution = fm.get('conflict_resolution', "rename")
                config.encoding = fm.get('encoding', "UTF-8")
                config.preserve_original_order = fm.get('preserve_original_order', False)
            
            # CookieÈÖçÁΩÆ
            if 'authentication' in data:
                auth = data['authentication']
                config.cookie_mode = auth.get('cookie_mode', "auto")
                config.manual_cookie = auth.get('manual_cookie', "")
                config.cookie_file = auth.get('cookie_file', "data/cookie.json")
                config.validate_cookie = auth.get('validate_cookie', False)
            
            # ÂÜÖÂÆπÂ§ÑÁêÜÈÖçÁΩÆ
            if 'content' in data:
                content = data['content']
                config.paragraph_spacing = content.get('paragraph_spacing', 0)
                config.indent_character = content.get('indent_character', "„ÄÄ")
                config.decode_mode = content.get('decode_mode', "auto")
                config.filter_special_chars = content.get('filter_special_chars', False)
            
            # ÁΩëÁªúÈÖçÁΩÆ
            if 'network' in data:
                net = data['network']
                config.timeout = net.get('timeout', 30)
                config.retry_count = net.get('retry_count', 3)
                config.rotate_user_agent = net.get('rotate_user_agent', True)
            
            # Êó•ÂøóÈÖçÁΩÆ
            if 'logging' in data:
                log = data['logging']
                config.log_level = log.get('level', "normal")
                config.save_log_to_file = log.get('save_to_file', False)
                config.log_file = log.get('log_file', "logs/download.log")
            
            # È´òÁ∫ßÈÖçÁΩÆ
            if 'advanced' in data:
                adv = data['advanced']
                config.enable_experimental = adv.get('enable_experimental', False)
                config.memory_mode = adv.get('memory_mode', "normal")
                config.show_progress_bar = adv.get('show_progress_bar', True)
            
            return config
            
        except Exception as e:
            print(f"‚ö†Ô∏è ÈÖçÁΩÆÊñá‰ª∂ËØªÂèñÂ§±Ë¥•: {e}")
            print("‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ")
            return cls()
    
    def get_delay_range(self) -> List[int]:
        """Ëé∑ÂèñÂΩìÂâçÁöÑÂª∂Êó∂ËåÉÂõ¥"""
        return self.delay


class NovelDownloader:
    def __init__(self,
                 config: Config,
                 progress_callback: Optional[Callable] = None,
                 log_callback: Optional[Callable] = None):
        self.config = config
        self.progress_callback = progress_callback or self._default_progress
        self.log_callback = log_callback or print

        # Initialize headers first
        self.headers_lib = [
            {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36'},
            {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0'},
            {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36 Edg/93.0.961.47'}
        ]
        self.headers = random.choice(self.headers_lib)

        # Use absolute paths based on script location
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        self.data_dir = os.path.join(self.script_dir, 'data')
        
        # ‰ΩøÁî®ÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑÁõÆÂΩïËÆæÁΩÆ (ÁÆÄÂåñÁâà)
        self.bookstore_dir = os.path.join(self.script_dir, self.config.bookstore_dir)  # JSONÊñá‰ª∂ÁõÆÂΩï
        self.download_dir = os.path.join(self.script_dir, self.config.download_dir)    # ÂÖ∂‰ªñÊ†ºÂºèÊñá‰ª∂ÁõÆÂΩï
        
        self.record_path = os.path.join(self.data_dir, 'record.json')
        self.config_path = os.path.join(self.data_dir, 'config.json')
        
        # CookieË∑ØÂæÑÊ†πÊçÆÈÖçÁΩÆÂÜ≥ÂÆö
        if self.config.cookie_mode == "file":
            self.cookie_path = os.path.join(self.script_dir, self.config.cookie_file)
        else:
            self.cookie_path = os.path.join(self.data_dir, 'cookie.json')

        self.CODE = [[58344, 58715], [58345, 58716]]

        # Load charset for text decoding
        charset_path = os.path.join(self.script_dir, 'charset.json')
        with open(charset_path, 'r', encoding='UTF-8') as f:
            self.charset = json.load(f)

        self._setup_directories()
        self._init_cookie()

        # Add these variables
        self.zj = {}  # For storing chapter data
        self.cs = 0  # Chapter counter
        self.tcs = 0  # Test counter
        self.tzj = None  # Test chapter ID
        self.book_json_path = None  # Current book's JSON path

    def _setup_directories(self):
        """Create necessary directories if they don't exist"""
        os.makedirs(self.data_dir, exist_ok=True)
        
        # ÂàõÂª∫Âü∫Á°ÄÁõÆÂΩï
        os.makedirs(self.bookstore_dir, exist_ok=True)  # JSONÊñá‰ª∂ÁõÆÂΩïÔºàÊÄªÊòØÈúÄË¶ÅÔºâ
        os.makedirs(self.download_dir, exist_ok=True)   # ÂÖ∂‰ªñÊ†ºÂºèÊñá‰ª∂ÁõÆÂΩï
            
        # Â¶ÇÊûúÈúÄË¶Å‰øùÂ≠òÊó•ÂøóÔºåÂàõÂª∫Êó•ÂøóÁõÆÂΩï
        if self.config.save_log_to_file:
            log_dir = os.path.dirname(os.path.join(self.script_dir, self.config.log_file))
            if log_dir:
                os.makedirs(log_dir, exist_ok=True)

    def _init_cookie(self):
        """Initialize cookie for downloads - ÁÆÄÂåñÁâàÊú¨ÔºåÁõ¥Êé•‰ΩøÁî®ÈªòËÆ§cookie"""
        self.log_callback('Ê≠£Âú®ÂàùÂßãÂåñcookie')
        
        # Áõ¥Êé•‰ΩøÁî®Êó∂Èó¥Êà≥ÁîüÊàêÈªòËÆ§cookieÔºåÊó†ÈúÄÈ™åËØÅ
        base_timestamp = int(time.time() * 1000)
        self.cookie = f'novel_web_id={base_timestamp}'
        
        # ‰øùÂ≠òcookieÂà∞Êñá‰ª∂
        try:
            with open(self.cookie_path, 'w', encoding='UTF-8') as f:
                json.dump(self.cookie, f)
        except Exception:
            pass  # ÂøΩÁï•‰øùÂ≠òÂ§±Ë¥•ÔºåÁªßÁª≠‰ΩøÁî®ÂÜÖÂ≠ò‰∏≠ÁöÑcookie
            
        self.log_callback('CookieÂàùÂßãÂåñÂÆåÊàê')

    def _default_progress(self, current: int, total: int, desc: str = '',
                          chapter_title: str = None):
        """Progress tracking for both CLI and web"""
        # For CLI: Use tqdm directly
        if not hasattr(self, '_pbar'):
            self._pbar = tqdm(total=total, desc=desc)
        self._pbar.update(1)  # Update by 1 instead of setting n directly

        # For web: Return progress info as dict
        return {
            'current': current,
            'total': total,
            'percentage': (current / total * 100) if total > 0 else 0,
            'description': desc,
            'chapter_title': chapter_title
        }

    def download_novel(self, novel_id: int) -> str:
        """Download a novel"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nÂºÄÂßã‰∏ãËΩΩ„Ää{name}„ÄãÔºåÁä∂ÊÄÅÔºö{status[0]}')

            # ÂàõÂª∫"‰π¶Âêç-id"Êñá‰ª∂Â§πÁªìÊûÑ
            book_folder_name = f"{safe_name}-{novel_id}"
            book_download_dir = os.path.join(self.download_dir, book_folder_name)    # ÂÖ∂‰ªñÊ†ºÂºèÊñá‰ª∂ÁõÆÂΩï
            book_json_dir = os.path.join(self.bookstore_dir, book_folder_name)       # JSONÊñá‰ª∂ÁõÆÂΩï
            chapters_dir = os.path.join(book_download_dir, "Chapters")
            
            # ÂàõÂª∫ÂøÖÈúÄÁöÑÁõÆÂΩï
            os.makedirs(book_download_dir, exist_ok=True)
            os.makedirs(book_json_dir, exist_ok=True) 
            os.makedirs(chapters_dir, exist_ok=True)
            
            self.log_callback(f'ÂàõÂª∫Êñá‰ª∂Â§π: {book_folder_name}')

            # ‰ΩøÁî®ÂéüÂßãÁ´†ËäÇÂàóË°®ÁöÑÈ°∫Â∫è
            chapter_list = list(chapters.items())  # ËΩ¨Êç¢‰∏∫ÂàóË°®‰øùÊåÅÈ°∫Â∫è
            total_chapters = len(chapter_list)
            completed_chapters = 0

            # ÂàõÂª∫‰∏Ä‰∏™ÊúâÂ∫èÂ≠óÂÖ∏Êù•‰øùÂ≠òÁ´†ËäÇÂÜÖÂÆπ
            novel_content = {}

            # ‰∏ãËΩΩÁ´†ËäÇ
            with tqdm(total=total_chapters, desc='‰∏ãËΩΩËøõÂ∫¶') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter,
                            title,
                            chapter_id,
                            {}
                        ): (title, chapter_id) for title, chapter_id in chapter_list
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        title, _ = future_to_chapter[future]
                        try:
                            content = future.result()
                            if content:
                                clean_title = title.strip()
                                novel_content[clean_title] = content  # ‰øùÂ≠òÊó∂ÂéªÈô§Ê†áÈ¢òÁöÑÁ©∫ÁôΩÂ≠óÁ¨¶
                                
                                # È¢ùÂ§ñ‰øùÂ≠òÂçïÁã¨ÁöÑÁ´†ËäÇTXTÊñá‰ª∂Âà∞ChaptersÊñá‰ª∂Â§π
                                chapter_filename = f"{self._sanitize_filename(clean_title)}.txt"
                                chapter_path = os.path.join(chapters_dir, chapter_filename)
                                
                                with open(chapter_path, 'w', encoding='UTF-8') as f:
                                    f.write(f"{clean_title}\n\n{content}")
                                    
                        except Exception as e:
                            self.log_callback(f'‰∏ãËΩΩÁ´†ËäÇÂ§±Ë¥• {title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            '‰∏ãËΩΩËøõÂ∫¶',
                            title
                        )

            # Ê†πÊçÆÈÖçÁΩÆÂÜ≥ÂÆö‰øùÂ≠òÂì™‰∫õÊ†ºÂºè
            results = []
            
            # ‰øùÂ≠òJSONÊñá‰ª∂ÔºàÂøÖÈ°ªË¶ÅÁöÑÔºâ
            json_path = os.path.join(book_json_dir, f'{safe_name}.json')
            with open(json_path, 'w', encoding='UTF-8') as f:
                json.dump(novel_content, f, ensure_ascii=False, indent=4)
            self.log_callback(f'‚úÖ JSONÊñá‰ª∂Â∑≤‰øùÂ≠ò: {json_path}')
            results.append('json')
            
            # ‰øùÂ≠òTXTÊñá‰ª∂ÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            if self.config.enable_txt:
                result = self._save_single_txt_to_folder(safe_name, novel_content, book_download_dir)
                if result == 's':
                    self.log_callback(f'‚úÖ TXTÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                    results.append('txt')
                    
                    # Â¶ÇÊûúÈÖçÁΩÆË¶ÅÊ±ÇÂà†Èô§Á´†ËäÇÊñá‰ª∂Â§π
                    if self.config.delete_chapters_after_merge:
                        try:
                            import shutil
                            shutil.rmtree(chapters_dir)
                            self.log_callback(f'üóëÔ∏è Â∑≤Âà†Èô§Á´†ËäÇÊñá‰ª∂Â§π: {chapters_dir}')
                        except Exception as e:
                            self.log_callback(f'‚ö†Ô∏è Âà†Èô§Á´†ËäÇÊñá‰ª∂Â§πÂ§±Ë¥•: {e}')
            
            # ‰øùÂ≠òEPUBÊñá‰ª∂ÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            if self.config.enable_epub:
                try:
                    epub_result = self._save_epub_from_content(safe_name, novel_content, book_download_dir, novel_id)
                    if epub_result == 's':
                        self.log_callback(f'‚úÖ EPUBÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                        results.append('epub')
                except Exception as e:
                    self.log_callback(f'‚ö†Ô∏è EPUB‰øùÂ≠òÂ§±Ë¥•: {e}')
            
            # ‰øùÂ≠òHTMLÊñá‰ª∂ÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            if self.config.enable_html:
                try:
                    html_result = self._save_html_from_content(safe_name, novel_content, book_download_dir)
                    if html_result == 's':
                        self.log_callback(f'‚úÖ HTMLÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                        results.append('html')
                except Exception as e:
                    self.log_callback(f'‚ö†Ô∏è HTML‰øùÂ≠òÂ§±Ë¥•: {e}')
            
            # ‰øùÂ≠òLaTeXÊñá‰ª∂ÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            if self.config.enable_latex:
                try:
                    latex_result = self._save_latex_from_content(safe_name, novel_content, book_download_dir)
                    if latex_result == 's':
                        self.log_callback(f'‚úÖ LaTeXÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                        results.append('latex')
                        
                        # Â¶ÇÊûú‰πüÂêØÁî®‰∫ÜPDFÔºå‰ªéLaTeXÁîüÊàêPDF
                        if self.config.enable_pdf:
                            try:
                                pdf_result = self._generate_pdf_from_latex(safe_name, book_download_dir)
                                if pdf_result == 's':
                                    self.log_callback(f'‚úÖ PDFÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                                    results.append('pdf')
                            except Exception as e:
                                self.log_callback(f'‚ö†Ô∏è PDFÁîüÊàêÂ§±Ë¥•: {e}')
                except Exception as e:
                    self.log_callback(f'‚ö†Ô∏è LaTeX‰øùÂ≠òÂ§±Ë¥•: {e}')
            elif self.config.enable_pdf:
                # Â¶ÇÊûúÂè™ÂêØÁî®‰∫ÜPDFËÄåÊ≤°ÊúâÂêØÁî®LaTeXÔºåÂÖàÁîüÊàêLaTeXÂÜçËΩ¨PDF
                try:
                    latex_result = self._save_latex_from_content(safe_name, novel_content, book_download_dir)
                    if latex_result == 's':
                        pdf_result = self._generate_pdf_from_latex(safe_name, book_download_dir)
                        if pdf_result == 's':
                            self.log_callback(f'‚úÖ PDFÊñá‰ª∂Â∑≤‰øùÂ≠ò')
                            results.append('pdf')
                            # Âà†Èô§‰∏¥Êó∂LaTeXÊñá‰ª∂
                            try:
                                latex_path = os.path.join(book_download_dir, f'{safe_name}.tex')
                                if os.path.exists(latex_path):
                                    os.remove(latex_path)
                            except:
                                pass
                except Exception as e:
                    self.log_callback(f'‚ö†Ô∏è PDFÁîüÊàêÂ§±Ë¥•: {e}')
            
            # ËøîÂõûÁªìÊûú
            if results:
                self.log_callback(f'üéâ ‰∏ãËΩΩÂÆåÊàêÔºÅÂ∑≤‰øùÂ≠òÊ†ºÂºè: {", ".join(results)}')
                return 's'
            else:
                self.log_callback(f'‚ö†Ô∏è Êú™ÂêØÁî®‰ªª‰ΩïËæìÂá∫Ê†ºÂºè')
                return 'err'

        except Exception as e:
            self.log_callback(f'‰∏ãËΩΩÂ§±Ë¥•: {str(e)}')
            return 'err'

    def search_novel(self, keyword: str) -> List[Dict]:
        """
        Search for novels by keyword
        Returns list of novel info dictionaries
        """
        if not keyword:
            return []

        # Use the correct API endpoint from ref_main.py
        url = f"https://api5-normal-lf.fqnovel.com/reading/bookapi/search/page/v/"
        params = {
            "query": keyword,
            "aid": "1967",
            "channel": "0",
            "os_version": "0",
            "device_type": "0",
            "device_platform": "0",
            "iid": "466614321180296",
            "passback": "{(page-1)*10}",
            "version_code": "999"
        }

        try:
            response = req.get(url, params=params, headers=self.headers)
            response.raise_for_status()
            data = response.json()

            if data['code'] == 0 and data['data']:
                return data['data']
            else:
                self.log_callback("Ê≤°ÊúâÊâæÂà∞Áõ∏ÂÖ≥‰π¶Á±ç„ÄÇ")
                return []

        except req.RequestException as e:
            self.log_callback(f"ÁΩëÁªúËØ∑Ê±ÇÂ§±Ë¥•: {str(e)}")
            return []
        except json.JSONDecodeError as e:
            self.log_callback(f"Ëß£ÊûêÊêúÁ¥¢ÁªìÊûúÂ§±Ë¥•: {str(e)}")
            return []
        except Exception as e:
            self.log_callback(f'ÊêúÁ¥¢Â§±Ë¥•: {str(e)}')
            return []

    # ... Additional helper methods would go here ...

    def _get_initial_chapter_id(self) -> int:
        """Get an initial chapter ID for cookie testing"""
        test_novel_id = 7143038691944959011  # Example novel ID
        chapters = self._get_chapter_list(test_novel_id)
        if chapters and len(chapters[1]) > 21:
            return int(random.choice(list(chapters[1].values())[21:]))
        raise Exception("Failed to get initial chapter ID")

    def _get_new_cookie(self, chapter_id: int):
        """Generate new cookie - ‰ºòÂåñÁâàÊú¨ÔºåÂáèÂ∞ëÈ™åËØÅÊ¨°Êï∞"""
        base_timestamp = int(time.time() * 1000)
        
        # Âè™Â∞ùËØï5Ê¨°ÔºåÂáèÂ∞ëÁ≠âÂæÖÊó∂Èó¥
        for i in range(5):
            cookie_id = base_timestamp + random.randint(1000, 999999)
            time.sleep(0.1)  # ÂáèÂ∞ëÂª∂ËøüÂà∞100ms
            self.cookie = f'novel_web_id={cookie_id}'
            
            try:
                if len(self._download_chapter_content(chapter_id, test_mode=True)) > 200:
                    with open(self.cookie_path, 'w', encoding='UTF-8') as f:
                        json.dump(self.cookie, f)
                    return
            except:
                continue
        
        # Âø´ÈÄüÂ§±Ë¥•Ôºå‰ΩøÁî®ÈªòËÆ§cookie
        self.cookie = f'novel_web_id={base_timestamp}'
        print("‚ö†Ô∏è CookieÁîüÊàêÂ§±Ë¥•Ôºå‰ΩøÁî®ÈªòËÆ§ÂÄº")

    def _download_txt(self, novel_id: int) -> str:
        """Download novel in TXT format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nÂºÄÂßã‰∏ãËΩΩ„Ää{name}„ÄãÔºåÁä∂ÊÄÅÔºö{status[0]}')

            # Set book_json_path for the current download
            self.book_json_path = os.path.join(self.bookstore_dir, f'{safe_name}.json')

            # Initialize global variables for this download
            self.zj = {}
            self.cs = 0
            self.tcs = 0

            # Store metadata at the start
            metadata = {
                '_metadata': {
                    'novel_id': str(novel_id),  # Á°Æ‰øùÂ≠òÂÇ®‰∏∫Â≠óÁ¨¶‰∏≤
                    'name': name,
                    'status': status[0] if status else None,
                    'last_updated': time.strftime('%Y-%m-%d %H:%M:%S')
                }
            }

            # Load existing content and merge with metadata
            existing_content = {}
            if os.path.exists(self.book_json_path):
                with open(self.book_json_path, 'r', encoding='UTF-8') as f:
                    existing_content = json.load(f)
                    # Keep existing chapters but update metadata
                    if isinstance(existing_content, dict):
                        existing_content.update(metadata)
            else:
                existing_content = metadata
                # Save initial metadata
                with open(self.book_json_path, 'w', encoding='UTF-8') as f:
                    json.dump(existing_content, f, ensure_ascii=False)

            total_chapters = len(chapters)
            completed_chapters = 0

            # Create CLI progress bar
            with tqdm(total=total_chapters, desc='‰∏ãËΩΩËøõÂ∫¶') as pbar:
                # Download chapters
                content = existing_content.copy()  # Start with existing content including metadata
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter,
                            title,
                            chapter_id,
                            existing_content
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            chapter_content = future.result()
                            if chapter_content:
                                content[chapter_title] = chapter_content
                                # Save progress periodically
                                if completed_chapters % 5 == 0:
                                    with open(self.book_json_path, 'w', encoding='UTF-8') as f:
                                        json.dump(content, f, ensure_ascii=False)
                        except Exception as e:
                            self.log_callback(f'‰∏ãËΩΩÁ´†ËäÇÂ§±Ë¥• {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            '‰∏ãËΩΩËøõÂ∫¶',
                            chapter_title
                        )

                # Save final content
                with open(self.book_json_path, 'w', encoding='UTF-8') as f:
                    json.dump(content, f, ensure_ascii=False)

                # Generate output file
                if self.config.save_mode == SaveMode.SINGLE_TXT:
                    return self._save_single_txt(safe_name, content)
                else:
                    return self._save_split_txt(safe_name, content)

        finally:
            # Send 100% completion if not already sent
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, '‰∏ãËΩΩÂÆåÊàê')

    def _download_epub(self, novel_id: int) -> str:
        """Download novel in EPUB format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nÂºÄÂßã‰∏ãËΩΩ„Ää{name}„ÄãÔºåÁä∂ÊÄÅÔºö{status[0]}')

            # Create EPUB book
            book = epub.EpubBook()
            book.set_title(name)
            book.set_language('zh')

            # Get author info and cover
            author = self._get_author_info(novel_id)
            if author:
                book.add_author(author)
            cover_url = self._get_cover_url(novel_id)
            if cover_url:
                self._add_cover_to_epub(book, cover_url)

            total_chapters = len(chapters)
            completed_chapters = 0

            # Download chapters with progress tracking
            epub_chapters = []
            with tqdm(total=total_chapters, desc='‰∏ãËΩΩËøõÂ∫¶') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter_for_epub,
                            title,
                            chapter_id
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            epub_chapter = future.result()
                            if epub_chapter:
                                epub_chapters.append((chapter_title, epub_chapter))
                        except Exception as e:
                            self.log_callback(f'‰∏ãËΩΩÁ´†ËäÇÂ§±Ë¥• {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            '‰∏ãËΩΩËøõÂ∫¶',
                            chapter_title
                        )

            # Sort chapters by their original order
            epub_chapters.sort(key=lambda x: list(chapters.keys()).index(x[0]))
            for _, chapter in epub_chapters:
                book.add_item(chapter)

            # Add navigation
            book.toc = [chapter for _, chapter in epub_chapters]
            book.spine = ['nav'] + [chapter for _, chapter in epub_chapters]
            book.add_item(epub.EpubNcx())
            book.add_item(epub.EpubNav())

            # Save EPUB file
            epub_path = os.path.join(self.config.save_path, f'{safe_name}.epub')
            epub.write_epub(epub_path, book)
            return 's'

        finally:
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, '‰∏ãËΩΩÂÆåÊàê')

    def _download_chapter(self, title: str, chapter_id: str, existing_content: Dict) -> Optional[str]:
        """Download a single chapter with retries"""
        if title in existing_content:
            self.zj[title] = existing_content[title]  # Add this
            return existing_content[title]

        self.log_callback(f'‰∏ãËΩΩÁ´†ËäÇ: {title}')
        retries = 3
        last_error = None

        while retries > 0:
            try:
                content = self._download_chapter_content(chapter_id)
                if content == 'err':  # Add this check
                    raise Exception('Download failed')

                time.sleep(random.randint(
                    self.config.delay[0],
                    self.config.delay[1]
                ) / 1000)

                # Handle cookie refresh
                if content == 'err':
                    self.tcs += 1
                    if self.tcs > 7:
                        self.tcs = 0
                        self._get_new_cookie(self.tzj)
                    continue  # Try again with new cookie

                # Save progress periodically
                self.cs += 1
                if self.cs >= 5:
                    self.cs = 0
                    self._save_progress(title, content)

                self.zj[title] = content  # Add this
                return content

            except Exception as e:
                last_error = e
                retries -= 1
                if retries == 0:
                    self.log_callback(f'‰∏ãËΩΩÂ§±Ë¥• {title}: {str(e)}')
                    break
                time.sleep(1)

        if last_error:
            raise last_error
        return None

    def _download_chapter_for_epub(self, title: str, chapter_id: str) -> Optional[epub.EpubHtml]:
        """Download and format chapter for EPUB"""
        content = self._download_chapter(title, chapter_id, {})
        if not content:
            return None

        chapter = epub.EpubHtml(
            title=title,
            file_name=f'chapter_{chapter_id}.xhtml',
            lang='zh'
        )

        # ‰ΩøÁî®<p>Ê†áÁ≠æÂåÖË£πÊØè‰∏™ÊÆµËêΩÔºåÁ°Æ‰øùÊ≤°ÊúâÂ§ö‰ΩôÁöÑÊç¢Ë°åÁ¨¶
        formatted_content = ''.join(f'<p>{para.strip()}</p>' for para in content.split('\n') if para.strip())
        chapter.content = f'<h1>{title}</h1>{formatted_content}'
        return chapter

    def _save_single_txt(self, name: str, content: dict) -> str:
        """Save all chapters to a single TXT file"""
        output_path = os.path.join(self.download_dir, f'{name}.txt')  # ‰øùÂ≠òÂà∞‰∏ãËΩΩÁõÆÂΩï
        fg = '\n' + self.config.kgf * self.config.kg

        with open(output_path, 'w', encoding='UTF-8') as f:
            for title, chapter_content in content.items():
                # Ë∑≥ËøáÂÖÉÊï∞ÊçÆÈ°π
                if title.startswith('_'):
                    continue
                    
                f.write(f'\n{title}{fg}')
                if self.config.kg == 0:
                    f.write(f'{chapter_content}\n')
                else:
                    # Â∞ÜÊõøÊç¢ÁªìÊûúÂ≠òÂÇ®Âú®‰∏Ä‰∏™ÂèòÈáè‰∏≠
                    modified_content = chapter_content.replace("\n", fg)
                    # Âú® f-string ‰∏≠‰ΩøÁî®Ëøô‰∏™ÂèòÈáè
                    f.write(f'{modified_content}\n')
        
        return 's'  # ËøîÂõûÊàêÂäüÊ†áËØÜ

    def _save_single_txt_to_folder(self, name: str, content: dict, output_dir: str) -> str:
        """Save all chapters to a single TXT file in specified folder with smart chapter ordering"""
        output_path = os.path.join(output_dir, f'{name}.txt')
        fg = '\n' + self.config.kgf * self.config.kg

        # ÊèêÂèñÊâÄÊúâÁ´†ËäÇÂèäÂÖ∂ÁºñÂè∑ÔºåË∑≥ËøáÂÖÉÊï∞ÊçÆ
        chapters_with_numbers = []
        for title, chapter_content in content.items():
            if title.startswith('_'):
                continue
            chapter_num = self._extract_chapter_number(title)
            chapters_with_numbers.append((chapter_num, title, chapter_content))
        
        # ÊåâÁ´†ËäÇÁºñÂè∑ÊéíÂ∫è
        chapters_with_numbers.sort(key=lambda x: x[0])
        
        self.log_callback(f'ÊåâÈ°∫Â∫èÂêàÂπ∂Á´†ËäÇ: ÂÖ± {len(chapters_with_numbers)} Á´†')
        
        with open(output_path, 'w', encoding='UTF-8') as f:
            if not chapters_with_numbers:
                f.write('ÊöÇÊó†Á´†ËäÇÂÜÖÂÆπ\n')
                return 's'
            
            # Ëé∑ÂèñÁ´†ËäÇÁºñÂè∑ËåÉÂõ¥
            min_chapter = chapters_with_numbers[0][0]
            max_chapter = chapters_with_numbers[-1][0]
            
            # ÂàõÂª∫Á´†ËäÇÂ≠óÂÖ∏‰ª•‰æøÂø´ÈÄüÊü•Êâæ
            chapter_dict = {num: (title, content) for num, title, content in chapters_with_numbers}
            
            # ÊåâÈ°∫Â∫èÂÜôÂÖ•Á´†ËäÇÔºåÂ§ÑÁêÜÁº∫Â§±Á´†ËäÇ
            for chapter_num in range(min_chapter, max_chapter + 1):
                if chapter_num in chapter_dict:
                    title, chapter_content = chapter_dict[chapter_num]
                    f.write(f'\n{title}{fg}')
                    if self.config.kg == 0:
                        f.write(f'{chapter_content}\n')
                    else:
                        modified_content = chapter_content.replace("\n", fg)
                        f.write(f'{modified_content}\n')
                else:
                    # Â§ÑÁêÜÁº∫Â§±Á´†ËäÇ
                    missing_title = f'Á¨¨ {chapter_num} Á´† ÂΩìÂâçÁ´†ËäÇÁº∫Â§±'
                    f.write(f'\n{missing_title}{fg}')
                    f.write(f'Êä±Ê≠âÔºåÂΩìÂâçÁ´†ËäÇ‰∏ãËΩΩÂ§±Ë¥•ÊàñÊöÇ‰∏çÂèØÁî®\n')
                    self.log_callback(f'‚ö†Ô∏è Ê£ÄÊµãÂà∞Áº∫Â§±Á´†ËäÇ: Á¨¨ {chapter_num} Á´†')
        
        return 's'  # ËøîÂõûÊàêÂäüÊ†áËØÜ

    def _save_split_txt_to_folder(self, name: str, content: Dict, output_dir: str) -> str:
        """Save each chapter to a separate TXT file in specified folder"""
        chapter_output_dir = os.path.join(output_dir, name)
        os.makedirs(chapter_output_dir, exist_ok=True)

        for title, chapter_content in content.items():
            # Ë∑≥ËøáÂÖÉÊï∞ÊçÆÈ°π
            if title.startswith('_'):
                continue
                
            chapter_path = os.path.join(
                chapter_output_dir,
                f'{self._sanitize_filename(title)}.txt'
            )
            if self.config.kg == 0:
                replacement_content = chapter_content
            else:
                replacement_content = chapter_content.replace("\n", self.config.kgf * self.config.kg)

            with open(chapter_path, 'w', encoding='UTF-8') as f:
                f.write(f'{replacement_content}\n')

        return 's'

    def _save_split_txt(self, name: str, content: Dict) -> str:
        """Save each chapter to a separate TXT file"""
        output_dir = os.path.join(self.download_dir, name)  # ‰øùÂ≠òÂà∞‰∏ãËΩΩÁõÆÂΩï
        os.makedirs(output_dir, exist_ok=True)

        for title, chapter_content in content.items():
            chapter_path = os.path.join(
                output_dir,
                f'{self._sanitize_filename(title)}.txt'
            )
            if self.config.kg == 0:
                replacement_content = chapter_content
            else:
                replacement_content = chapter_content.replace("\n", self.config.kgf * self.config.kg)

            with open(chapter_path, 'w', encoding='UTF-8') as f:
                f.write(f'{replacement_content}\n')

        return 's'

    def update_all_novels(self):
        """Update all novels in records"""
        if not os.path.exists(self.record_path):
            self.log_callback("No novels to update")
            return

        with open(self.record_path, 'r', encoding='UTF-8') as f:
            novels = json.load(f)

        for novel_id in novels:
            self.log_callback(f"Updating novel {novel_id}")
            status = self.download_novel(novel_id)
            if not status:
                novels.remove(novel_id)

        with open(self.record_path, 'w', encoding='UTF-8') as f:
            json.dump(novels, f)

    def _download_html(self, novel_id: int) -> str:
        """Download novel in HTML format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            html_dir = os.path.join(self.config.save_path, f"{safe_name}(html)")
            os.makedirs(html_dir, exist_ok=True)

            self.log_callback(f'\nÂºÄÂßã‰∏ãËΩΩ„Ää{name}„ÄãÔºåÁä∂ÊÄÅÔºö{status[0]}')

            # Create index.html
            toc_content = self._create_html_index(name, chapters)
            with open(os.path.join(html_dir, "index.html"), "w", encoding='UTF-8') as f:
                f.write(toc_content)

            total_chapters = len(chapters)
            completed_chapters = 0

            # Download chapters with progress tracking
            with tqdm(total=total_chapters, desc='‰∏ãËΩΩËøõÂ∫¶') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter_for_html,
                            title,
                            chapter_id,
                            html_dir,
                            list(chapters.keys())
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            future.result()
                        except Exception as e:
                            self.log_callback(f'‰∏ãËΩΩÁ´†ËäÇÂ§±Ë¥• {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            '‰∏ãËΩΩËøõÂ∫¶',
                            chapter_title
                        )

            return 's'

        finally:
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, '‰∏ãËΩΩÂÆåÊàê')

    def _download_latex(self, novel_id: int) -> str:
        """Download novel in LaTeX format"""
        try:
            name, chapters, status = self._get_chapter_list(novel_id)
            if name == 'err':
                return 'err'

            safe_name = self._sanitize_filename(name)
            self.log_callback(f'\nÂºÄÂßã‰∏ãËΩΩ„Ää{name}„ÄãÔºåÁä∂ÊÄÅÔºö{status[0]}')

            # Create LaTeX document header
            latex_content = self._create_latex_header(name)

            total_chapters = len(chapters)
            completed_chapters = 0
            chapter_contents = []

            # Download chapters with progress tracking
            with tqdm(total=total_chapters, desc='‰∏ãËΩΩËøõÂ∫¶') as pbar:
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.xc) as executor:
                    future_to_chapter = {
                        executor.submit(
                            self._download_chapter_for_latex,
                            title,
                            chapter_id
                        ): title
                        for title, chapter_id in chapters.items()
                    }

                    for future in concurrent.futures.as_completed(future_to_chapter):
                        chapter_title = future_to_chapter[future]
                        try:
                            chapter_content = future.result()
                            if chapter_content:
                                chapter_contents.append((chapter_title, chapter_content))
                        except Exception as e:
                            self.log_callback(f'‰∏ãËΩΩÁ´†ËäÇÂ§±Ë¥• {chapter_title}: {str(e)}')

                        completed_chapters += 1
                        pbar.update(1)
                        self.progress_callback(
                            completed_chapters,
                            total_chapters,
                            '‰∏ãËΩΩËøõÂ∫¶',
                            chapter_title
                        )

            # Sort chapters and add to document
            chapter_contents.sort(key=lambda x: list(chapters.keys()).index(x[0]))
            for title, content in chapter_contents:
                latex_content += self._format_latex_chapter(title, content)

            # Add document footer and save
            latex_content += "\n\\end{document}"
            latex_path = os.path.join(self.config.save_path, f'{safe_name}.tex')
            with open(latex_path, 'w', encoding='UTF-8') as f:
                f.write(latex_content)

            return 's'

        finally:
            if 'completed_chapters' in locals() and 'total_chapters' in locals():
                if completed_chapters < total_chapters:
                    self.progress_callback(total_chapters, total_chapters, '‰∏ãËΩΩÂÆåÊàê')

    def _create_html_index(self, title: str, chapters: Dict[str, str]) -> str:
        """Create HTML index page with CSS styling"""
        return f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title} - ÁõÆÂΩï</title>
    <style>
        :root {{
            --bg-color: #f5f5f5;
            --text-color: #333;
            --link-color: #007bff;
            --hover-color: #0056b3;
        }}
        @media (prefers-color-scheme: dark) {{
            :root {{
                --bg-color: #222;
                --text-color: #fff;
                --link-color: #66b0ff;
                --hover-color: #99ccff;
            }}
        }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: var(--bg-color);
            color: var(--text-color);
        }}
        h1 {{
            text-align: center;
            margin-bottom: 30px;
        }}
        .toc {{
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
        }}
        .toc a {{
            color: var(--link-color);
            text-decoration: none;
            display: block;
            padding: 8px 0;
            transition: all 0.2s;
        }}
        .toc a:hover {{
            color: var(--hover-color);
            transform: translateX(10px);
        }}
    </style>
</head>
<body>
    <h1>{title}</h1>
    <div class="toc">
        {''.join(f'<a href="{self._sanitize_filename(title)}.html">{title}</a>' for title in chapters.keys())}
    </div>
</body>
</html>
"""

    def _create_latex_header(self, title: str) -> str:
        """Create LaTeX document header"""
        return f"""\\documentclass[12pt,a4paper]{{article}}
\\usepackage{{ctex}}
\\usepackage{{geometry}}
\\usepackage{{hyperref}}
\\usepackage{{bookmark}}

\\geometry{{
    top=2.54cm,
    bottom=2.54cm,
    left=3.18cm,
    right=3.18cm
}}

\\title{{{title}}}
\\author{{Generated by NovelDownloader}}
\\date{{\\today}}

\\begin{{document}}
\\maketitle
\\tableofcontents
\\newpage
"""

    def _download_chapter_for_html(self, title: str, chapter_id: str, output_dir: str, all_titles: List[str]) -> None:
        """Download and format chapter for HTML"""
        content = self._download_chapter(title, chapter_id, {})
        if not content:
            return

        current_index = all_titles.index(title)
        prev_link = f'<a href="{self._sanitize_filename(all_titles[current_index - 1])}.html">‰∏ä‰∏ÄÁ´†</a>' if current_index > 0 else ''
        next_link = f'<a href="{self._sanitize_filename(all_titles[current_index + 1])}.html">‰∏ã‰∏ÄÁ´†</a>' if current_index < len(
            all_titles) - 1 else ''

        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        /* ... Same CSS variables as index ... */
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.8;
            margin: 0;
            padding: 20px;
            background-color: var(--bg-color);
            color: var(--text-color);
            max-width: 800px;
            margin: 0 auto;
        }}
        .navigation {{
            display: flex;
            justify-content: space-between;
            padding: 20px 0;
            position: sticky;
            top: 0;
            background-color: var(--bg-color);
        }}
        .navigation a {{
            color: var(--link-color);
            text-decoration: none;
            padding: 8px 16px;
            border: 1px solid var(--link-color);
            border-radius: 4px;
        }}
        .content {{
            text-indent: 2em;
            margin-bottom: 40px;
        }}
    </style>
</head>
<body>
    <div class="navigation">
        <a href="index.html">ÁõÆÂΩï</a>
        {prev_link}
        {next_link}
    </div>
    <h1>{title}</h1>
    <div class="content">
        {content.replace(chr(10), '<br>' + self.config.kgf * self.config.kg)}
    </div>
    <div class="navigation">
        <a href="index.html">ÁõÆÂΩï</a>
        {prev_link}
        {next_link}
    </div>
</body>
</html>
"""

        with open(os.path.join(output_dir, f"{self._sanitize_filename(title)}.html"), "w", encoding='UTF-8') as f:
            f.write(html_content)

    def _download_chapter_for_latex(self, title: str, chapter_id: str) -> Optional[str]:
        """Download and format chapter for LaTeX"""
        content = self._download_chapter(title, chapter_id, {})
        if not content:
            return None
        return self._format_latex_chapter(title, content)

    def _format_latex_chapter(self, title: str, content: str) -> str:
        """Format chapter content for LaTeX"""
        # Escape special LaTeX characters
        special_chars = ['\\', '{', '}', '&', '#', '$', '^', '_', '~', '%']
        for char in special_chars:
            content = content.replace(char, f'\\{char}')
            title = title.replace(char, f'\\{char}')

        # Format content with proper spacing
        content = content.replace('\n', '\n\n' + self.config.kgf * self.config.kg)

        return f"""
\\section{{{title}}}
{content}
"""

    def _test_cookie(self, chapter_id: int, cookie: str) -> str:
        """Test if cookie is valid"""
        self.cookie = cookie
        if len(self._download_chapter_content(chapter_id, test_mode=True)) > 200:
            return 's'
        return 'err'

    def _get_chapter_list(self, novel_id: int) -> tuple:
        """Get novel info and chapter list"""
        url = f'https://fanqienovel.com/page/{novel_id}'
        response = req.get(url, headers=self.headers)
        ele = etree.HTML(response.text)

        chapters = {}
        a_elements = ele.xpath('//div[@class="chapter"]/div/a')
        if not a_elements:  # Add this check
            return 'err', {}, []

        for a in a_elements:
            href = a.xpath('@href')
            if not href:  # Add this check
                continue
            chapters[a.text] = href[0].split('/')[-1]

        title = ele.xpath('//h1/text()')
        status = ele.xpath('//span[@class="info-label-yellow"]/text()')

        if not title or not status:  # Check both title and status
            return 'err', {}, []

        return title[0], chapters, status

    def _download_chapter_content(self, chapter_id: int, test_mode: bool = False) -> str:
        """Download content with fallback and better error handling"""
        headers = self.headers.copy()
        headers['cookie'] = self.cookie

        for attempt in range(3):
            try:
                # Try primary method
                response = req.get(
                    f'https://fanqienovel.com/reader/{chapter_id}',
                    headers=headers,
                    timeout=10
                )
                response.raise_for_status()

                content = '\n'.join(
                    etree.HTML(response.text).xpath(
                        '//div[@class="muye-reader-content noselect"]//p/text()'
                    )
                )

                if test_mode:
                    return content

                try:
                    return self._decode_content(content)
                except:
                    # Try alternative decoding mode
                    try:
                        return self._decode_content(content, mode=1)
                    except:
                        # Fallback HTML processing
                        content = content[6:]
                        tmp = 1
                        result = ''
                        for i in content:
                            if i == '<':
                                tmp += 1
                            elif i == '>':
                                tmp -= 1
                            elif tmp == 0:
                                result += i
                            elif tmp == 1 and i == 'p':
                                result = (result + '\n').replace('\n\n', '\n')
                        return result

            except Exception as e:
                # Try alternative API endpoint
                try:
                    response = req.get(
                        f'https://fanqienovel.com/api/reader/full?itemId={chapter_id}',
                        headers=headers
                    )
                    content = json.loads(response.text)['data']['chapterData']['content']

                    if test_mode:
                        return content

                    return self._decode_content(content)
                except:
                    if attempt == 2:  # Last attempt
                        if test_mode:
                            return 'err'
                        raise Exception(f"Download failed after 3 attempts: {str(e)}")
                    time.sleep(1)

    def _get_author_info(self, novel_id: int) -> Optional[str]:
        """Get author information from novel page"""
        url = f'https://fanqienovel.com/page/{novel_id}'
        try:
            response = req.get(url, headers=self.headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            script_tag = soup.find('script', type="application/ld+json")
            if script_tag:
                data = json.loads(script_tag.string)
                if 'author' in data:
                    return data['author'][0]['name']
        except Exception as e:
            self.log_callback(f"Ëé∑Âèñ‰ΩúËÄÖ‰ø°ÊÅØÂ§±Ë¥•: {str(e)}")
        return None

    def _get_cover_url(self, novel_id: int) -> Optional[str]:
        """Get cover image URL from novel page"""
        url = f'https://fanqienovel.com/page/{novel_id}'
        try:
            response = req.get(url, headers=self.headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            script_tag = soup.find('script', type="application/ld+json")
            if script_tag:
                data = json.loads(script_tag.string)
                if 'image' in data:
                    return data['image'][0]
        except Exception as e:
            self.log_callback(f"Ëé∑ÂèñÂ∞ÅÈù¢ÂõæÁâáÂ§±Ë¥•: {str(e)}")
        return None

    def _add_cover_to_epub(self, book: epub.EpubBook, cover_url: str):
        """Add cover image to EPUB book"""
        try:
            response = req.get(cover_url)
            if response.status_code == 200:
                book.set_cover('cover.jpg', response.content)

                # Add cover page
                cover_content = f'''
                    <div style="text-align: center; padding: 0; margin: 0;">
                        <img src="cover.jpg" alt="Cover" style="max-width: 100%; height: auto;"/>
                    </div>
                '''
                cover_page = epub.EpubHtml(
                    title='Cover',
                    file_name='cover.xhtml',
                    content=cover_content,
                    media_type='image/jpeg'
                )
                book.add_item(cover_page)
                book.spine.insert(0, cover_page)
        except Exception as e:
            self.log_callback(f"Ê∑ªÂä†Â∞ÅÈù¢Â§±Ë¥•: {str(e)}")

    def _extract_chapter_number(self, title: str) -> int:
        """Extract chapter number from title for sorting"""
        # Â∞ùËØïÊèêÂèñÁ´†ËäÇÁºñÂè∑ÁöÑÂ§öÁßçÊ®°Âºè
        patterns = [
            r'Á¨¨\s*(\d+)\s*Á´†',      # Á¨¨1Á´†, Á¨¨ 1 Á´†
            r'Á¨¨\s*([‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅÁôæÂçÉ‰∏á]+)\s*Á´†',  # Á¨¨‰∏ÄÁ´†, Á¨¨‰∫åÂçÅÁ´†
            r'Á´†ËäÇ?\s*(\d+)',        # Á´†ËäÇ1, Á´†1  
            r'(\d+)\s*Á´†',           # 1Á´†
            r'Chapter\s*(\d+)',      # Chapter 1
            r'Ch\s*(\d+)',           # Ch 1
            r'^(\d+)',               # ÂºÄÂ§¥ÁöÑÊï∞Â≠ó
        ]
        
        for pattern in patterns:
            match = re.search(pattern, title, re.IGNORECASE)
            if match:
                chapter_num_str = match.group(1)
                
                # Â§ÑÁêÜ‰∏≠ÊñáÊï∞Â≠ó
                if chapter_num_str in ['‰∏Ä', '‰∫å', '‰∏â', 'Âõõ', '‰∫î', 'ÂÖ≠', '‰∏É', 'ÂÖ´', '‰πù', 'ÂçÅ']:
                    chinese_numbers = {'‰∏Ä': 1, '‰∫å': 2, '‰∏â': 3, 'Âõõ': 4, '‰∫î': 5, 
                                     'ÂÖ≠': 6, '‰∏É': 7, 'ÂÖ´': 8, '‰πù': 9, 'ÂçÅ': 10}
                    return chinese_numbers.get(chapter_num_str, 0)
                
                # Â§ÑÁêÜÈòøÊãâ‰ºØÊï∞Â≠ó
                try:
                    return int(chapter_num_str)
                except ValueError:
                    continue
        
        # Â¶ÇÊûúÊ≤°ÊúâÊâæÂà∞Á´†ËäÇÁºñÂè∑ÔºåËøîÂõû0ÔºàÂ∞ÜÊéíÂú®ÊúÄÂâçÈù¢Ôºâ
        return 0

    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize filename for different platforms"""
        illegal_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*']
        illegal_chars_rep = ['Ôºú', 'Ôºû', 'Ôºö', 'ÔºÇ', 'Ôºè', 'Ôºº', 'ÔΩú', 'Ôºü', 'Ôºä']
        for old, new in zip(illegal_chars, illegal_chars_rep):
            filename = filename.replace(old, new)
        return filename

    def _parse_novel_id(self, novel_id: Union[str, int]) -> Optional[int]:
        """Parse novel ID from input (URL or ID)"""
        if isinstance(novel_id, str) and novel_id.startswith('http'):
            novel_id = novel_id.split('?')[0].split('/')[-1]
        try:
            return int(novel_id)
        except ValueError:
            self.log_callback(f'Invalid novel ID: {novel_id}')
            return None

    def get_downloaded_novels(self) -> List[Dict[str, str]]:
        """Get list of downloaded novels with their paths"""
        novels = []
        for filename in os.listdir(self.bookstore_dir):
            if filename.endswith('.json'):
                novel_name = filename[:-5]  # Remove .json extension
                json_path = os.path.join(self.bookstore_dir, filename)

                try:
                    with open(json_path, 'r', encoding='UTF-8') as f:
                        novel_data = json.load(f)
                        metadata = novel_data.get('_metadata', {})

                        novels.append({
                            'name': novel_name,
                            'novel_id': metadata.get('novel_id'),
                            'status': metadata.get('status'),
                            'last_updated': metadata.get('last_updated'),
                            'json_path': json_path,
                            'txt_path': os.path.join(self.config.save_path, f'{novel_name}.txt'),
                            'epub_path': os.path.join(self.config.save_path, f'{novel_name}.epub'),
                            'html_path': os.path.join(self.config.save_path, f'{novel_name}(html)'),
                            'latex_path': os.path.join(self.config.save_path, f'{novel_name}.tex')
                        })
                except Exception as e:
                    self.log_callback(f"Error reading novel data for {novel_name}: {str(e)}")
                    # Add novel with minimal info if metadata can't be read
                    novels.append({
                        'name': novel_name,
                        'novel_id': None,
                        'status': None,
                        'last_updated': None,
                        'json_path': json_path,
                        'txt_path': os.path.join(self.config.save_path, f'{novel_name}.txt'),
                        'epub_path': os.path.join(self.config.save_path, f'{novel_name}.epub'),
                        'html_path': os.path.join(self.config.save_path, f'{novel_name}(html)'),
                        'latex_path': os.path.join(self.config.save_path, f'{novel_name}.tex')
                    })
        return novels

    def backup_data(self, backup_dir: str):
        """Backup all data to specified directory"""
        os.makedirs(backup_dir, exist_ok=True)

        # Backup configuration
        if os.path.exists(self.config_path):
            shutil.copy2(self.config_path, os.path.join(backup_dir, 'config.json'))

        # Backup records
        if os.path.exists(self.record_path):
            shutil.copy2(self.record_path, os.path.join(backup_dir, 'record.json'))

        # Backup novels
        novels_backup_dir = os.path.join(backup_dir, 'novels')
        os.makedirs(novels_backup_dir, exist_ok=True)
        for novel in self.get_downloaded_novels():
            shutil.copy2(novel['json_path'], novels_backup_dir)

    def _decode_content(self, content: str, mode: int = 0) -> str:
        """Decode novel content using both charset modes"""
        result = ''
        for char in content:
            uni = ord(char)
            if self.CODE[mode][0] <= uni <= self.CODE[mode][1]:
                bias = uni - self.CODE[mode][0]
                if 0 <= bias < len(self.charset[mode]) and self.charset[mode][bias] != '?':
                    result += self.charset[mode][bias]
                else:
                    result += char
            else:
                result += char
        return result

    def _update_records(self, novel_id: int):
        """Update download records"""
        if os.path.exists(self.record_path):
            with open(self.record_path, 'r', encoding='UTF-8') as f:
                records = json.load(f)
        else:
            records = []

        if novel_id not in records:
            records.append(novel_id)
            with open(self.record_path, 'w', encoding='UTF-8') as f:
                json.dump(records, f)

    def _save_progress(self, title: str, content: str):
        """Save download progress"""
        self.zj[title] = content
        with open(self.book_json_path, 'w', encoding='UTF-8') as f:
            json.dump(self.zj, f, ensure_ascii=False)

    def _save_epub_from_content(self, safe_name: str, novel_content: dict, output_dir: str, novel_id: int) -> str:
        """Âü∫‰∫éÂ∑≤‰∏ãËΩΩÂÜÖÂÆπÁîüÊàêEPUBÊñá‰ª∂Ôºå‰øùÂ≠òÂà∞ÊåáÂÆöÁõÆÂΩï"""
        try:
            # Ëé∑ÂèñÂ∞èËØ¥‰ø°ÊÅØ
            book = epub.EpubBook()
            book.set_identifier(str(novel_id))
            book.set_title(safe_name)
            book.set_language('zh')
            
            # Â∞ùËØïËé∑Âèñ‰ΩúËÄÖ‰ø°ÊÅØ
            try:
                author = self._get_author_info(novel_id)
                if author:
                    book.add_author(author)
                else:
                    book.add_author('Êú™Áü•‰ΩúËÄÖ')
            except:
                book.add_author('Êú™Áü•‰ΩúËÄÖ')
            
            # Ê∑ªÂä†Â∞ÅÈù¢ÔºàÂ¶ÇÊûúÂèØ‰ª•Ëé∑ÂèñÔºâ
            try:
                cover_url = self._get_cover_url(novel_id)
                if cover_url:
                    self._add_cover_to_epub(book, cover_url)
            except:
                pass  # Â∞ÅÈù¢Ëé∑ÂèñÂ§±Ë¥•‰∏çÂΩ±Âìç‰∏ªË¶ÅÊµÅÁ®ã
            
            # ‰∏∫ÊØè‰∏™Á´†ËäÇÂàõÂª∫EPUBÁ´†ËäÇ
            for i, (title, content) in enumerate(novel_content.items()):
                if title.startswith('_'):  # Ë∑≥ËøáÂÖÉÊï∞ÊçÆ
                    continue
                    
                chapter = epub.EpubHtml(
                    title=title,
                    file_name=f'chapter_{i+1}.xhtml',
                    lang='zh'
                )
                
                # Ê†ºÂºèÂåñÂÜÖÂÆπ
                formatted_content = ''.join(f'<p>{para.strip()}</p>' for para in content.split('\n') if para.strip())
                chapter.content = f'<h1>{title}</h1>{formatted_content}'
                
                book.add_item(chapter)
            
            # Ê∑ªÂä†ÂØºËà™
            chapters = [item for item in book.get_items() if isinstance(item, epub.EpubHtml)]
            book.toc = chapters
            book.spine = ['nav'] + chapters
            book.add_item(epub.EpubNcx())
            book.add_item(epub.EpubNav())
            
            # ‰øùÂ≠òEPUBÊñá‰ª∂Âà∞ÊåáÂÆöÁõÆÂΩï
            epub_path = os.path.join(output_dir, f'{safe_name}.epub')
            epub.write_epub(epub_path, book)
            
            return 's'
            
        except Exception as e:
            self.log_callback(f'EPUBÁîüÊàêÂ§±Ë¥•: {str(e)}')
            return 'err'
    
    def _save_html_from_content(self, safe_name: str, novel_content: dict, output_dir: str) -> str:
        """Âü∫‰∫éÂ∑≤‰∏ãËΩΩÂÜÖÂÆπÁîüÊàêHTMLÊñá‰ª∂Ôºå‰øùÂ≠òÂà∞ÊåáÂÆöÁõÆÂΩï"""
        try:
            html_dir = os.path.join(output_dir, f"{safe_name}(html)")
            os.makedirs(html_dir, exist_ok=True)
            
            # ÁîüÊàêÁ´†ËäÇÊñá‰ª∂
            all_titles = []
            for i, (title, content) in enumerate(novel_content.items()):
                if title.startswith('_'):  # Ë∑≥ËøáÂÖÉÊï∞ÊçÆ
                    continue
                    
                all_titles.append(title)
                filename = f"chapter_{i+1}.html"
                chapter_path = os.path.join(html_dir, filename)
                
                # ÂàõÂª∫HTMLÂÜÖÂÆπ
                html_content = f"""<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{ font-family: serif; line-height: 1.8; margin: 40px; background: #f9f9f9; }}
        .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        h1 {{ color: #333; border-bottom: 2px solid #eee; padding-bottom: 10px; }}
        p {{ text-indent: 2em; margin: 1em 0; }}
        .navigation {{ margin: 20px 0; text-align: center; }}
        .navigation a {{ margin: 0 10px; padding: 8px 16px; background: #007bff; color: white; text-decoration: none; border-radius: 4px; }}
        .navigation a:hover {{ background: #0056b3; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="navigation">
            <a href="index.html">ÁõÆÂΩï</a>
        </div>
        <h1>{title}</h1>
"""
                
                # Ê∑ªÂä†Á´†ËäÇÂÜÖÂÆπ
                for paragraph in content.split('\n'):
                    if paragraph.strip():
                        html_content += f"        <p>{paragraph.strip()}</p>\n"
                
                html_content += """    </div>
</body>
</html>"""
                
                with open(chapter_path, 'w', encoding='UTF-8') as f:
                    f.write(html_content)
            
            # ÁîüÊàêÁõÆÂΩïÊñá‰ª∂
            index_content = self._create_html_index(safe_name, novel_content)
            index_path = os.path.join(html_dir, 'index.html')
            with open(index_path, 'w', encoding='UTF-8') as f:
                f.write(index_content)
            
            return 's'
            
        except Exception as e:
            self.log_callback(f'HTMLÁîüÊàêÂ§±Ë¥•: {str(e)}')
            return 'err'
    
    def _save_latex_from_content(self, safe_name: str, novel_content: dict, output_dir: str) -> str:
        """Âü∫‰∫éÂ∑≤‰∏ãËΩΩÂÜÖÂÆπÁîüÊàêLaTeXÊñá‰ª∂Ôºå‰øùÂ≠òÂà∞ÊåáÂÆöÁõÆÂΩï"""
        try:
            latex_path = os.path.join(output_dir, f'{safe_name}.tex')
            
            with open(latex_path, 'w', encoding='UTF-8') as f:
                # LaTeXÊñáÊ°£Â§¥ÈÉ®
                f.write(self._create_latex_header(safe_name))
                
                # Ê∑ªÂä†Á´†ËäÇÂÜÖÂÆπ
                for title, content in novel_content.items():
                    if title.startswith('_'):  # Ë∑≥ËøáÂÖÉÊï∞ÊçÆ
                        continue
                        
                    formatted_chapter = self._format_latex_chapter(title, content)
                    f.write(formatted_chapter)
                
                # LaTeXÊñáÊ°£Â∞æÈÉ®
                f.write('\n\\end{document}\n')
            
            return 's'
            
        except Exception as e:
            self.log_callback(f'LaTeXÁîüÊàêÂ§±Ë¥•: {str(e)}')
            return 'err'
    
    def _generate_pdf_from_latex(self, safe_name: str, output_dir: str) -> str:
        """‰ΩøÁî®pdflatexÂ∞ÜLaTeXÊñá‰ª∂ÁºñËØë‰∏∫PDF"""
        try:
            import subprocess
            
            latex_file = f'{safe_name}.tex'
            latex_path = os.path.join(output_dir, latex_file)
            
            # Ê£ÄÊü•LaTeXÊñá‰ª∂ÊòØÂê¶Â≠òÂú®
            if not os.path.exists(latex_path):
                raise Exception(f'LaTeXÊñá‰ª∂‰∏çÂ≠òÂú®: {latex_path}')
            
            # Ê£ÄÊü•pdflatexÊòØÂê¶ÂèØÁî®
            try:
                subprocess.run(['pdflatex', '--version'], capture_output=True, check=True)
            except (subprocess.CalledProcessError, FileNotFoundError):
                raise Exception('pdflatexÊú™ÂÆâË£ÖÊàñ‰∏çÂú®PATH‰∏≠„ÄÇËØ∑ÂÆâË£ÖLaTeXÂèëË°åÁâàÔºàÂ¶ÇTeX LiveÊàñMiKTeXÔºâ')
            
            # ÁºñËØëLaTeX‰∏∫PDF
            self.log_callback('Ê≠£Âú®‰ΩøÁî®pdflatexÁºñËØëPDF...')
            
            # ÂàáÊç¢Âà∞ËæìÂá∫ÁõÆÂΩïÊâßË°åpdflatex
            original_cwd = os.getcwd()
            try:
                os.chdir(output_dir)
                
                # ËøêË°åpdflatexÔºåÈÄöÂ∏∏ÈúÄË¶ÅËøêË°å‰∏§Ê¨°‰ª•Ê≠£Á°ÆÁîüÊàêÁõÆÂΩïÂíåÂºïÁî®
                for i in range(2):
                    result = subprocess.run(
                        ['pdflatex', '-interaction=nonstopmode', latex_file],
                        capture_output=True,
                        text=True,
                        timeout=300  # 5ÂàÜÈíüË∂ÖÊó∂
                    )
                    
                    if result.returncode != 0:
                        # Â¶ÇÊûúÂ§±Ë¥•ÔºåÂ∞ùËØïÊü•ÁúãÊó•Âøó
                        log_file = f'{safe_name}.log'
                        error_info = f'pdflatexÁºñËØëÂ§±Ë¥• (ËøîÂõûÁ†Å: {result.returncode})'
                        if os.path.exists(log_file):
                            # ËØªÂèñÊúÄÂêéÂá†Ë°åÊó•Âøó
                            try:
                                with open(log_file, 'r', encoding='utf-8', errors='ignore') as log_f:
                                    lines = log_f.readlines()
                                    # ÂèñÊúÄÂêé20Ë°å
                                    error_lines = lines[-20:] if len(lines) > 20 else lines
                                    error_info += '\nÊúÄÂêéÂá†Ë°åÊó•Âøó:\n' + ''.join(error_lines)
                            except:
                                pass
                        raise Exception(error_info)
                
                # Ê£ÄÊü•PDFÊòØÂê¶ÁîüÊàêÊàêÂäü
                pdf_file = f'{safe_name}.pdf'
                if not os.path.exists(pdf_file):
                    raise Exception('PDFÊñá‰ª∂Êú™ÁîüÊàê')
                
                # Ê∏ÖÁêÜËæÖÂä©Êñá‰ª∂
                aux_extensions = ['.aux', '.log', '.out', '.toc', '.fls', '.fdb_latexmk']
                for ext in aux_extensions:
                    aux_file = f'{safe_name}{ext}'
                    if os.path.exists(aux_file):
                        try:
                            os.remove(aux_file)
                        except:
                            pass  # Ê∏ÖÁêÜÂ§±Ë¥•‰∏çÂΩ±Âìç‰∏ªË¶ÅÊµÅÁ®ã
                
                return 's'
                
            finally:
                os.chdir(original_cwd)
            
        except Exception as e:
            self.log_callback(f'PDFÁîüÊàêÂ§±Ë¥•: {str(e)}')
            return 'err'


def create_cli():
    """Create CLI interface using the NovelDownloader class"""
    print('Êú¨Á®ãÂ∫èÂÆåÂÖ®ÂÖçË¥π(Ê≠§ÁâàÊú¨‰∏∫WEBÁâàÔºåÁõÆÂâçÂ§Ñ‰∫éÊµãËØïÈò∂ÊÆµ)\nGithub: https://github.com/ying-ck/fanqienovel-downloader\n‰ΩúËÄÖÔºöYck & qxqycb & lingo34')
    print('‰ºòÂåñÂ¢ûÂº∫Áâà - ÊîØÊåÅYAMLÈÖçÁΩÆÊñá‰ª∂')

    # Ê£ÄÊü•ÂëΩ‰ª§Ë°åÂèÇÊï∞
    import sys
    config_path = 'config.yaml'
    
    if len(sys.argv) > 1:
        if sys.argv[1] in ['-h', '--help']:
            print('\n‰ΩøÁî®ÊñπÊ≥ï:')
            print('  python src/main.py                    # ‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆÊñá‰ª∂ config.yaml')
            print('  python src/main.py [ÈÖçÁΩÆÊñá‰ª∂Ë∑ØÂæÑ]      # ‰ΩøÁî®ÊåáÂÆöÈÖçÁΩÆÊñá‰ª∂')
            print('  python src/main.py --help            # ÊòæÁ§∫Ê≠§Â∏ÆÂä©‰ø°ÊÅØ')
            print('\nÈÖçÁΩÆÊñá‰ª∂Á§∫‰æãËØ∑ÂèÇËÄÉ config.yaml')
            return
        else:
            config_path = sys.argv[1]
    
    # Âä†ËΩΩÈÖçÁΩÆ
    if os.path.exists(config_path):
        print(f'üìÑ Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂: {config_path}')
        config = Config.from_yaml(config_path)
    else:
        if config_path != 'config.yaml':
            print(f'‚ö†Ô∏è ÈÖçÁΩÆÊñá‰ª∂‰∏çÂ≠òÂú®: {config_path}')
        print('üìÑ ‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ')
        config = Config()
    
    # ÊòæÁ§∫ÂΩìÂâçÈÖçÁΩÆÊëòË¶Å
    print(f'\nüìã ÂΩìÂâçÈÖçÁΩÆÊëòË¶Å:')
    print(f'  üóÇÔ∏è  ËæìÂá∫Ê†ºÂºè: TXT({config.enable_txt}) JSON(ÂøÖÈ°ª) EPUB({config.enable_epub}) HTML({config.enable_html}) LaTeX({config.enable_latex}) PDF({config.enable_pdf})')
    print(f'  ‚ö° Á∫øÁ®ãÊï∞: {config.thread_count}')
    print(f'  ‚è±Ô∏è  Âª∂Êó∂Ê®°Âºè: {config.delay_mode} ({config.delay[0]}-{config.delay[1]}ms)')
    print(f'  üìÅ JSONÁõÆÂΩï: {config.bookstore_dir}')
    print(f'  üìÅ ‰∏ãËΩΩÁõÆÂΩï: {config.download_dir}')
    
    downloader = NovelDownloader(config)

    # Check for backup
    backup_folder_path = 'C:\\Users\\Administrator\\fanqie_down_backup'
    if os.path.exists(backup_folder_path):
        choice = input("Ê£ÄÊµãÂà∞Â§á‰ªΩÊñá‰ª∂Â§πÔºåÂê¶‰ΩøÁî®Â§á‰ªΩÊçÆÔºü1.‰ΩøÁî®Â§á‰ªΩ  2.Ë∑≥ËøáÔºö")
        if choice == '1':
            if os.path.isdir(backup_folder_path):
                source_folder_path = os.path.dirname(os.path.abspath(__file__))
                for item in os.listdir(backup_folder_path):
                    source_item_path = os.path.join(backup_folder_path, item)
                    target_item_path = os.path.join(source_folder_path, item)
                    if os.path.isfile(source_item_path):
                        if os.path.exists(target_item_path):
                            os.remove(target_item_path)
                        shutil.copy2(source_item_path, target_item_path)
                    elif os.path.isdir(source_item_path):
                        if os.path.exists(target_item_path):
                            shutil.rmtree(target_item_path)
                        shutil.copytree(source_item_path, target_item_path)
            else:
                print("Â§á‰ªΩÊñá‰ª∂Â§π‰∏çÂ≠òÂú®ÔºåÊó†Ê≥ï‰ΩøÁî®Â§á‰ªΩÊï∞ÊçÆ„ÄÇ")
        elif choice != '2':
            print("ÂÖ•Êó†ÊïàÔºåËØ∑ÈáçÊñ∞ËøêË°åÁ®ãÂ∫èÂπ∂Ê≠£Á°ÆËæìÂÖ•„ÄÇ")
    else:
        print("Á®ãÂ∫èËøòÊú™Â§á‰ªΩ")

    while True:
        print('\nËæìÂÖ•‰π¶ÁöÑidÁõ¥Êé•‰∏ãËΩΩ\nËæìÂÖ•‰∏ãÈù¢ÁöÑÊï∞Â≠óËøõÂÖ•ÂÖ∂‰ªñÂäüËÉΩ:')
        print('''
1. Êõ¥Êñ∞Â∞èËØ¥
2. ÊêúÁ¥¢
3. ÊâπÈáè‰∏ãËΩΩ
4. ËÆæÁΩÆ
5. Â§á‰ªΩ
6. ÈÄÄÂá∫
        ''')

        inp = input()

        if inp == '1':
            downloader.update_all_novels()

        elif inp == '2':
            while True:
                key = input("ËØ∑ËæìÂÖ•ÊêúÁ¥¢ÂÖ≥ÈîÆËØçÔºàÁõ¥Êé•EnterËøîÂõûÔºâÔºö")
                if key == '':
                    break
                results = downloader.search_novel(key)
                if not results:
                    print("Ê≤°ÊúâÊâæÂà∞Áõ∏ÂÖ≥‰π¶Á±ç„ÄÇ")
                    continue

                for i, book in enumerate(results):
                    print(f"{i + 1}. ÂêçÁß∞Ôºö{book['book_data'][0]['book_name']} "
                          f"‰ΩúËÄÖÔºö{book['book_data'][0]['author']} "
                          f"IDÔºö{book['book_data'][0]['book_id']} "
                          f"Â≠óÊï∞Ôºö{book['book_data'][0]['word_number']}")

                while True:
                    choice = input("ËØ∑ÈÄâÊã©‰∏Ä‰∏™ÁªìÊûú, ËæìÂÖ• r ‰ª•ÈáçÊñ∞ÊêúÁ¥¢Ôºö")
                    if choice == "r":
                        break
                    elif choice.isdigit() and 1 <= int(choice) <= len(results):
                        chosen_book = results[int(choice) - 1]
                        downloader.download_novel(chosen_book['book_data'][0]['book_id'])
                        break
                    else:
                        print("ËæìÂÖ•Êó†ÊïàÔºåËØ∑ÈáçÊñ∞ËæìÂÖ•„ÄÇ")

        elif inp == '3':
            urls_path = 'urls.txt'
            if not os.path.exists(urls_path):
                print(f"Êú™ÊâæÂà∞'{urls_path}'ÔºåÂ∞Ü‰∏∫ÊÇ®ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÊñá‰ª∂„ÄÇ")
                with open(urls_path, 'w', encoding='UTF-8') as file:
                    file.write("# ËæìÂÖ•Â∞èËØ¥ÈìæÊé•Ôºå‰∏ÄË°å‰∏Ä‰∏™\n")

            print(f"\nËØ∑Âú®ÊñáÊú¨ÁºñËæëÂô®‰∏≠ÊâìÂºÄÂπ∂ÁºñËæë '{urls_path}'")
            print("Âú®Êñá‰ª∂‰∏≠ËæìÂÖ•Â∞èËØ¥ÈìæÊé•Ôºå‰∏ÄË°å‰∏Ä‰∏™")

            if platform.system() == "Windows":
                os.system(f'notepad "{urls_path}"')
            elif platform.system() == "Darwin":
                os.system(f'open -e "{urls_path}"')
            else:
                if os.system('which nano > /dev/null') == 0:
                    os.system(f'nano "{urls_path}"')
                elif os.system('which vim > /dev/null') == 0:
                    os.system(f'vim "{urls_path}"')
                else:
                    print(f"ËØ∑‰ΩøÁî®‰ªªÊÑèÊñáÊú¨ÁºñËæëÂô®ÊâãÂä®ÁºñËæë {urls_path} Êñá‰ª∂")

            print("\nÁºñËæëÂÆåÊàêÂêéÊåâEnterÈîÆÁªßÁª≠...")
            input()

            with open(urls_path, 'r', encoding='UTF-8') as file:
                content = file.read()
                urls = content.replace(' ', '').split('\n')

            for url in urls:
                if url and url[0] != '#':
                    print(f'ÂºÄÂßã‰∏ãËΩΩÈìæÊé•: {url}')
                    status = downloader.download_novel(url)
                    if not status:
                        print(f'ÈìæÊé•: {url} ‰∏ãËΩΩÂ§±Ë¥•„ÄÇ')
                    else:
                        print(f'ÈìæÊé•: {url} ‰∏ãËΩΩÂÆåÊàê„ÄÇ')

        elif inp == '4':
            print('ËØ∑ÈÄâÊã©È°πÁõÆÔºö1.Ê≠£ÊñáÊÆµÈ¶ñÂç†‰ΩçÁ¨¶ 2.Á´†ËäÇ‰∏ãËΩΩÈó¥ÈöîÂª∂Ëøü 3.Â∞èËØ¥‰øùÂ≠òË∑ØÂæÑ 4.Â∞èËØ¥‰øùÂ≠òÊñπÂºè 5.ËÆæÁΩÆ‰∏ãËΩΩÁ∫øÁ®ãÊï∞')
            inp2 = input()
            if inp2 == '1':
                tmp = input('ËØ∑ËæìÂÖ•Ê≠£ÊñáÊÆµÈ¶ñÂç†‰ΩçÁ¨¶(ÂΩìÂâç‰∏∫"%s")(Áõ¥Êé•Enter‰∏çÊõ¥Êîπ)Ôºö' % config.kgf)
                if tmp != '':
                    config.kgf = tmp
                config.kg = int(input('ËØ∑ËæìÂÖ•Ê≠£ÊñáÊÆµÈ¶ñÂç†‰ΩçÁ¨¶Êï∞ÔºàÂΩìÂâç‰∏∫%dÔºâÔºö' % config.kg))
            elif inp2 == '2':
                print('Áî±‰∫éËøüËøáÂ∞èÈÄ†ÊàêÁöÑÂêéÊûúËØ∑Ëá™Ë°åË¥üË¥£„ÄÇ\nËØ∑ËæìÂÖ•‰∏ãËΩΩÈó¥ÈöîÈöèÊú∫Âª∂Ëøü')
                config.delay[0] = int(input('‰∏ãÈôêÔºàÂΩìÂâç‰∏∫%dÔºâÊØ´ÁßíÔºâÔºö' % config.delay[0]))
                config.delay[1] = int(input('‰∏äÈôêÔºàÂΩìÂâç‰∏∫%dÔºâÔºàÊØ´ÁßíÔºâÔºö' % config.delay[1]))
            elif inp2 == '3':
                print('tip:ËÆæÁΩÆ‰∏∫ÂΩìÂâçÁõÆÂΩïÁÇπÂèñÊ∂à')
                time.sleep(1)
                path = input("\nËØ∑ËæìÂÖ•‰øùÂ≠òÁõÆÂΩïÁöÑÂÆåÊï¥Ë∑ØÂæÑ:\n(Áõ¥Êé•ÊåâEnterÁî®ÂΩìÂâçÁõÆÂΩï)\n").strip()
                if path == "":
                    config.save_path = os.getcwd()
                else:
                    if not os.path.exists(path):
                        try:
                            os.makedirs(path)
                            config.save_path = path
                        except:
                            print("Êó†Ê≥ïÂàõÂª∫ÁõÆÂΩïÔºåÂ∞Ü‰ΩøÁî®ÂΩìÂâçÁõÆÂΩï")
                            config.save_path = os.getcwd()
                    else:
                        config.save_path = path
            elif inp2 == '4':
                print('ËØ∑ÈÄâÊã©Ôºö1.‰øùÂ≠ò‰∏∫Âçï‰∏™ txt 2.ÂàÜÁ´†‰øùÂ≠ò 3.‰øùÂ≠ò‰∏∫ epub 4.‰øùÂ≠ò‰∏∫ HTML ÁΩëÈ°µÊ†ºÂºè 5.‰øùÂ≠ò‰∏∫ LaTeX')
                inp3 = input()
                try:
                    config.save_mode = SaveMode(int(inp3))
                except ValueError:
                    print('ËØ∑Ê≠£Á°ÆËæìÂÖ•!')
                    continue
            elif inp2 == '5':
                config.xc = int(input('ËØ∑ËæìÂÖ•‰∏ãËΩΩÁ∫øÁ®ãÊï∞Ôºö'))
            else:
                print('ËØ∑Ê≠£Á°ÆËæìÂÖ•!')
                continue

            # Save config
            with open(downloader.config_path, 'w', encoding='UTF-8') as f:
                json.dump({
                    'kg': config.kg,
                    'kgf': config.kgf,
                    'delay': config.delay,
                    'save_path': config.save_path,
                    'save_mode': config.save_mode.value,
                    'space_mode': config.space_mode,
                    'xc': config.xc
                }, f)
            print('ËÆæÁΩÆÂÆåÊàê')

        elif inp == '5':
            downloader.backup_data('C:\\Users\\Administrator\\fanqie_down_backup')
            print('Â§á‰ªΩÂÆåÊàê')

        elif inp == '6':
            break

        else:
            # Try to download novel directly
            if downloader.download_novel(inp):
                print('‰∏ãËΩΩÂÆåÊàê')
            else:
                print('ËØ∑ËæìÂÖ•ÊúâÊïàÁöÑÈÄâÈ°πÊàñ‰π¶Á±çID„ÄÇ')


if __name__ == "__main__":
    create_cli()